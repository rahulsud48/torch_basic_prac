{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# <font style=\"color:blue\">Assignment: Implement a CNN for Image Classification on CIFAR10 dataset</font>\n",
    "\n",
    "We have seen how to implement a CNN (LeNet5 and LeNet with the batch norm) in the last section. We used MNIST and Fashion MNIST dataset which are grayscale or single channel datasets. In this assignment, you will implement a CNN Model ( similar to LeNet ) for classifying objects in the `CIFAR10` dataset. \n",
    "\n",
    "The CIFAR10 dataset has the following properties\n",
    "1. It has `10` classes.  \n",
    "1. It has colored images, so it has `3-channels`. \n",
    "1. The image shape is `32 x 32`.\n",
    "\n",
    "Samples of CIFAR10- dataset ([source](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html?highlight=cifar)):\n",
    "\n",
    "<img src=\"https://www.learnopencv.com/wp-content/uploads/2020/01/c3_w3_cirar10.png\" width=700>\n",
    "\n",
    "\n",
    "# <font color='blue'>Marking Scheme</font>\n",
    "\n",
    "### <font style=\"color:green\">Maximum Points: 30\n",
    "\n",
    "<div>\n",
    "    <table>\n",
    "        <tr><td><h3>Sr. no.</h3></td> <td><h3>Problem</h3></td> <td><h3>Points</h3></td> </tr>\n",
    "        <tr><td><h3>1</h3></td> <td><h3>Implement the CNN Model</h3></td> <td><h3>10</h3></td> </tr>\n",
    "        <tr><td><h3>2</h3></td> <td><h3>Find Mean and Std of Training Data</h3></td> <td><h3>5</h3></td> </tr>\n",
    "        <tr><td><h3>3</h3></td> <td><h3>Model Training & Accuracy</h3></td> <td><h3>15</h3></td> </tr>\n",
    "    </table>\n",
    "</div>\n",
    "\n",
    "\n",
    "# <font color='blue'>Problem Description</font>\n",
    "\n",
    "### <font color='blue'>1. Implement the CNN Model</font>\n",
    "Since the task is to classify objects in a dataset of color images, you need to implement a CNN with 10 output classes. **Also, your model must use `Conv2d`, `BatchNorm2d`, and `ReLU`.** \n",
    "\n",
    "**You need to define the model architecture in the function: `MyModel` ( Step 1 )**\n",
    "\n",
    "Hint: For color images you need to use an input shape that is different than the ones we have been using till now, so that it accepts 3 channel inputs.\n",
    "\n",
    "### <font color='blue'>2. Find Mean and Std of Training Data</font>\n",
    "\n",
    "It is a good practice to normalize the training data. To normalize the data, we need to compute mean and std. As the dataset has colored images, it has `3-channel` (RGB or BGR). We have to find mean and std per channel using training data. \n",
    "\n",
    "**You need to compute the mean and std for the dataset in the function: `get_mean_std_train_data` ( Step 3 )**\n",
    "\n",
    "### <font color='blue'>3. Model Training and Accuracy</font>\n",
    "\n",
    "Once you have defined the model, you can train it. To get better accuracy, you need to play around the training configuration **( Step 5 )** and even the model architecture. You can check the accuracy by running the training loop in `Step 11`.\n",
    "\n",
    "Here are a few hints on how you can improve the accuracy:\n",
    "- Train for longer duration\n",
    "- Try with different learning rate\n",
    "- Try to add more convolutional layers to the architecture\n",
    "- Try to add more nodes in the layers.\n",
    "\n",
    "You need to achieve **75% accuracy** ( See Step11 ) in order to get full marks for this part. \n",
    "\n",
    "**You do not need to implement anything for this, just changing the parameters as mentioned above and running the Notebook will give you the accuracy. ( Step 5 and Step 11 )**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "required_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  # one of the best graphics library for python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "from typing import Iterable\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:blue\">1. CNN Model Architecture [10 Points]</font>\n",
    "\n",
    "You have to write the model code here. You can take reference from LeNet code.\n",
    "\n",
    "If you do not get higher accuracy, here are a few hints:\n",
    "- Try to add more convolutional layers to the architecture\n",
    "- Try to add more nodes in the layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        ###\n",
    "        ### YOUR CODE HERE\n",
    "        self.body = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 3, out_channels = 16, kernel_size = 5),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.MaxPool2d(kernel_size = 2),\n",
    "            \n",
    "            nn.Conv2d(in_channels = 16, out_channels = 64, kernel_size = 5),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.MaxPool2d(kernel_size = 2),\n",
    "            \n",
    "        )\n",
    "        \n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(in_features=64*5*5, out_features=256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_features=256, out_features=128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_features=128, out_features=10)\n",
    "        )\n",
    "        ###\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ###\n",
    "        ### YOUR CODE HERE\n",
    "        x = self.body(x)\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self.head(x)\n",
    "        ###\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# <font style=\"color:blue\">2. Display the Network</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel(\n",
      "  (body): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(16, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (head): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=256, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "my_model = MyModel()\n",
    "print(my_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Conv2d",
     "locked": true,
     "points": "3",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "BatchNorm2d",
     "locked": true,
     "points": "2",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "ReLU",
     "locked": true,
     "points": "2",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "input-output",
     "locked": true,
     "points": "3",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "lines_to_next_cell": 2,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# <font style=\"color:blue\">3. Find Mean and STD of CIFAR10 Data [5 Points]</font>\n",
    "\n",
    "Function **`get_mean_std_train_data`** should `return` `mean` and `std` of training data. You can refer to the code used in the previous section for finding the mean and std of the training data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def get_mean_std_train_data(data_root):\n",
    "    \n",
    "    train_transform = transforms.Compose([transforms.ToTensor()])\n",
    "    train_set = datasets.CIFAR10(root=data_root, train=True, download=False, transform=train_transform)\n",
    "    \n",
    "    # return mean (numpy.ndarray) and std (numpy.ndarray)\n",
    "    mean = np.array([0.5, 0.5, 0.5])\n",
    "    std = np.array([0.5, 0.5, 0.5])\n",
    "    \n",
    "    ###\n",
    "    ### YOUR CODE HERE\n",
    "    image_means = torch.stack([t.mean(1).mean(1) for t, c in train_set])\n",
    "    mean = image_means.mean(0)\n",
    "    \n",
    "    image_std = torch.stack([t.std(1).std(1) for t, c in train_set])\n",
    "    std = image_std.std(0)\n",
    "    ###\n",
    "    \n",
    "    return mean, std\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_mean_std_train_data(\"../resource/lib/publicdata/images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "lines_to_next_cell": 2,
    "nbgrader": {
     "grade": true,
     "grade_id": "mean",
     "locked": true,
     "points": "2",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "lines_to_next_cell": 2,
    "nbgrader": {
     "grade": true,
     "grade_id": "std",
     "locked": true,
     "points": "3",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def get_data(batch_size, data_root, num_workers=1):\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        mean, std = get_mean_std_train_data(data_root)\n",
    "        assert len(mean) == len(std) == 3\n",
    "    except:\n",
    "        mean = np.array([0.5, 0.5, 0.5])\n",
    "        std = np.array([0.5, 0.5, 0.5])\n",
    "        \n",
    "    \n",
    "    train_test_transforms = transforms.Compose([\n",
    "        # this re-scale image tensor values between 0-1. image_tensor /= 255\n",
    "        transforms.ToTensor(),\n",
    "        # subtract mean and divide by variance.\n",
    "        transforms.Normalize(mean, std)\n",
    "    ])\n",
    "    \n",
    "    # train dataloader\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.CIFAR10(root=data_root, train=True, download=False, transform=train_test_transforms),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "    \n",
    "    # test dataloader\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.CIFAR10(root=data_root, train=False, download=False, transform=train_test_transforms),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# <font style=\"color:blue\">4. System Configuration</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SystemConfiguration:\n",
    "    '''\n",
    "    Describes the common system setting needed for reproducible training\n",
    "    '''\n",
    "    seed: int = 42  # seed number to set the state of all random number generators\n",
    "    cudnn_benchmark_enabled: bool = True  # enable CuDNN benchmark for the sake of performance\n",
    "    cudnn_deterministic: bool = True  # make cudnn deterministic (reproducible training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# <font style=\"color:blue\">5. Training Configuration [15 Points]</font>\n",
    "All training parameters are defined here. So, \n",
    "This is where you can improve your accuracy, apart from improving the architecture. \n",
    "\n",
    "Here are a few hints on how you can improve the accuracy:\n",
    "- Train for longer duration\n",
    "- Try with different learning rate\n",
    "\n",
    "**You need to achieve 75% accuracy in order to get full marks for this part.**\n",
    "\n",
    "**You will see the effect of these changes when you run Step 11**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainingConfiguration:\n",
    "    '''\n",
    "    Describes configuration of the training process\n",
    "    '''\n",
    "    batch_size: int = 16  # amount of data to pass through the network at each forward-backward iteration\n",
    "    epochs_count: int = 50  # number of times the whole dataset will be passed through the network\n",
    "    learning_rate: float = 0.01  # determines the speed of network's weights update\n",
    "        \n",
    "    log_interval: int = 100  # how many batches to wait between logging training status\n",
    "    test_interval: int = 1  # how many epochs to wait before another test. Set to 1 to get val loss at each epoch\n",
    "    data_root: str = \"../resource/lib/publicdata/images\"  # folder to save data\n",
    "    num_workers: int = 10  # number of concurrent processes using to prepare data\n",
    "    device: str = 'cuda'  # device to use for training.\n",
    "    # update changed parameters in blow coding block.\n",
    "    # Please do not change \"data_root\" \n",
    "    \n",
    "    ###\n",
    "    ### YOUR CODE HERE\n",
    "    ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# <font style=\"color:blue\">6. System Setup</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def setup_system(system_config: SystemConfiguration) -> None:\n",
    "    torch.manual_seed(system_config.seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.backends.cudnn_benchmark_enabled = system_config.cudnn_benchmark_enabled\n",
    "        torch.backends.cudnn.deterministic = system_config.cudnn_deterministic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# <font style=\"color:blue\">7. Training</font>\n",
    "We are familiar with the training pipeline used in PyTorch. The following steps are performed in the code below:\n",
    "\n",
    "1. Send the data to the required device ( CPU/GPU )\n",
    "1. Make a forward pass using the forward method.\n",
    "1. Find the loss using the Cross_Entropy function.\n",
    "1. Find the gradients using the backward function.\n",
    "1. Update the weights using the optimizer.\n",
    "1. Find the accuracy of the model\n",
    "\n",
    "Repeat the above for the specified number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def train(\n",
    "    train_config: TrainingConfiguration, model: nn.Module, optimizer: torch.optim.Optimizer,\n",
    "    train_loader: torch.utils.data.DataLoader, epoch_idx: int\n",
    ") -> None:\n",
    "    \n",
    "    # change model in training mood\n",
    "    model.train()\n",
    "    \n",
    "    # to get batch loss\n",
    "    batch_loss = np.array([])\n",
    "    \n",
    "    # to get batch accuracy\n",
    "    batch_acc = np.array([])\n",
    "        \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        \n",
    "        # clone target\n",
    "        indx_target = target.clone()\n",
    "        # send data to device (its is medatory if GPU has to be used)\n",
    "        data = data.to(train_config.device)\n",
    "        # send target to device\n",
    "        target = target.to(train_config.device)\n",
    "\n",
    "        # reset parameters gradient to zero\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass to the model\n",
    "        output = model(data)\n",
    "        \n",
    "        # cross entropy loss\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        \n",
    "        # find gradients w.r.t training parameters\n",
    "        loss.backward()\n",
    "        # Update parameters using gardients\n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_loss = np.append(batch_loss, [loss.item()])\n",
    "        \n",
    "        # Score to probability using softmax\n",
    "        prob = F.softmax(output, dim=1)\n",
    "            \n",
    "        # get the index of the max probability\n",
    "        pred = prob.data.max(dim=1)[1]  \n",
    "                        \n",
    "        # correct prediction\n",
    "        correct = pred.cpu().eq(indx_target).sum()\n",
    "            \n",
    "        # accuracy\n",
    "        acc = float(correct) / float(len(data))\n",
    "        \n",
    "        batch_acc = np.append(batch_acc, [acc])\n",
    "\n",
    "        if batch_idx % train_config.log_interval == 0 and batch_idx > 0:              \n",
    "            print(\n",
    "                'Train Epoch: {} [{}/{}] Loss: {:.6f} Acc: {:.4f}'.format(\n",
    "                    epoch_idx, batch_idx * len(data), len(train_loader.dataset), loss.item(), acc\n",
    "                )\n",
    "            )\n",
    "            \n",
    "    epoch_loss = batch_loss.mean()\n",
    "    epoch_acc = batch_acc.mean()\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# <font style=\"color:blue\">8. Validation</font>\n",
    "\n",
    "After every few epochs **`validation`** will be called with the `trained model` and `test_loader` to get validation loss and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def validate(\n",
    "    train_config: TrainingConfiguration,\n",
    "    model: nn.Module,\n",
    "    test_loader: torch.utils.data.DataLoader,\n",
    ") -> float:\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    count_corect_predictions = 0\n",
    "    for data, target in test_loader:\n",
    "        indx_target = target.clone()\n",
    "        data = data.to(train_config.device)\n",
    "        \n",
    "        target = target.to(train_config.device)\n",
    "        \n",
    "        output = model(data)\n",
    "        # add loss for each mini batch\n",
    "        test_loss += F.cross_entropy(output, target).item()\n",
    "        \n",
    "        # Score to probability using softmax\n",
    "        prob = F.softmax(output, dim=1)\n",
    "        \n",
    "        # get the index of the max probability\n",
    "        pred = prob.data.max(dim=1)[1] \n",
    "        \n",
    "        # add correct prediction count\n",
    "        count_corect_predictions += pred.cpu().eq(indx_target).sum()\n",
    "\n",
    "    # average over number of mini-batches\n",
    "    test_loss = test_loss / len(test_loader)  \n",
    "    \n",
    "    # average over number of dataset\n",
    "    accuracy = 100. * count_corect_predictions / len(test_loader.dataset)\n",
    "    \n",
    "    print(\n",
    "        '\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            test_loss, count_corect_predictions, len(test_loader.dataset), accuracy\n",
    "        )\n",
    "    )\n",
    "    return test_loss, accuracy/100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# <font style=\"color:blue\">9. Saving the Model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def save_model(model, device, model_dir='models', model_file_name='cifar10_cnn_model.pt'):\n",
    "    \n",
    "\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "\n",
    "    model_path = os.path.join(model_dir, model_file_name)\n",
    "\n",
    "    # make sure you transfer the model to cpu.\n",
    "    if device == 'cuda':\n",
    "        model.to('cpu')\n",
    "\n",
    "    # save the state_dict\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    \n",
    "    if device == 'cuda':\n",
    "        model.to('cuda')\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# <font style=\"color:blue\">10. Main</font>\n",
    "\n",
    "In this section of code, we use the configuration parameters defined above and start the training. Here are the important actions being taken in the code below:\n",
    "\n",
    "1. Set up system parameters like CPU/GPU, number of threads etc\n",
    "1. Load the data using dataloaders\n",
    "1. Create an instance of the LeNet model\n",
    "1. Specify optimizer to use.\n",
    "1. Set up variables to track loss and accuracy and start training.\n",
    "1. If loss decreases, saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def main(system_configuration=SystemConfiguration(), training_configuration=TrainingConfiguration()):\n",
    "    \n",
    "    # system configuration\n",
    "    setup_system(system_configuration)\n",
    "\n",
    "    # batch size\n",
    "    batch_size_to_set = training_configuration.batch_size\n",
    "    # num_workers\n",
    "    num_workers_to_set = training_configuration.num_workers\n",
    "    # epochs\n",
    "    epoch_num_to_set = training_configuration.epochs_count\n",
    "\n",
    "    # if GPU is available use training config, \n",
    "    # else lowers batch_size, num_workers and epochs count\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "        num_workers_to_set = 2\n",
    "\n",
    "    # data loader\n",
    "    train_loader, test_loader = get_data(\n",
    "        batch_size=training_configuration.batch_size,\n",
    "        data_root=training_configuration.data_root,\n",
    "        num_workers=num_workers_to_set\n",
    "    )\n",
    "    \n",
    "    # Update training configuration\n",
    "    training_configuration = TrainingConfiguration(\n",
    "        device=device,\n",
    "        num_workers=num_workers_to_set\n",
    "    )\n",
    "\n",
    "    # initiate model\n",
    "    model = MyModel()\n",
    "        \n",
    "    # send model to device (GPU/CPU)\n",
    "    model.to(training_configuration.device)\n",
    "\n",
    "    # optimizer\n",
    "    optimizer = optim.SGD(\n",
    "        model.parameters(),\n",
    "        lr=training_configuration.learning_rate\n",
    "    )\n",
    "\n",
    "    best_loss = torch.tensor(np.inf)\n",
    "    best_accuracy = torch.tensor(0)\n",
    "    \n",
    "    # epoch train/test loss\n",
    "    epoch_train_loss = np.array([])\n",
    "    epoch_test_loss = np.array([])\n",
    "    \n",
    "    # epch train/test accuracy\n",
    "    epoch_train_acc = np.array([])\n",
    "    epoch_test_acc = np.array([])\n",
    "    \n",
    "    # trainig time measurement\n",
    "    t_begin = time.time()\n",
    "    for epoch in range(training_configuration.epochs_count):\n",
    "        \n",
    "        train_loss, train_acc = train(training_configuration, model, optimizer, train_loader, epoch)\n",
    "        \n",
    "        epoch_train_loss = np.append(epoch_train_loss, [train_loss])\n",
    "        \n",
    "        epoch_train_acc = np.append(epoch_train_acc, [train_acc])\n",
    "\n",
    "        elapsed_time = time.time() - t_begin\n",
    "        speed_epoch = elapsed_time / (epoch + 1)\n",
    "        speed_batch = speed_epoch / len(train_loader)\n",
    "        eta = speed_epoch * training_configuration.epochs_count - elapsed_time\n",
    "        \n",
    "        print(\n",
    "            \"Elapsed {:.2f}s, {:.2f} s/epoch, {:.2f} s/batch, ets {:.2f}s\".format(\n",
    "                elapsed_time, speed_epoch, speed_batch, eta\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if epoch % training_configuration.test_interval == 0:\n",
    "            current_loss, current_accuracy = validate(training_configuration, model, test_loader)\n",
    "            \n",
    "            epoch_test_loss = np.append(epoch_test_loss, [current_loss])\n",
    "        \n",
    "            epoch_test_acc = np.append(epoch_test_acc, [current_accuracy])\n",
    "            \n",
    "            if current_loss < best_loss:\n",
    "                best_loss = current_loss\n",
    "            \n",
    "            if current_accuracy > best_accuracy:\n",
    "                best_accuracy = current_accuracy\n",
    "                print('Accuracy improved, saving the model.\\n')\n",
    "                save_model(model, device)\n",
    "            \n",
    "                \n",
    "    print(\"Total time: {:.2f}, Best Loss: {:.3f}, Best Accuracy: {:.3f}\".format(time.time() - t_begin, best_loss, \n",
    "                                                                                best_accuracy))\n",
    "    \n",
    "    return model, epoch_train_loss, epoch_train_acc, epoch_test_loss, epoch_test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Accuracy",
     "locked": true,
     "points": "15",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:blue\">Step 11: Start Training</font>\n",
    "This is where you start the training. You may see that the training does not converge or does not give a good accuracy. You need to change \n",
    "- In Step 1: the network architecture and add a few more layers or more nodes to the already existing layers\n",
    "- In Step 5: training parameters such as learning rate or batch_size or epochs so that the network converges or run the network for longer so that it gets more time to fit the data\n",
    "\n",
    "**You need to make sure that the accuracy at the end is at least 75%.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [1600/50000] Loss: 2.266490 Acc: 0.1875\n",
      "Train Epoch: 0 [3200/50000] Loss: 1.976810 Acc: 0.1875\n",
      "Train Epoch: 0 [4800/50000] Loss: 1.538387 Acc: 0.5625\n",
      "Train Epoch: 0 [6400/50000] Loss: 1.727487 Acc: 0.3125\n",
      "Train Epoch: 0 [8000/50000] Loss: 1.600228 Acc: 0.4375\n",
      "Train Epoch: 0 [9600/50000] Loss: 1.315786 Acc: 0.3750\n",
      "Train Epoch: 0 [11200/50000] Loss: 1.719422 Acc: 0.1875\n",
      "Train Epoch: 0 [12800/50000] Loss: 1.585712 Acc: 0.5000\n",
      "Train Epoch: 0 [14400/50000] Loss: 1.435912 Acc: 0.3125\n",
      "Train Epoch: 0 [16000/50000] Loss: 1.502356 Acc: 0.3750\n",
      "Train Epoch: 0 [17600/50000] Loss: 1.087530 Acc: 0.6250\n",
      "Train Epoch: 0 [19200/50000] Loss: 1.831149 Acc: 0.2500\n",
      "Train Epoch: 0 [20800/50000] Loss: 1.048182 Acc: 0.5625\n",
      "Train Epoch: 0 [22400/50000] Loss: 1.782965 Acc: 0.4375\n",
      "Train Epoch: 0 [24000/50000] Loss: 0.995813 Acc: 0.6875\n",
      "Train Epoch: 0 [25600/50000] Loss: 1.000976 Acc: 0.8125\n",
      "Train Epoch: 0 [27200/50000] Loss: 1.507758 Acc: 0.5625\n",
      "Train Epoch: 0 [28800/50000] Loss: 1.275683 Acc: 0.5000\n",
      "Train Epoch: 0 [30400/50000] Loss: 1.440747 Acc: 0.5000\n",
      "Train Epoch: 0 [32000/50000] Loss: 1.179719 Acc: 0.4375\n",
      "Train Epoch: 0 [33600/50000] Loss: 1.890763 Acc: 0.3125\n",
      "Train Epoch: 0 [35200/50000] Loss: 1.349627 Acc: 0.5000\n",
      "Train Epoch: 0 [36800/50000] Loss: 1.308190 Acc: 0.5000\n",
      "Train Epoch: 0 [38400/50000] Loss: 1.064295 Acc: 0.6875\n",
      "Train Epoch: 0 [40000/50000] Loss: 1.294179 Acc: 0.5625\n",
      "Train Epoch: 0 [41600/50000] Loss: 1.749128 Acc: 0.2500\n",
      "Train Epoch: 0 [43200/50000] Loss: 1.139144 Acc: 0.6250\n",
      "Train Epoch: 0 [44800/50000] Loss: 1.562957 Acc: 0.3750\n",
      "Train Epoch: 0 [46400/50000] Loss: 1.479609 Acc: 0.5000\n",
      "Train Epoch: 0 [48000/50000] Loss: 1.407359 Acc: 0.6250\n",
      "Train Epoch: 0 [49600/50000] Loss: 1.287086 Acc: 0.6250\n",
      "Elapsed 38.65s, 38.65 s/epoch, 0.01 s/batch, ets 1894.07s\n",
      "\n",
      "Test set: Average loss: 1.2403, Accuracy: 5532/10000 (55%)\n",
      "\n",
      "Accuracy improved, saving the model.\n",
      "\n",
      "Train Epoch: 1 [1600/50000] Loss: 1.379926 Acc: 0.5625\n",
      "Train Epoch: 1 [3200/50000] Loss: 1.445103 Acc: 0.5625\n",
      "Train Epoch: 1 [4800/50000] Loss: 1.241072 Acc: 0.5000\n",
      "Train Epoch: 1 [6400/50000] Loss: 1.790949 Acc: 0.4375\n",
      "Train Epoch: 1 [8000/50000] Loss: 1.113376 Acc: 0.5625\n",
      "Train Epoch: 1 [9600/50000] Loss: 1.494789 Acc: 0.5000\n",
      "Train Epoch: 1 [11200/50000] Loss: 1.081829 Acc: 0.6250\n",
      "Train Epoch: 1 [12800/50000] Loss: 1.712948 Acc: 0.4375\n",
      "Train Epoch: 1 [14400/50000] Loss: 1.136499 Acc: 0.5625\n",
      "Train Epoch: 1 [16000/50000] Loss: 0.686117 Acc: 0.8125\n",
      "Train Epoch: 1 [17600/50000] Loss: 0.791570 Acc: 0.7500\n",
      "Train Epoch: 1 [19200/50000] Loss: 0.996710 Acc: 0.5625\n",
      "Train Epoch: 1 [20800/50000] Loss: 1.047934 Acc: 0.7500\n",
      "Train Epoch: 1 [22400/50000] Loss: 1.251250 Acc: 0.5000\n",
      "Train Epoch: 1 [24000/50000] Loss: 1.432862 Acc: 0.5625\n",
      "Train Epoch: 1 [25600/50000] Loss: 1.340665 Acc: 0.6875\n",
      "Train Epoch: 1 [27200/50000] Loss: 1.367369 Acc: 0.3750\n",
      "Train Epoch: 1 [28800/50000] Loss: 0.879760 Acc: 0.6250\n",
      "Train Epoch: 1 [30400/50000] Loss: 0.949604 Acc: 0.6875\n",
      "Train Epoch: 1 [32000/50000] Loss: 0.876613 Acc: 0.6250\n",
      "Train Epoch: 1 [33600/50000] Loss: 1.344642 Acc: 0.5000\n",
      "Train Epoch: 1 [35200/50000] Loss: 1.146642 Acc: 0.5625\n",
      "Train Epoch: 1 [36800/50000] Loss: 1.085533 Acc: 0.6875\n",
      "Train Epoch: 1 [38400/50000] Loss: 0.717767 Acc: 0.7500\n",
      "Train Epoch: 1 [40000/50000] Loss: 0.935366 Acc: 0.7500\n",
      "Train Epoch: 1 [41600/50000] Loss: 1.232286 Acc: 0.6250\n",
      "Train Epoch: 1 [43200/50000] Loss: 0.859929 Acc: 0.6250\n",
      "Train Epoch: 1 [44800/50000] Loss: 0.918672 Acc: 0.6250\n",
      "Train Epoch: 1 [46400/50000] Loss: 0.836432 Acc: 0.6875\n",
      "Train Epoch: 1 [48000/50000] Loss: 0.963328 Acc: 0.6250\n",
      "Train Epoch: 1 [49600/50000] Loss: 1.269614 Acc: 0.5000\n",
      "Elapsed 79.41s, 39.71 s/epoch, 0.01 s/batch, ets 1905.93s\n",
      "\n",
      "Test set: Average loss: 0.9931, Accuracy: 6476/10000 (65%)\n",
      "\n",
      "Accuracy improved, saving the model.\n",
      "\n",
      "Train Epoch: 2 [1600/50000] Loss: 1.492123 Acc: 0.6250\n",
      "Train Epoch: 2 [3200/50000] Loss: 0.757347 Acc: 0.6875\n",
      "Train Epoch: 2 [4800/50000] Loss: 0.889533 Acc: 0.6250\n",
      "Train Epoch: 2 [6400/50000] Loss: 0.988036 Acc: 0.6250\n",
      "Train Epoch: 2 [8000/50000] Loss: 0.835664 Acc: 0.6875\n",
      "Train Epoch: 2 [9600/50000] Loss: 1.300410 Acc: 0.4375\n",
      "Train Epoch: 2 [11200/50000] Loss: 0.843144 Acc: 0.8125\n",
      "Train Epoch: 2 [12800/50000] Loss: 1.049745 Acc: 0.6875\n",
      "Train Epoch: 2 [14400/50000] Loss: 1.795285 Acc: 0.5000\n",
      "Train Epoch: 2 [16000/50000] Loss: 1.057368 Acc: 0.5625\n",
      "Train Epoch: 2 [17600/50000] Loss: 0.895963 Acc: 0.6875\n",
      "Train Epoch: 2 [19200/50000] Loss: 0.771746 Acc: 0.6875\n",
      "Train Epoch: 2 [20800/50000] Loss: 1.641068 Acc: 0.3750\n",
      "Train Epoch: 2 [22400/50000] Loss: 0.895616 Acc: 0.5625\n",
      "Train Epoch: 2 [24000/50000] Loss: 0.779589 Acc: 0.6250\n",
      "Train Epoch: 2 [25600/50000] Loss: 1.178309 Acc: 0.6250\n",
      "Train Epoch: 2 [27200/50000] Loss: 1.040580 Acc: 0.6250\n",
      "Train Epoch: 2 [28800/50000] Loss: 0.730675 Acc: 0.7500\n",
      "Train Epoch: 2 [30400/50000] Loss: 0.696641 Acc: 0.7500\n",
      "Train Epoch: 2 [32000/50000] Loss: 0.803844 Acc: 0.6875\n",
      "Train Epoch: 2 [33600/50000] Loss: 1.396271 Acc: 0.5000\n",
      "Train Epoch: 2 [35200/50000] Loss: 0.543890 Acc: 0.7500\n",
      "Train Epoch: 2 [36800/50000] Loss: 1.137068 Acc: 0.6250\n",
      "Train Epoch: 2 [38400/50000] Loss: 0.906900 Acc: 0.7500\n",
      "Train Epoch: 2 [40000/50000] Loss: 1.024743 Acc: 0.6250\n",
      "Train Epoch: 2 [41600/50000] Loss: 0.955067 Acc: 0.6875\n",
      "Train Epoch: 2 [43200/50000] Loss: 0.875890 Acc: 0.6875\n",
      "Train Epoch: 2 [44800/50000] Loss: 0.486932 Acc: 0.8125\n",
      "Train Epoch: 2 [46400/50000] Loss: 0.685916 Acc: 0.8750\n",
      "Train Epoch: 2 [48000/50000] Loss: 1.028696 Acc: 0.5625\n",
      "Train Epoch: 2 [49600/50000] Loss: 0.667737 Acc: 0.7500\n",
      "Elapsed 120.53s, 40.18 s/epoch, 0.01 s/batch, ets 1888.34s\n",
      "\n",
      "Test set: Average loss: 0.9371, Accuracy: 6666/10000 (67%)\n",
      "\n",
      "Accuracy improved, saving the model.\n",
      "\n",
      "Train Epoch: 3 [1600/50000] Loss: 0.625790 Acc: 0.7500\n",
      "Train Epoch: 3 [3200/50000] Loss: 0.672412 Acc: 0.8125\n",
      "Train Epoch: 3 [4800/50000] Loss: 1.344947 Acc: 0.3125\n",
      "Train Epoch: 3 [6400/50000] Loss: 0.987467 Acc: 0.6875\n",
      "Train Epoch: 3 [8000/50000] Loss: 0.801027 Acc: 0.7500\n",
      "Train Epoch: 3 [9600/50000] Loss: 0.582074 Acc: 0.7500\n",
      "Train Epoch: 3 [11200/50000] Loss: 0.886044 Acc: 0.6875\n",
      "Train Epoch: 3 [12800/50000] Loss: 1.254827 Acc: 0.3750\n",
      "Train Epoch: 3 [14400/50000] Loss: 0.979911 Acc: 0.6250\n",
      "Train Epoch: 3 [16000/50000] Loss: 0.688075 Acc: 0.8125\n",
      "Train Epoch: 3 [17600/50000] Loss: 0.965057 Acc: 0.6875\n",
      "Train Epoch: 3 [19200/50000] Loss: 0.627555 Acc: 0.8125\n",
      "Train Epoch: 3 [20800/50000] Loss: 0.741317 Acc: 0.6250\n",
      "Train Epoch: 3 [22400/50000] Loss: 1.159857 Acc: 0.5625\n",
      "Train Epoch: 3 [24000/50000] Loss: 0.981842 Acc: 0.6250\n",
      "Train Epoch: 3 [25600/50000] Loss: 1.145436 Acc: 0.6875\n",
      "Train Epoch: 3 [27200/50000] Loss: 0.894420 Acc: 0.6875\n",
      "Train Epoch: 3 [28800/50000] Loss: 1.162248 Acc: 0.5000\n",
      "Train Epoch: 3 [30400/50000] Loss: 0.628877 Acc: 0.8750\n",
      "Train Epoch: 3 [32000/50000] Loss: 1.402109 Acc: 0.5625\n",
      "Train Epoch: 3 [33600/50000] Loss: 0.863857 Acc: 0.6250\n",
      "Train Epoch: 3 [35200/50000] Loss: 0.497599 Acc: 0.8125\n",
      "Train Epoch: 3 [36800/50000] Loss: 1.576330 Acc: 0.3750\n",
      "Train Epoch: 3 [38400/50000] Loss: 1.007155 Acc: 0.6250\n",
      "Train Epoch: 3 [40000/50000] Loss: 1.139227 Acc: 0.6250\n",
      "Train Epoch: 3 [41600/50000] Loss: 0.818886 Acc: 0.6875\n",
      "Train Epoch: 3 [43200/50000] Loss: 0.845539 Acc: 0.6875\n",
      "Train Epoch: 3 [44800/50000] Loss: 1.281404 Acc: 0.6250\n",
      "Train Epoch: 3 [46400/50000] Loss: 0.778546 Acc: 0.7500\n",
      "Train Epoch: 3 [48000/50000] Loss: 0.978793 Acc: 0.6875\n",
      "Train Epoch: 3 [49600/50000] Loss: 1.072928 Acc: 0.5625\n",
      "Elapsed 163.03s, 40.76 s/epoch, 0.01 s/batch, ets 1874.84s\n",
      "\n",
      "Test set: Average loss: 0.8677, Accuracy: 6976/10000 (70%)\n",
      "\n",
      "Accuracy improved, saving the model.\n",
      "\n",
      "Train Epoch: 4 [1600/50000] Loss: 0.970400 Acc: 0.5000\n",
      "Train Epoch: 4 [3200/50000] Loss: 0.404331 Acc: 0.8125\n",
      "Train Epoch: 4 [4800/50000] Loss: 0.471860 Acc: 0.8750\n",
      "Train Epoch: 4 [6400/50000] Loss: 0.678251 Acc: 0.8750\n",
      "Train Epoch: 4 [8000/50000] Loss: 1.242633 Acc: 0.6250\n",
      "Train Epoch: 4 [9600/50000] Loss: 0.797760 Acc: 0.6875\n",
      "Train Epoch: 4 [11200/50000] Loss: 0.857974 Acc: 0.6250\n",
      "Train Epoch: 4 [12800/50000] Loss: 0.432661 Acc: 0.8750\n",
      "Train Epoch: 4 [14400/50000] Loss: 0.878429 Acc: 0.5625\n",
      "Train Epoch: 4 [16000/50000] Loss: 1.467258 Acc: 0.6250\n",
      "Train Epoch: 4 [17600/50000] Loss: 0.507643 Acc: 0.7500\n",
      "Train Epoch: 4 [19200/50000] Loss: 0.683275 Acc: 0.6875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [20800/50000] Loss: 0.755048 Acc: 0.8125\n",
      "Train Epoch: 4 [22400/50000] Loss: 0.531642 Acc: 0.8125\n",
      "Train Epoch: 4 [24000/50000] Loss: 0.937861 Acc: 0.7500\n",
      "Train Epoch: 4 [25600/50000] Loss: 0.691422 Acc: 0.6875\n",
      "Train Epoch: 4 [27200/50000] Loss: 0.895158 Acc: 0.6250\n",
      "Train Epoch: 4 [28800/50000] Loss: 0.794406 Acc: 0.6250\n",
      "Train Epoch: 4 [30400/50000] Loss: 1.642938 Acc: 0.5625\n",
      "Train Epoch: 4 [32000/50000] Loss: 0.188386 Acc: 1.0000\n",
      "Train Epoch: 4 [33600/50000] Loss: 0.513072 Acc: 0.8750\n",
      "Train Epoch: 4 [35200/50000] Loss: 0.487537 Acc: 0.8750\n",
      "Train Epoch: 4 [36800/50000] Loss: 1.191493 Acc: 0.5625\n",
      "Train Epoch: 4 [38400/50000] Loss: 0.518916 Acc: 0.8125\n",
      "Train Epoch: 4 [40000/50000] Loss: 0.897439 Acc: 0.7500\n",
      "Train Epoch: 4 [41600/50000] Loss: 0.658374 Acc: 0.8125\n",
      "Train Epoch: 4 [43200/50000] Loss: 0.937753 Acc: 0.6250\n",
      "Train Epoch: 4 [44800/50000] Loss: 0.704165 Acc: 0.6875\n",
      "Train Epoch: 4 [46400/50000] Loss: 0.545505 Acc: 0.8125\n",
      "Train Epoch: 4 [48000/50000] Loss: 0.920128 Acc: 0.7500\n",
      "Train Epoch: 4 [49600/50000] Loss: 0.587041 Acc: 0.8750\n",
      "Elapsed 204.33s, 40.87 s/epoch, 0.01 s/batch, ets 1838.94s\n",
      "\n",
      "Test set: Average loss: 0.8597, Accuracy: 7012/10000 (70%)\n",
      "\n",
      "Accuracy improved, saving the model.\n",
      "\n",
      "Train Epoch: 5 [1600/50000] Loss: 0.384356 Acc: 0.8125\n",
      "Train Epoch: 5 [3200/50000] Loss: 0.706516 Acc: 0.8125\n",
      "Train Epoch: 5 [4800/50000] Loss: 0.511995 Acc: 0.8750\n",
      "Train Epoch: 5 [6400/50000] Loss: 0.438384 Acc: 0.8750\n",
      "Train Epoch: 5 [8000/50000] Loss: 0.866138 Acc: 0.7500\n",
      "Train Epoch: 5 [9600/50000] Loss: 1.108798 Acc: 0.6250\n",
      "Train Epoch: 5 [11200/50000] Loss: 1.187782 Acc: 0.5000\n",
      "Train Epoch: 5 [12800/50000] Loss: 0.982718 Acc: 0.6250\n",
      "Train Epoch: 5 [14400/50000] Loss: 0.515324 Acc: 0.8750\n",
      "Train Epoch: 5 [16000/50000] Loss: 0.409261 Acc: 0.7500\n",
      "Train Epoch: 5 [17600/50000] Loss: 0.453717 Acc: 0.8750\n",
      "Train Epoch: 5 [19200/50000] Loss: 0.294824 Acc: 0.9375\n",
      "Train Epoch: 5 [20800/50000] Loss: 0.717514 Acc: 0.7500\n",
      "Train Epoch: 5 [22400/50000] Loss: 0.813932 Acc: 0.5625\n",
      "Train Epoch: 5 [24000/50000] Loss: 1.388673 Acc: 0.6250\n",
      "Train Epoch: 5 [25600/50000] Loss: 0.696465 Acc: 0.7500\n",
      "Train Epoch: 5 [27200/50000] Loss: 0.344720 Acc: 0.8750\n",
      "Train Epoch: 5 [28800/50000] Loss: 0.847162 Acc: 0.6250\n",
      "Train Epoch: 5 [30400/50000] Loss: 0.763930 Acc: 0.6250\n",
      "Train Epoch: 5 [32000/50000] Loss: 0.956817 Acc: 0.6250\n",
      "Train Epoch: 5 [33600/50000] Loss: 1.159562 Acc: 0.6250\n",
      "Train Epoch: 5 [35200/50000] Loss: 0.910262 Acc: 0.7500\n",
      "Train Epoch: 5 [36800/50000] Loss: 0.712541 Acc: 0.7500\n",
      "Train Epoch: 5 [38400/50000] Loss: 0.518229 Acc: 0.7500\n",
      "Train Epoch: 5 [40000/50000] Loss: 1.037861 Acc: 0.7500\n",
      "Train Epoch: 5 [41600/50000] Loss: 0.581661 Acc: 0.8125\n",
      "Train Epoch: 5 [43200/50000] Loss: 0.429205 Acc: 0.8750\n",
      "Train Epoch: 5 [44800/50000] Loss: 0.760434 Acc: 0.6875\n",
      "Train Epoch: 5 [46400/50000] Loss: 0.456601 Acc: 0.9375\n",
      "Train Epoch: 5 [48000/50000] Loss: 0.421523 Acc: 0.8125\n",
      "Train Epoch: 5 [49600/50000] Loss: 1.068261 Acc: 0.6250\n",
      "Elapsed 246.59s, 41.10 s/epoch, 0.01 s/batch, ets 1808.31s\n",
      "\n",
      "Test set: Average loss: 0.7815, Accuracy: 7302/10000 (73%)\n",
      "\n",
      "Accuracy improved, saving the model.\n",
      "\n",
      "Train Epoch: 6 [1600/50000] Loss: 0.883516 Acc: 0.6875\n",
      "Train Epoch: 6 [3200/50000] Loss: 0.287518 Acc: 0.8750\n",
      "Train Epoch: 6 [4800/50000] Loss: 0.900901 Acc: 0.6250\n",
      "Train Epoch: 6 [6400/50000] Loss: 0.881256 Acc: 0.6250\n",
      "Train Epoch: 6 [8000/50000] Loss: 0.378335 Acc: 0.8750\n",
      "Train Epoch: 6 [9600/50000] Loss: 0.790138 Acc: 0.7500\n",
      "Train Epoch: 6 [11200/50000] Loss: 0.404961 Acc: 0.8750\n",
      "Train Epoch: 6 [12800/50000] Loss: 0.613537 Acc: 0.6875\n",
      "Train Epoch: 6 [14400/50000] Loss: 0.932544 Acc: 0.5625\n",
      "Train Epoch: 6 [16000/50000] Loss: 1.040496 Acc: 0.6875\n",
      "Train Epoch: 6 [17600/50000] Loss: 0.644199 Acc: 0.7500\n",
      "Train Epoch: 6 [19200/50000] Loss: 0.413323 Acc: 0.8750\n",
      "Train Epoch: 6 [20800/50000] Loss: 0.743731 Acc: 0.8125\n",
      "Train Epoch: 6 [22400/50000] Loss: 0.859024 Acc: 0.7500\n",
      "Train Epoch: 6 [24000/50000] Loss: 0.440063 Acc: 0.8750\n",
      "Train Epoch: 6 [25600/50000] Loss: 0.402950 Acc: 0.8750\n",
      "Train Epoch: 6 [27200/50000] Loss: 0.807022 Acc: 0.7500\n",
      "Train Epoch: 6 [28800/50000] Loss: 0.563484 Acc: 0.8125\n",
      "Train Epoch: 6 [30400/50000] Loss: 0.398102 Acc: 0.8750\n",
      "Train Epoch: 6 [32000/50000] Loss: 0.403212 Acc: 0.8750\n",
      "Train Epoch: 6 [33600/50000] Loss: 0.483785 Acc: 0.8750\n",
      "Train Epoch: 6 [35200/50000] Loss: 0.612431 Acc: 0.6875\n",
      "Train Epoch: 6 [36800/50000] Loss: 0.594754 Acc: 0.7500\n",
      "Train Epoch: 6 [38400/50000] Loss: 0.399026 Acc: 0.8125\n",
      "Train Epoch: 6 [40000/50000] Loss: 0.699813 Acc: 0.6250\n",
      "Train Epoch: 6 [41600/50000] Loss: 0.492782 Acc: 0.9375\n",
      "Train Epoch: 6 [43200/50000] Loss: 0.335742 Acc: 0.9375\n",
      "Train Epoch: 6 [44800/50000] Loss: 0.320615 Acc: 0.9375\n",
      "Train Epoch: 6 [46400/50000] Loss: 0.449917 Acc: 0.8750\n",
      "Train Epoch: 6 [48000/50000] Loss: 0.437056 Acc: 0.8125\n",
      "Train Epoch: 6 [49600/50000] Loss: 0.605560 Acc: 0.8750\n",
      "Elapsed 287.76s, 41.11 s/epoch, 0.01 s/batch, ets 1767.69s\n",
      "\n",
      "Test set: Average loss: 0.8611, Accuracy: 7060/10000 (71%)\n",
      "\n",
      "Train Epoch: 7 [1600/50000] Loss: 0.451000 Acc: 0.8750\n",
      "Train Epoch: 7 [3200/50000] Loss: 0.698943 Acc: 0.6875\n",
      "Train Epoch: 7 [4800/50000] Loss: 1.282407 Acc: 0.6250\n",
      "Train Epoch: 7 [6400/50000] Loss: 0.622405 Acc: 0.8750\n",
      "Train Epoch: 7 [8000/50000] Loss: 0.518776 Acc: 0.7500\n",
      "Train Epoch: 7 [9600/50000] Loss: 0.622839 Acc: 0.6250\n",
      "Train Epoch: 7 [11200/50000] Loss: 0.662434 Acc: 0.8125\n",
      "Train Epoch: 7 [12800/50000] Loss: 0.526386 Acc: 0.8125\n",
      "Train Epoch: 7 [14400/50000] Loss: 0.809201 Acc: 0.7500\n",
      "Train Epoch: 7 [16000/50000] Loss: 0.423411 Acc: 0.8750\n",
      "Train Epoch: 7 [17600/50000] Loss: 1.060900 Acc: 0.6875\n",
      "Train Epoch: 7 [19200/50000] Loss: 0.581214 Acc: 0.8125\n",
      "Train Epoch: 7 [20800/50000] Loss: 0.348101 Acc: 0.9375\n",
      "Train Epoch: 7 [22400/50000] Loss: 0.595728 Acc: 0.8125\n",
      "Train Epoch: 7 [24000/50000] Loss: 0.517448 Acc: 0.8750\n",
      "Train Epoch: 7 [25600/50000] Loss: 0.325410 Acc: 0.9375\n",
      "Train Epoch: 7 [27200/50000] Loss: 0.486226 Acc: 0.8750\n",
      "Train Epoch: 7 [28800/50000] Loss: 1.018906 Acc: 0.6875\n",
      "Train Epoch: 7 [30400/50000] Loss: 0.648237 Acc: 0.8750\n",
      "Train Epoch: 7 [32000/50000] Loss: 0.614520 Acc: 0.7500\n",
      "Train Epoch: 7 [33600/50000] Loss: 0.558322 Acc: 0.8125\n",
      "Train Epoch: 7 [35200/50000] Loss: 0.481386 Acc: 0.7500\n",
      "Train Epoch: 7 [36800/50000] Loss: 0.777653 Acc: 0.6875\n",
      "Train Epoch: 7 [38400/50000] Loss: 0.581445 Acc: 0.6875\n",
      "Train Epoch: 7 [40000/50000] Loss: 0.533484 Acc: 0.7500\n",
      "Train Epoch: 7 [41600/50000] Loss: 0.392103 Acc: 0.9375\n",
      "Train Epoch: 7 [43200/50000] Loss: 0.569005 Acc: 0.8125\n",
      "Train Epoch: 7 [44800/50000] Loss: 0.601881 Acc: 0.8125\n",
      "Train Epoch: 7 [46400/50000] Loss: 0.466612 Acc: 0.7500\n",
      "Train Epoch: 7 [48000/50000] Loss: 0.151106 Acc: 1.0000\n",
      "Train Epoch: 7 [49600/50000] Loss: 0.749233 Acc: 0.8125\n",
      "Elapsed 328.64s, 41.08 s/epoch, 0.01 s/batch, ets 1725.35s\n",
      "\n",
      "Test set: Average loss: 0.7929, Accuracy: 7329/10000 (73%)\n",
      "\n",
      "Accuracy improved, saving the model.\n",
      "\n",
      "Train Epoch: 8 [1600/50000] Loss: 0.471980 Acc: 0.8125\n",
      "Train Epoch: 8 [3200/50000] Loss: 0.480359 Acc: 0.8750\n",
      "Train Epoch: 8 [4800/50000] Loss: 0.301777 Acc: 0.9375\n",
      "Train Epoch: 8 [6400/50000] Loss: 0.112596 Acc: 1.0000\n",
      "Train Epoch: 8 [8000/50000] Loss: 0.712246 Acc: 0.7500\n",
      "Train Epoch: 8 [9600/50000] Loss: 1.192943 Acc: 0.6875\n",
      "Train Epoch: 8 [11200/50000] Loss: 0.649795 Acc: 0.6875\n",
      "Train Epoch: 8 [12800/50000] Loss: 0.906954 Acc: 0.6875\n",
      "Train Epoch: 8 [14400/50000] Loss: 0.710130 Acc: 0.6875\n",
      "Train Epoch: 8 [16000/50000] Loss: 0.311612 Acc: 0.8750\n",
      "Train Epoch: 8 [17600/50000] Loss: 0.306992 Acc: 0.8750\n",
      "Train Epoch: 8 [19200/50000] Loss: 0.554646 Acc: 0.8125\n",
      "Train Epoch: 8 [20800/50000] Loss: 0.504321 Acc: 0.8750\n",
      "Train Epoch: 8 [22400/50000] Loss: 0.234717 Acc: 0.8750\n",
      "Train Epoch: 8 [24000/50000] Loss: 0.554313 Acc: 0.8125\n",
      "Train Epoch: 8 [25600/50000] Loss: 0.422502 Acc: 0.7500\n",
      "Train Epoch: 8 [27200/50000] Loss: 0.527802 Acc: 0.8125\n",
      "Train Epoch: 8 [28800/50000] Loss: 0.569448 Acc: 0.7500\n",
      "Train Epoch: 8 [30400/50000] Loss: 1.247472 Acc: 0.5625\n",
      "Train Epoch: 8 [32000/50000] Loss: 0.487241 Acc: 0.8125\n",
      "Train Epoch: 8 [33600/50000] Loss: 0.512851 Acc: 0.8750\n",
      "Train Epoch: 8 [35200/50000] Loss: 0.999051 Acc: 0.7500\n",
      "Train Epoch: 8 [36800/50000] Loss: 0.206178 Acc: 1.0000\n",
      "Train Epoch: 8 [38400/50000] Loss: 0.927981 Acc: 0.8125\n",
      "Train Epoch: 8 [40000/50000] Loss: 0.967406 Acc: 0.6875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [41600/50000] Loss: 0.351039 Acc: 0.8750\n",
      "Train Epoch: 8 [43200/50000] Loss: 0.677381 Acc: 0.7500\n",
      "Train Epoch: 8 [44800/50000] Loss: 0.466045 Acc: 0.8125\n",
      "Train Epoch: 8 [46400/50000] Loss: 0.498329 Acc: 0.7500\n",
      "Train Epoch: 8 [48000/50000] Loss: 0.572376 Acc: 0.8750\n",
      "Train Epoch: 8 [49600/50000] Loss: 0.700865 Acc: 0.7500\n",
      "Elapsed 370.24s, 41.14 s/epoch, 0.01 s/batch, ets 1686.64s\n",
      "\n",
      "Test set: Average loss: 0.8098, Accuracy: 7338/10000 (73%)\n",
      "\n",
      "Accuracy improved, saving the model.\n",
      "\n",
      "Train Epoch: 9 [1600/50000] Loss: 0.705769 Acc: 0.7500\n",
      "Train Epoch: 9 [3200/50000] Loss: 0.478465 Acc: 0.8125\n",
      "Train Epoch: 9 [4800/50000] Loss: 0.655992 Acc: 0.8125\n",
      "Train Epoch: 9 [6400/50000] Loss: 0.448906 Acc: 0.8125\n",
      "Train Epoch: 9 [8000/50000] Loss: 0.798198 Acc: 0.8750\n",
      "Train Epoch: 9 [9600/50000] Loss: 0.363779 Acc: 0.8125\n",
      "Train Epoch: 9 [11200/50000] Loss: 0.577490 Acc: 0.8125\n",
      "Train Epoch: 9 [12800/50000] Loss: 0.427700 Acc: 0.9375\n",
      "Train Epoch: 9 [14400/50000] Loss: 0.350082 Acc: 0.8750\n",
      "Train Epoch: 9 [16000/50000] Loss: 0.346135 Acc: 0.9375\n",
      "Train Epoch: 9 [17600/50000] Loss: 0.309307 Acc: 0.8750\n",
      "Train Epoch: 9 [19200/50000] Loss: 0.921863 Acc: 0.7500\n",
      "Train Epoch: 9 [20800/50000] Loss: 0.480317 Acc: 0.8125\n",
      "Train Epoch: 9 [22400/50000] Loss: 0.715476 Acc: 0.7500\n",
      "Train Epoch: 9 [24000/50000] Loss: 0.215859 Acc: 0.9375\n",
      "Train Epoch: 9 [25600/50000] Loss: 0.426556 Acc: 0.8750\n",
      "Train Epoch: 9 [27200/50000] Loss: 0.127792 Acc: 1.0000\n",
      "Train Epoch: 9 [28800/50000] Loss: 0.452914 Acc: 0.7500\n",
      "Train Epoch: 9 [30400/50000] Loss: 0.988390 Acc: 0.6875\n",
      "Train Epoch: 9 [32000/50000] Loss: 0.346595 Acc: 0.9375\n",
      "Train Epoch: 9 [33600/50000] Loss: 0.727045 Acc: 0.7500\n",
      "Train Epoch: 9 [35200/50000] Loss: 0.173726 Acc: 0.9375\n",
      "Train Epoch: 9 [36800/50000] Loss: 0.704126 Acc: 0.8125\n",
      "Train Epoch: 9 [38400/50000] Loss: 0.609949 Acc: 0.7500\n",
      "Train Epoch: 9 [40000/50000] Loss: 0.668175 Acc: 0.7500\n",
      "Train Epoch: 9 [41600/50000] Loss: 0.383062 Acc: 0.9375\n",
      "Train Epoch: 9 [43200/50000] Loss: 0.898248 Acc: 0.6875\n",
      "Train Epoch: 9 [44800/50000] Loss: 0.318485 Acc: 0.9375\n",
      "Train Epoch: 9 [46400/50000] Loss: 0.774819 Acc: 0.6875\n",
      "Train Epoch: 9 [48000/50000] Loss: 0.673609 Acc: 0.7500\n",
      "Train Epoch: 9 [49600/50000] Loss: 0.530017 Acc: 0.7500\n",
      "Elapsed 411.42s, 41.14 s/epoch, 0.01 s/batch, ets 1645.67s\n",
      "\n",
      "Test set: Average loss: 0.8741, Accuracy: 7187/10000 (72%)\n",
      "\n",
      "Train Epoch: 10 [1600/50000] Loss: 0.534164 Acc: 0.8750\n",
      "Train Epoch: 10 [3200/50000] Loss: 0.340487 Acc: 0.8750\n",
      "Train Epoch: 10 [4800/50000] Loss: 0.391074 Acc: 0.8125\n",
      "Train Epoch: 10 [6400/50000] Loss: 0.257909 Acc: 0.8750\n",
      "Train Epoch: 10 [8000/50000] Loss: 0.428080 Acc: 0.8750\n",
      "Train Epoch: 10 [9600/50000] Loss: 0.287454 Acc: 1.0000\n",
      "Train Epoch: 10 [11200/50000] Loss: 0.220548 Acc: 0.9375\n",
      "Train Epoch: 10 [12800/50000] Loss: 0.405595 Acc: 0.8750\n",
      "Train Epoch: 10 [14400/50000] Loss: 0.636437 Acc: 0.9375\n",
      "Train Epoch: 10 [16000/50000] Loss: 0.472576 Acc: 0.8750\n",
      "Train Epoch: 10 [17600/50000] Loss: 0.690432 Acc: 0.5625\n",
      "Train Epoch: 10 [19200/50000] Loss: 0.462654 Acc: 0.8125\n",
      "Train Epoch: 10 [20800/50000] Loss: 0.616191 Acc: 0.8125\n",
      "Train Epoch: 10 [22400/50000] Loss: 0.133269 Acc: 1.0000\n",
      "Train Epoch: 10 [24000/50000] Loss: 0.615546 Acc: 0.8125\n",
      "Train Epoch: 10 [25600/50000] Loss: 0.775597 Acc: 0.7500\n",
      "Train Epoch: 10 [27200/50000] Loss: 0.326208 Acc: 0.8125\n",
      "Train Epoch: 10 [28800/50000] Loss: 0.927378 Acc: 0.6875\n",
      "Train Epoch: 10 [30400/50000] Loss: 0.443745 Acc: 0.8750\n",
      "Train Epoch: 10 [32000/50000] Loss: 0.341426 Acc: 0.9375\n",
      "Train Epoch: 10 [33600/50000] Loss: 0.086716 Acc: 1.0000\n",
      "Train Epoch: 10 [35200/50000] Loss: 0.648667 Acc: 0.7500\n",
      "Train Epoch: 10 [36800/50000] Loss: 0.522900 Acc: 0.8750\n",
      "Train Epoch: 10 [38400/50000] Loss: 0.262213 Acc: 0.9375\n",
      "Train Epoch: 10 [40000/50000] Loss: 0.194182 Acc: 1.0000\n",
      "Train Epoch: 10 [41600/50000] Loss: 0.354120 Acc: 0.9375\n",
      "Train Epoch: 10 [43200/50000] Loss: 0.352154 Acc: 0.8125\n",
      "Train Epoch: 10 [44800/50000] Loss: 0.119439 Acc: 1.0000\n",
      "Train Epoch: 10 [46400/50000] Loss: 0.380951 Acc: 0.8125\n",
      "Train Epoch: 10 [48000/50000] Loss: 0.494445 Acc: 0.8125\n",
      "Train Epoch: 10 [49600/50000] Loss: 0.212215 Acc: 0.9375\n",
      "Elapsed 452.83s, 41.17 s/epoch, 0.01 s/batch, ets 1605.47s\n",
      "\n",
      "Test set: Average loss: 0.7942, Accuracy: 7481/10000 (75%)\n",
      "\n",
      "Accuracy improved, saving the model.\n",
      "\n",
      "Train Epoch: 11 [1600/50000] Loss: 0.241795 Acc: 0.8750\n",
      "Train Epoch: 11 [3200/50000] Loss: 0.317968 Acc: 0.8750\n",
      "Train Epoch: 11 [4800/50000] Loss: 0.612312 Acc: 0.7500\n",
      "Train Epoch: 11 [6400/50000] Loss: 0.388011 Acc: 0.9375\n",
      "Train Epoch: 11 [8000/50000] Loss: 0.176186 Acc: 1.0000\n",
      "Train Epoch: 11 [9600/50000] Loss: 0.832539 Acc: 0.7500\n",
      "Train Epoch: 11 [11200/50000] Loss: 0.467492 Acc: 0.8125\n",
      "Train Epoch: 11 [12800/50000] Loss: 0.747568 Acc: 0.7500\n",
      "Train Epoch: 11 [14400/50000] Loss: 0.136503 Acc: 1.0000\n",
      "Train Epoch: 11 [16000/50000] Loss: 0.262458 Acc: 0.9375\n",
      "Train Epoch: 11 [17600/50000] Loss: 0.416288 Acc: 0.8750\n",
      "Train Epoch: 11 [19200/50000] Loss: 0.556922 Acc: 0.8125\n",
      "Train Epoch: 11 [20800/50000] Loss: 0.436389 Acc: 0.9375\n",
      "Train Epoch: 11 [22400/50000] Loss: 1.032673 Acc: 0.6250\n",
      "Train Epoch: 11 [24000/50000] Loss: 0.320572 Acc: 0.8750\n",
      "Train Epoch: 11 [25600/50000] Loss: 0.261278 Acc: 0.8750\n",
      "Train Epoch: 11 [27200/50000] Loss: 0.328536 Acc: 0.8125\n",
      "Train Epoch: 11 [28800/50000] Loss: 0.635667 Acc: 0.6875\n",
      "Train Epoch: 11 [30400/50000] Loss: 0.469193 Acc: 0.8125\n",
      "Train Epoch: 11 [32000/50000] Loss: 0.389777 Acc: 0.8750\n",
      "Train Epoch: 11 [33600/50000] Loss: 0.139329 Acc: 0.9375\n",
      "Train Epoch: 11 [35200/50000] Loss: 0.257491 Acc: 0.9375\n",
      "Train Epoch: 11 [36800/50000] Loss: 0.763843 Acc: 0.6250\n",
      "Train Epoch: 11 [38400/50000] Loss: 0.342747 Acc: 0.8750\n",
      "Train Epoch: 11 [40000/50000] Loss: 0.421910 Acc: 0.8125\n",
      "Train Epoch: 11 [41600/50000] Loss: 0.379602 Acc: 0.8125\n",
      "Train Epoch: 11 [43200/50000] Loss: 0.227127 Acc: 0.9375\n",
      "Train Epoch: 11 [44800/50000] Loss: 0.279268 Acc: 0.9375\n",
      "Train Epoch: 11 [46400/50000] Loss: 0.326626 Acc: 0.8750\n",
      "Train Epoch: 11 [48000/50000] Loss: 0.282337 Acc: 0.8125\n",
      "Train Epoch: 11 [49600/50000] Loss: 0.308058 Acc: 0.8750\n",
      "Elapsed 493.87s, 41.16 s/epoch, 0.01 s/batch, ets 1563.93s\n",
      "\n",
      "Test set: Average loss: 0.8639, Accuracy: 7394/10000 (74%)\n",
      "\n",
      "Train Epoch: 12 [1600/50000] Loss: 0.243714 Acc: 0.8750\n",
      "Train Epoch: 12 [3200/50000] Loss: 0.321612 Acc: 0.8750\n",
      "Train Epoch: 12 [4800/50000] Loss: 0.523450 Acc: 0.8125\n",
      "Train Epoch: 12 [6400/50000] Loss: 0.207806 Acc: 0.9375\n",
      "Train Epoch: 12 [8000/50000] Loss: 0.583221 Acc: 0.8125\n",
      "Train Epoch: 12 [9600/50000] Loss: 0.444690 Acc: 0.8125\n",
      "Train Epoch: 12 [11200/50000] Loss: 0.086762 Acc: 1.0000\n",
      "Train Epoch: 12 [12800/50000] Loss: 0.285494 Acc: 0.8750\n",
      "Train Epoch: 12 [14400/50000] Loss: 0.304995 Acc: 0.9375\n",
      "Train Epoch: 12 [16000/50000] Loss: 0.201974 Acc: 0.9375\n",
      "Train Epoch: 12 [17600/50000] Loss: 0.260823 Acc: 0.9375\n",
      "Train Epoch: 12 [19200/50000] Loss: 0.442120 Acc: 0.8750\n",
      "Train Epoch: 12 [20800/50000] Loss: 0.417322 Acc: 0.8125\n",
      "Train Epoch: 12 [22400/50000] Loss: 0.194685 Acc: 0.9375\n",
      "Train Epoch: 12 [24000/50000] Loss: 0.274929 Acc: 0.8750\n",
      "Train Epoch: 12 [25600/50000] Loss: 0.570871 Acc: 0.8125\n",
      "Train Epoch: 12 [27200/50000] Loss: 0.334090 Acc: 0.8125\n",
      "Train Epoch: 12 [28800/50000] Loss: 0.314885 Acc: 0.9375\n",
      "Train Epoch: 12 [30400/50000] Loss: 0.219047 Acc: 0.9375\n",
      "Train Epoch: 12 [32000/50000] Loss: 0.267498 Acc: 0.8750\n",
      "Train Epoch: 12 [33600/50000] Loss: 0.462069 Acc: 0.8750\n",
      "Train Epoch: 12 [35200/50000] Loss: 0.134654 Acc: 1.0000\n",
      "Train Epoch: 12 [36800/50000] Loss: 0.307247 Acc: 0.9375\n",
      "Train Epoch: 12 [38400/50000] Loss: 0.232161 Acc: 0.8750\n",
      "Train Epoch: 12 [40000/50000] Loss: 0.283297 Acc: 0.8125\n",
      "Train Epoch: 12 [41600/50000] Loss: 0.384220 Acc: 0.8750\n",
      "Train Epoch: 12 [43200/50000] Loss: 0.285737 Acc: 0.8750\n",
      "Train Epoch: 12 [44800/50000] Loss: 0.842831 Acc: 0.6875\n",
      "Train Epoch: 12 [46400/50000] Loss: 0.249190 Acc: 0.8750\n",
      "Train Epoch: 12 [48000/50000] Loss: 0.173805 Acc: 1.0000\n",
      "Train Epoch: 12 [49600/50000] Loss: 0.102400 Acc: 1.0000\n",
      "Elapsed 536.59s, 41.28 s/epoch, 0.01 s/batch, ets 1527.21s\n",
      "\n",
      "Test set: Average loss: 0.8787, Accuracy: 7350/10000 (74%)\n",
      "\n",
      "Train Epoch: 13 [1600/50000] Loss: 0.261354 Acc: 0.9375\n",
      "Train Epoch: 13 [3200/50000] Loss: 0.270055 Acc: 0.9375\n",
      "Train Epoch: 13 [4800/50000] Loss: 0.343013 Acc: 0.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 13 [6400/50000] Loss: 0.325646 Acc: 0.8750\n",
      "Train Epoch: 13 [8000/50000] Loss: 0.033328 Acc: 1.0000\n",
      "Train Epoch: 13 [9600/50000] Loss: 0.161405 Acc: 0.9375\n",
      "Train Epoch: 13 [11200/50000] Loss: 0.306059 Acc: 0.9375\n",
      "Train Epoch: 13 [12800/50000] Loss: 0.400662 Acc: 0.8125\n",
      "Train Epoch: 13 [14400/50000] Loss: 0.123098 Acc: 1.0000\n",
      "Train Epoch: 13 [16000/50000] Loss: 0.097191 Acc: 1.0000\n",
      "Train Epoch: 13 [17600/50000] Loss: 0.302581 Acc: 0.8750\n",
      "Train Epoch: 13 [19200/50000] Loss: 0.305100 Acc: 0.8750\n",
      "Train Epoch: 13 [20800/50000] Loss: 0.168395 Acc: 0.9375\n",
      "Train Epoch: 13 [22400/50000] Loss: 0.246277 Acc: 0.9375\n",
      "Train Epoch: 13 [24000/50000] Loss: 0.500830 Acc: 0.9375\n",
      "Train Epoch: 13 [25600/50000] Loss: 0.212789 Acc: 0.9375\n",
      "Train Epoch: 13 [27200/50000] Loss: 0.206435 Acc: 0.9375\n",
      "Train Epoch: 13 [28800/50000] Loss: 0.442061 Acc: 0.8125\n",
      "Train Epoch: 13 [30400/50000] Loss: 0.066516 Acc: 1.0000\n",
      "Train Epoch: 13 [32000/50000] Loss: 0.215412 Acc: 0.9375\n",
      "Train Epoch: 13 [33600/50000] Loss: 0.390673 Acc: 0.8125\n",
      "Train Epoch: 13 [35200/50000] Loss: 0.155444 Acc: 1.0000\n",
      "Train Epoch: 13 [36800/50000] Loss: 0.037099 Acc: 1.0000\n",
      "Train Epoch: 13 [38400/50000] Loss: 0.366148 Acc: 0.9375\n",
      "Train Epoch: 13 [40000/50000] Loss: 0.220759 Acc: 0.9375\n",
      "Train Epoch: 13 [41600/50000] Loss: 0.103038 Acc: 1.0000\n",
      "Train Epoch: 13 [43200/50000] Loss: 0.656846 Acc: 0.8750\n",
      "Train Epoch: 13 [44800/50000] Loss: 0.307415 Acc: 0.8750\n",
      "Train Epoch: 13 [46400/50000] Loss: 0.204207 Acc: 0.8750\n",
      "Train Epoch: 13 [48000/50000] Loss: 0.163335 Acc: 1.0000\n",
      "Train Epoch: 13 [49600/50000] Loss: 0.084304 Acc: 1.0000\n",
      "Elapsed 579.76s, 41.41 s/epoch, 0.01 s/batch, ets 1490.82s\n",
      "\n",
      "Test set: Average loss: 0.8784, Accuracy: 7403/10000 (74%)\n",
      "\n",
      "Train Epoch: 14 [1600/50000] Loss: 0.386298 Acc: 0.8125\n",
      "Train Epoch: 14 [3200/50000] Loss: 0.064163 Acc: 1.0000\n",
      "Train Epoch: 14 [4800/50000] Loss: 0.012271 Acc: 1.0000\n",
      "Train Epoch: 14 [6400/50000] Loss: 0.327926 Acc: 0.8750\n",
      "Train Epoch: 14 [8000/50000] Loss: 0.102096 Acc: 1.0000\n",
      "Train Epoch: 14 [9600/50000] Loss: 0.175580 Acc: 0.9375\n",
      "Train Epoch: 14 [11200/50000] Loss: 0.114163 Acc: 1.0000\n",
      "Train Epoch: 14 [12800/50000] Loss: 0.235596 Acc: 0.9375\n",
      "Train Epoch: 14 [14400/50000] Loss: 0.144342 Acc: 0.8750\n",
      "Train Epoch: 14 [16000/50000] Loss: 0.177758 Acc: 0.9375\n",
      "Train Epoch: 14 [17600/50000] Loss: 0.318536 Acc: 0.9375\n",
      "Train Epoch: 14 [19200/50000] Loss: 0.415769 Acc: 0.9375\n",
      "Train Epoch: 14 [20800/50000] Loss: 0.173147 Acc: 0.8750\n",
      "Train Epoch: 14 [22400/50000] Loss: 0.299740 Acc: 0.9375\n",
      "Train Epoch: 14 [24000/50000] Loss: 0.397315 Acc: 0.9375\n",
      "Train Epoch: 14 [25600/50000] Loss: 0.092715 Acc: 0.9375\n",
      "Train Epoch: 14 [27200/50000] Loss: 0.755539 Acc: 0.8125\n",
      "Train Epoch: 14 [28800/50000] Loss: 0.261547 Acc: 0.8125\n",
      "Train Epoch: 14 [30400/50000] Loss: 0.176292 Acc: 0.9375\n",
      "Train Epoch: 14 [32000/50000] Loss: 0.115111 Acc: 0.9375\n",
      "Train Epoch: 14 [33600/50000] Loss: 0.511906 Acc: 0.8750\n",
      "Train Epoch: 14 [35200/50000] Loss: 0.328065 Acc: 0.8125\n",
      "Train Epoch: 14 [36800/50000] Loss: 0.191398 Acc: 0.8750\n",
      "Train Epoch: 14 [38400/50000] Loss: 0.556637 Acc: 0.8125\n",
      "Train Epoch: 14 [40000/50000] Loss: 0.340543 Acc: 0.8750\n",
      "Train Epoch: 14 [41600/50000] Loss: 0.305681 Acc: 0.8750\n",
      "Train Epoch: 14 [43200/50000] Loss: 0.446664 Acc: 0.8125\n",
      "Train Epoch: 14 [44800/50000] Loss: 0.123013 Acc: 1.0000\n",
      "Train Epoch: 14 [46400/50000] Loss: 0.433680 Acc: 0.8750\n",
      "Train Epoch: 14 [48000/50000] Loss: 0.403649 Acc: 0.8125\n",
      "Train Epoch: 14 [49600/50000] Loss: 0.462623 Acc: 0.8750\n",
      "Elapsed 623.29s, 41.55 s/epoch, 0.01 s/batch, ets 1454.34s\n",
      "\n",
      "Test set: Average loss: 0.9393, Accuracy: 7375/10000 (74%)\n",
      "\n",
      "Train Epoch: 15 [1600/50000] Loss: 0.056809 Acc: 1.0000\n",
      "Train Epoch: 15 [3200/50000] Loss: 0.117712 Acc: 0.9375\n",
      "Train Epoch: 15 [4800/50000] Loss: 0.048596 Acc: 1.0000\n",
      "Train Epoch: 15 [6400/50000] Loss: 0.257073 Acc: 0.9375\n",
      "Train Epoch: 15 [8000/50000] Loss: 0.165100 Acc: 1.0000\n",
      "Train Epoch: 15 [9600/50000] Loss: 0.689640 Acc: 0.7500\n",
      "Train Epoch: 15 [11200/50000] Loss: 0.190772 Acc: 0.9375\n",
      "Train Epoch: 15 [12800/50000] Loss: 0.355612 Acc: 0.8750\n",
      "Train Epoch: 15 [14400/50000] Loss: 0.202533 Acc: 1.0000\n",
      "Train Epoch: 15 [16000/50000] Loss: 0.055411 Acc: 1.0000\n",
      "Train Epoch: 15 [17600/50000] Loss: 0.273056 Acc: 0.8750\n",
      "Train Epoch: 15 [19200/50000] Loss: 0.135967 Acc: 0.9375\n",
      "Train Epoch: 15 [20800/50000] Loss: 0.722033 Acc: 0.6875\n",
      "Train Epoch: 15 [22400/50000] Loss: 0.296574 Acc: 0.8750\n",
      "Train Epoch: 15 [24000/50000] Loss: 0.223901 Acc: 0.9375\n",
      "Train Epoch: 15 [25600/50000] Loss: 0.182563 Acc: 0.9375\n",
      "Train Epoch: 15 [27200/50000] Loss: 0.048440 Acc: 1.0000\n",
      "Train Epoch: 15 [28800/50000] Loss: 0.258888 Acc: 0.8750\n",
      "Train Epoch: 15 [30400/50000] Loss: 0.114275 Acc: 0.9375\n",
      "Train Epoch: 15 [32000/50000] Loss: 0.212022 Acc: 0.8750\n",
      "Train Epoch: 15 [33600/50000] Loss: 0.244482 Acc: 0.8750\n",
      "Train Epoch: 15 [35200/50000] Loss: 0.188488 Acc: 0.9375\n",
      "Train Epoch: 15 [36800/50000] Loss: 0.136875 Acc: 0.9375\n",
      "Train Epoch: 15 [38400/50000] Loss: 0.277036 Acc: 0.8750\n",
      "Train Epoch: 15 [40000/50000] Loss: 0.227984 Acc: 0.9375\n",
      "Train Epoch: 15 [41600/50000] Loss: 0.624011 Acc: 0.7500\n",
      "Train Epoch: 15 [43200/50000] Loss: 0.474142 Acc: 0.9375\n",
      "Train Epoch: 15 [44800/50000] Loss: 0.059870 Acc: 1.0000\n",
      "Train Epoch: 15 [46400/50000] Loss: 0.076265 Acc: 1.0000\n",
      "Train Epoch: 15 [48000/50000] Loss: 0.287005 Acc: 0.9375\n",
      "Train Epoch: 15 [49600/50000] Loss: 0.325567 Acc: 0.8125\n",
      "Elapsed 666.27s, 41.64 s/epoch, 0.01 s/batch, ets 1415.83s\n",
      "\n",
      "Test set: Average loss: 0.9709, Accuracy: 7364/10000 (74%)\n",
      "\n",
      "Train Epoch: 16 [1600/50000] Loss: 0.037936 Acc: 1.0000\n",
      "Train Epoch: 16 [3200/50000] Loss: 0.180818 Acc: 1.0000\n",
      "Train Epoch: 16 [4800/50000] Loss: 0.173621 Acc: 0.9375\n",
      "Train Epoch: 16 [6400/50000] Loss: 0.135860 Acc: 1.0000\n",
      "Train Epoch: 16 [8000/50000] Loss: 0.014448 Acc: 1.0000\n",
      "Train Epoch: 16 [9600/50000] Loss: 0.158373 Acc: 0.9375\n",
      "Train Epoch: 16 [11200/50000] Loss: 0.298045 Acc: 0.8750\n",
      "Train Epoch: 16 [12800/50000] Loss: 0.107375 Acc: 1.0000\n",
      "Train Epoch: 16 [14400/50000] Loss: 0.076440 Acc: 1.0000\n",
      "Train Epoch: 16 [16000/50000] Loss: 0.380842 Acc: 0.8750\n",
      "Train Epoch: 16 [17600/50000] Loss: 0.020654 Acc: 1.0000\n",
      "Train Epoch: 16 [19200/50000] Loss: 0.237075 Acc: 0.8750\n",
      "Train Epoch: 16 [20800/50000] Loss: 0.573376 Acc: 0.7500\n",
      "Train Epoch: 16 [22400/50000] Loss: 0.429638 Acc: 0.8125\n",
      "Train Epoch: 16 [24000/50000] Loss: 0.039022 Acc: 1.0000\n",
      "Train Epoch: 16 [25600/50000] Loss: 0.482986 Acc: 0.8750\n",
      "Train Epoch: 16 [27200/50000] Loss: 0.223798 Acc: 0.8750\n",
      "Train Epoch: 16 [28800/50000] Loss: 0.186461 Acc: 0.9375\n",
      "Train Epoch: 16 [30400/50000] Loss: 0.061632 Acc: 1.0000\n",
      "Train Epoch: 16 [32000/50000] Loss: 0.154811 Acc: 0.9375\n",
      "Train Epoch: 16 [33600/50000] Loss: 0.348188 Acc: 0.9375\n",
      "Train Epoch: 16 [35200/50000] Loss: 0.076483 Acc: 1.0000\n",
      "Train Epoch: 16 [36800/50000] Loss: 0.201027 Acc: 0.9375\n",
      "Train Epoch: 16 [38400/50000] Loss: 0.408428 Acc: 0.8750\n",
      "Train Epoch: 16 [40000/50000] Loss: 0.088142 Acc: 1.0000\n",
      "Train Epoch: 16 [41600/50000] Loss: 0.576586 Acc: 0.7500\n",
      "Train Epoch: 16 [43200/50000] Loss: 0.181833 Acc: 0.9375\n",
      "Train Epoch: 16 [44800/50000] Loss: 0.387233 Acc: 0.8750\n",
      "Train Epoch: 16 [46400/50000] Loss: 0.142219 Acc: 1.0000\n",
      "Train Epoch: 16 [48000/50000] Loss: 0.454110 Acc: 0.8750\n",
      "Train Epoch: 16 [49600/50000] Loss: 0.216615 Acc: 0.9375\n",
      "Elapsed 708.88s, 41.70 s/epoch, 0.01 s/batch, ets 1376.07s\n",
      "\n",
      "Test set: Average loss: 1.0502, Accuracy: 7339/10000 (73%)\n",
      "\n",
      "Train Epoch: 17 [1600/50000] Loss: 0.212302 Acc: 0.9375\n",
      "Train Epoch: 17 [3200/50000] Loss: 0.059793 Acc: 1.0000\n",
      "Train Epoch: 17 [4800/50000] Loss: 0.101920 Acc: 0.9375\n",
      "Train Epoch: 17 [6400/50000] Loss: 0.074996 Acc: 0.9375\n",
      "Train Epoch: 17 [8000/50000] Loss: 0.063912 Acc: 1.0000\n",
      "Train Epoch: 17 [9600/50000] Loss: 0.055546 Acc: 1.0000\n",
      "Train Epoch: 17 [11200/50000] Loss: 0.116273 Acc: 0.9375\n",
      "Train Epoch: 17 [12800/50000] Loss: 0.181718 Acc: 0.9375\n",
      "Train Epoch: 17 [14400/50000] Loss: 0.113297 Acc: 1.0000\n",
      "Train Epoch: 17 [16000/50000] Loss: 0.166150 Acc: 0.8750\n",
      "Train Epoch: 17 [17600/50000] Loss: 0.399610 Acc: 0.9375\n",
      "Train Epoch: 17 [19200/50000] Loss: 0.233055 Acc: 0.9375\n",
      "Train Epoch: 17 [20800/50000] Loss: 0.101671 Acc: 0.9375\n",
      "Train Epoch: 17 [22400/50000] Loss: 0.114168 Acc: 0.9375\n",
      "Train Epoch: 17 [24000/50000] Loss: 0.323439 Acc: 0.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 17 [25600/50000] Loss: 0.128678 Acc: 0.9375\n",
      "Train Epoch: 17 [27200/50000] Loss: 0.136409 Acc: 0.9375\n",
      "Train Epoch: 17 [28800/50000] Loss: 0.025574 Acc: 1.0000\n",
      "Train Epoch: 17 [30400/50000] Loss: 0.147291 Acc: 0.9375\n",
      "Train Epoch: 17 [32000/50000] Loss: 1.000519 Acc: 0.7500\n",
      "Train Epoch: 17 [33600/50000] Loss: 0.036195 Acc: 1.0000\n",
      "Train Epoch: 17 [35200/50000] Loss: 0.127229 Acc: 0.9375\n",
      "Train Epoch: 17 [36800/50000] Loss: 0.528952 Acc: 0.7500\n",
      "Train Epoch: 17 [38400/50000] Loss: 0.156890 Acc: 0.9375\n",
      "Train Epoch: 17 [40000/50000] Loss: 0.055727 Acc: 1.0000\n",
      "Train Epoch: 17 [41600/50000] Loss: 0.260902 Acc: 0.8125\n",
      "Train Epoch: 17 [43200/50000] Loss: 0.142522 Acc: 0.9375\n",
      "Train Epoch: 17 [44800/50000] Loss: 0.239633 Acc: 0.9375\n",
      "Train Epoch: 17 [46400/50000] Loss: 0.194237 Acc: 0.9375\n",
      "Train Epoch: 17 [48000/50000] Loss: 0.236111 Acc: 0.9375\n",
      "Train Epoch: 17 [49600/50000] Loss: 0.090618 Acc: 0.9375\n",
      "Elapsed 752.37s, 41.80 s/epoch, 0.01 s/batch, ets 1337.54s\n",
      "\n",
      "Test set: Average loss: 1.0998, Accuracy: 7313/10000 (73%)\n",
      "\n",
      "Train Epoch: 18 [1600/50000] Loss: 0.071008 Acc: 1.0000\n",
      "Train Epoch: 18 [3200/50000] Loss: 0.204124 Acc: 0.9375\n",
      "Train Epoch: 18 [4800/50000] Loss: 0.197748 Acc: 0.9375\n",
      "Train Epoch: 18 [6400/50000] Loss: 0.231446 Acc: 0.8750\n",
      "Train Epoch: 18 [8000/50000] Loss: 0.039504 Acc: 1.0000\n",
      "Train Epoch: 18 [9600/50000] Loss: 0.091596 Acc: 1.0000\n",
      "Train Epoch: 18 [11200/50000] Loss: 0.052747 Acc: 1.0000\n",
      "Train Epoch: 18 [12800/50000] Loss: 0.180893 Acc: 0.9375\n",
      "Train Epoch: 18 [14400/50000] Loss: 0.041540 Acc: 1.0000\n",
      "Train Epoch: 18 [16000/50000] Loss: 0.103237 Acc: 1.0000\n",
      "Train Epoch: 18 [17600/50000] Loss: 0.037027 Acc: 1.0000\n",
      "Train Epoch: 18 [19200/50000] Loss: 0.015714 Acc: 1.0000\n",
      "Train Epoch: 18 [20800/50000] Loss: 0.035673 Acc: 1.0000\n",
      "Train Epoch: 18 [22400/50000] Loss: 0.050280 Acc: 1.0000\n",
      "Train Epoch: 18 [24000/50000] Loss: 0.151045 Acc: 0.9375\n",
      "Train Epoch: 18 [25600/50000] Loss: 0.153701 Acc: 0.9375\n",
      "Train Epoch: 18 [27200/50000] Loss: 0.102013 Acc: 0.9375\n",
      "Train Epoch: 18 [28800/50000] Loss: 0.117128 Acc: 0.8750\n",
      "Train Epoch: 18 [30400/50000] Loss: 0.091184 Acc: 0.9375\n",
      "Train Epoch: 18 [32000/50000] Loss: 0.088135 Acc: 0.9375\n",
      "Train Epoch: 18 [33600/50000] Loss: 0.013974 Acc: 1.0000\n",
      "Train Epoch: 18 [35200/50000] Loss: 0.122892 Acc: 0.9375\n",
      "Train Epoch: 18 [36800/50000] Loss: 0.044331 Acc: 1.0000\n",
      "Train Epoch: 18 [38400/50000] Loss: 0.052430 Acc: 1.0000\n",
      "Train Epoch: 18 [40000/50000] Loss: 0.126147 Acc: 0.9375\n",
      "Train Epoch: 18 [41600/50000] Loss: 0.046610 Acc: 1.0000\n",
      "Train Epoch: 18 [43200/50000] Loss: 0.078365 Acc: 1.0000\n",
      "Train Epoch: 18 [44800/50000] Loss: 0.267935 Acc: 0.9375\n",
      "Train Epoch: 18 [46400/50000] Loss: 0.044867 Acc: 1.0000\n",
      "Train Epoch: 18 [48000/50000] Loss: 0.041174 Acc: 1.0000\n",
      "Train Epoch: 18 [49600/50000] Loss: 0.116464 Acc: 1.0000\n",
      "Elapsed 794.63s, 41.82 s/epoch, 0.01 s/batch, ets 1296.50s\n",
      "\n",
      "Test set: Average loss: 1.0983, Accuracy: 7386/10000 (74%)\n",
      "\n",
      "Train Epoch: 19 [1600/50000] Loss: 0.041842 Acc: 1.0000\n",
      "Train Epoch: 19 [3200/50000] Loss: 0.065725 Acc: 1.0000\n",
      "Train Epoch: 19 [4800/50000] Loss: 0.178509 Acc: 0.9375\n",
      "Train Epoch: 19 [6400/50000] Loss: 0.070473 Acc: 1.0000\n",
      "Train Epoch: 19 [8000/50000] Loss: 0.053875 Acc: 1.0000\n",
      "Train Epoch: 19 [9600/50000] Loss: 0.008856 Acc: 1.0000\n",
      "Train Epoch: 19 [11200/50000] Loss: 0.206746 Acc: 0.9375\n",
      "Train Epoch: 19 [12800/50000] Loss: 0.202467 Acc: 0.8750\n",
      "Train Epoch: 19 [14400/50000] Loss: 0.072459 Acc: 1.0000\n",
      "Train Epoch: 19 [16000/50000] Loss: 0.021169 Acc: 1.0000\n",
      "Train Epoch: 19 [17600/50000] Loss: 0.182582 Acc: 1.0000\n",
      "Train Epoch: 19 [19200/50000] Loss: 0.022775 Acc: 1.0000\n",
      "Train Epoch: 19 [20800/50000] Loss: 0.110126 Acc: 0.9375\n",
      "Train Epoch: 19 [22400/50000] Loss: 0.095634 Acc: 0.9375\n",
      "Train Epoch: 19 [24000/50000] Loss: 0.068310 Acc: 1.0000\n",
      "Train Epoch: 19 [25600/50000] Loss: 0.169979 Acc: 0.9375\n",
      "Train Epoch: 19 [27200/50000] Loss: 0.061304 Acc: 1.0000\n",
      "Train Epoch: 19 [28800/50000] Loss: 0.086080 Acc: 0.9375\n",
      "Train Epoch: 19 [30400/50000] Loss: 0.492167 Acc: 0.9375\n",
      "Train Epoch: 19 [32000/50000] Loss: 0.157341 Acc: 0.9375\n",
      "Train Epoch: 19 [33600/50000] Loss: 0.125686 Acc: 1.0000\n",
      "Train Epoch: 19 [35200/50000] Loss: 0.011542 Acc: 1.0000\n",
      "Train Epoch: 19 [36800/50000] Loss: 0.288777 Acc: 0.9375\n",
      "Train Epoch: 19 [38400/50000] Loss: 0.119369 Acc: 0.9375\n",
      "Train Epoch: 19 [40000/50000] Loss: 0.034059 Acc: 1.0000\n",
      "Train Epoch: 19 [41600/50000] Loss: 0.193728 Acc: 0.9375\n",
      "Train Epoch: 19 [43200/50000] Loss: 0.219402 Acc: 0.8750\n",
      "Train Epoch: 19 [44800/50000] Loss: 0.166173 Acc: 0.9375\n",
      "Train Epoch: 19 [46400/50000] Loss: 0.110071 Acc: 1.0000\n",
      "Train Epoch: 19 [48000/50000] Loss: 0.007996 Acc: 1.0000\n",
      "Train Epoch: 19 [49600/50000] Loss: 0.085970 Acc: 0.9375\n",
      "Elapsed 838.10s, 41.90 s/epoch, 0.01 s/batch, ets 1257.14s\n",
      "\n",
      "Test set: Average loss: 1.1330, Accuracy: 7381/10000 (74%)\n",
      "\n",
      "Train Epoch: 20 [1600/50000] Loss: 0.222075 Acc: 0.8750\n",
      "Train Epoch: 20 [3200/50000] Loss: 0.190839 Acc: 0.8750\n",
      "Train Epoch: 20 [4800/50000] Loss: 0.108987 Acc: 0.9375\n",
      "Train Epoch: 20 [6400/50000] Loss: 0.047099 Acc: 1.0000\n",
      "Train Epoch: 20 [8000/50000] Loss: 0.165516 Acc: 0.8750\n",
      "Train Epoch: 20 [9600/50000] Loss: 0.005657 Acc: 1.0000\n",
      "Train Epoch: 20 [11200/50000] Loss: 0.110573 Acc: 0.9375\n",
      "Train Epoch: 20 [12800/50000] Loss: 0.124131 Acc: 0.9375\n",
      "Train Epoch: 20 [14400/50000] Loss: 0.085921 Acc: 0.9375\n",
      "Train Epoch: 20 [16000/50000] Loss: 0.130358 Acc: 0.9375\n",
      "Train Epoch: 20 [17600/50000] Loss: 0.012955 Acc: 1.0000\n",
      "Train Epoch: 20 [19200/50000] Loss: 0.220232 Acc: 0.8750\n",
      "Train Epoch: 20 [20800/50000] Loss: 0.014348 Acc: 1.0000\n",
      "Train Epoch: 20 [22400/50000] Loss: 0.389870 Acc: 0.8750\n",
      "Train Epoch: 20 [24000/50000] Loss: 0.277099 Acc: 0.8125\n",
      "Train Epoch: 20 [25600/50000] Loss: 0.014778 Acc: 1.0000\n",
      "Train Epoch: 20 [27200/50000] Loss: 0.019440 Acc: 1.0000\n",
      "Train Epoch: 20 [28800/50000] Loss: 0.069944 Acc: 1.0000\n",
      "Train Epoch: 20 [30400/50000] Loss: 0.099219 Acc: 1.0000\n",
      "Train Epoch: 20 [32000/50000] Loss: 0.237600 Acc: 0.8750\n",
      "Train Epoch: 20 [33600/50000] Loss: 0.521224 Acc: 0.8750\n",
      "Train Epoch: 20 [35200/50000] Loss: 0.046755 Acc: 1.0000\n",
      "Train Epoch: 20 [36800/50000] Loss: 0.124158 Acc: 1.0000\n",
      "Train Epoch: 20 [38400/50000] Loss: 0.061191 Acc: 1.0000\n",
      "Train Epoch: 20 [40000/50000] Loss: 0.180714 Acc: 0.9375\n",
      "Train Epoch: 20 [41600/50000] Loss: 0.458985 Acc: 0.7500\n",
      "Train Epoch: 20 [43200/50000] Loss: 0.054148 Acc: 1.0000\n",
      "Train Epoch: 20 [44800/50000] Loss: 0.037949 Acc: 1.0000\n",
      "Train Epoch: 20 [46400/50000] Loss: 0.628510 Acc: 0.9375\n",
      "Train Epoch: 20 [48000/50000] Loss: 0.004804 Acc: 1.0000\n",
      "Train Epoch: 20 [49600/50000] Loss: 0.181077 Acc: 0.9375\n",
      "Elapsed 879.73s, 41.89 s/epoch, 0.01 s/batch, ets 1214.87s\n",
      "\n",
      "Test set: Average loss: 1.2334, Accuracy: 7349/10000 (73%)\n",
      "\n",
      "Train Epoch: 21 [1600/50000] Loss: 0.013593 Acc: 1.0000\n",
      "Train Epoch: 21 [3200/50000] Loss: 0.017774 Acc: 1.0000\n",
      "Train Epoch: 21 [4800/50000] Loss: 0.013000 Acc: 1.0000\n",
      "Train Epoch: 21 [6400/50000] Loss: 0.100650 Acc: 1.0000\n",
      "Train Epoch: 21 [8000/50000] Loss: 0.244196 Acc: 0.9375\n",
      "Train Epoch: 21 [9600/50000] Loss: 0.025800 Acc: 1.0000\n",
      "Train Epoch: 21 [11200/50000] Loss: 0.097588 Acc: 1.0000\n",
      "Train Epoch: 21 [12800/50000] Loss: 0.193844 Acc: 0.8750\n",
      "Train Epoch: 21 [14400/50000] Loss: 0.043662 Acc: 1.0000\n",
      "Train Epoch: 21 [16000/50000] Loss: 0.034660 Acc: 1.0000\n",
      "Train Epoch: 21 [17600/50000] Loss: 0.039792 Acc: 1.0000\n",
      "Train Epoch: 21 [19200/50000] Loss: 0.010983 Acc: 1.0000\n",
      "Train Epoch: 21 [20800/50000] Loss: 0.032916 Acc: 1.0000\n",
      "Train Epoch: 21 [22400/50000] Loss: 0.097152 Acc: 0.9375\n",
      "Train Epoch: 21 [24000/50000] Loss: 0.258746 Acc: 0.8750\n",
      "Train Epoch: 21 [25600/50000] Loss: 0.032542 Acc: 1.0000\n",
      "Train Epoch: 21 [27200/50000] Loss: 0.088688 Acc: 1.0000\n",
      "Train Epoch: 21 [28800/50000] Loss: 0.038450 Acc: 1.0000\n",
      "Train Epoch: 21 [30400/50000] Loss: 0.088622 Acc: 0.9375\n",
      "Train Epoch: 21 [32000/50000] Loss: 0.040258 Acc: 1.0000\n",
      "Train Epoch: 21 [33600/50000] Loss: 0.059276 Acc: 1.0000\n",
      "Train Epoch: 21 [35200/50000] Loss: 0.062447 Acc: 1.0000\n",
      "Train Epoch: 21 [36800/50000] Loss: 0.250904 Acc: 0.9375\n",
      "Train Epoch: 21 [38400/50000] Loss: 0.153524 Acc: 0.9375\n",
      "Train Epoch: 21 [40000/50000] Loss: 0.010768 Acc: 1.0000\n",
      "Train Epoch: 21 [41600/50000] Loss: 0.008984 Acc: 1.0000\n",
      "Train Epoch: 21 [43200/50000] Loss: 0.214887 Acc: 0.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 21 [44800/50000] Loss: 0.267050 Acc: 0.8750\n",
      "Train Epoch: 21 [46400/50000] Loss: 0.022707 Acc: 1.0000\n",
      "Train Epoch: 21 [48000/50000] Loss: 0.102011 Acc: 1.0000\n",
      "Train Epoch: 21 [49600/50000] Loss: 0.119474 Acc: 0.9375\n",
      "Elapsed 919.87s, 41.81 s/epoch, 0.01 s/batch, ets 1170.74s\n",
      "\n",
      "Test set: Average loss: 1.2776, Accuracy: 7303/10000 (73%)\n",
      "\n",
      "Train Epoch: 22 [1600/50000] Loss: 0.039373 Acc: 1.0000\n",
      "Train Epoch: 22 [3200/50000] Loss: 0.029210 Acc: 1.0000\n",
      "Train Epoch: 22 [4800/50000] Loss: 0.044001 Acc: 1.0000\n",
      "Train Epoch: 22 [6400/50000] Loss: 0.079140 Acc: 1.0000\n",
      "Train Epoch: 22 [8000/50000] Loss: 0.208172 Acc: 0.8750\n",
      "Train Epoch: 22 [9600/50000] Loss: 0.038680 Acc: 1.0000\n",
      "Train Epoch: 22 [11200/50000] Loss: 0.038716 Acc: 1.0000\n",
      "Train Epoch: 22 [12800/50000] Loss: 0.026845 Acc: 1.0000\n",
      "Train Epoch: 22 [14400/50000] Loss: 0.082312 Acc: 0.9375\n",
      "Train Epoch: 22 [16000/50000] Loss: 0.174433 Acc: 0.9375\n",
      "Train Epoch: 22 [17600/50000] Loss: 0.062996 Acc: 0.9375\n",
      "Train Epoch: 22 [19200/50000] Loss: 0.098528 Acc: 1.0000\n",
      "Train Epoch: 22 [20800/50000] Loss: 0.046533 Acc: 1.0000\n",
      "Train Epoch: 22 [22400/50000] Loss: 0.033884 Acc: 1.0000\n",
      "Train Epoch: 22 [24000/50000] Loss: 0.415237 Acc: 0.8125\n",
      "Train Epoch: 22 [25600/50000] Loss: 0.055002 Acc: 1.0000\n",
      "Train Epoch: 22 [27200/50000] Loss: 0.058031 Acc: 1.0000\n",
      "Train Epoch: 22 [28800/50000] Loss: 0.164691 Acc: 0.9375\n",
      "Train Epoch: 22 [30400/50000] Loss: 0.279760 Acc: 0.8125\n",
      "Train Epoch: 22 [32000/50000] Loss: 0.013544 Acc: 1.0000\n",
      "Train Epoch: 22 [33600/50000] Loss: 0.088340 Acc: 0.9375\n",
      "Train Epoch: 22 [35200/50000] Loss: 0.222854 Acc: 0.9375\n",
      "Train Epoch: 22 [36800/50000] Loss: 0.235305 Acc: 0.9375\n",
      "Train Epoch: 22 [38400/50000] Loss: 0.041834 Acc: 1.0000\n",
      "Train Epoch: 22 [40000/50000] Loss: 0.041433 Acc: 1.0000\n",
      "Train Epoch: 22 [41600/50000] Loss: 0.140512 Acc: 0.9375\n",
      "Train Epoch: 22 [43200/50000] Loss: 0.292025 Acc: 0.8125\n",
      "Train Epoch: 22 [44800/50000] Loss: 0.010786 Acc: 1.0000\n",
      "Train Epoch: 22 [46400/50000] Loss: 0.232307 Acc: 0.8750\n",
      "Train Epoch: 22 [48000/50000] Loss: 0.023183 Acc: 1.0000\n",
      "Train Epoch: 22 [49600/50000] Loss: 0.049941 Acc: 1.0000\n",
      "Elapsed 964.00s, 41.91 s/epoch, 0.01 s/batch, ets 1131.65s\n",
      "\n",
      "Test set: Average loss: 1.2386, Accuracy: 7416/10000 (74%)\n",
      "\n",
      "Train Epoch: 23 [1600/50000] Loss: 0.256417 Acc: 0.9375\n",
      "Train Epoch: 23 [3200/50000] Loss: 0.014760 Acc: 1.0000\n",
      "Train Epoch: 23 [4800/50000] Loss: 0.026121 Acc: 1.0000\n",
      "Train Epoch: 23 [6400/50000] Loss: 0.025052 Acc: 1.0000\n",
      "Train Epoch: 23 [8000/50000] Loss: 0.022969 Acc: 1.0000\n",
      "Train Epoch: 23 [9600/50000] Loss: 0.008496 Acc: 1.0000\n",
      "Train Epoch: 23 [11200/50000] Loss: 0.234662 Acc: 0.8750\n",
      "Train Epoch: 23 [12800/50000] Loss: 0.036247 Acc: 1.0000\n",
      "Train Epoch: 23 [14400/50000] Loss: 0.029906 Acc: 1.0000\n",
      "Train Epoch: 23 [16000/50000] Loss: 0.014506 Acc: 1.0000\n",
      "Train Epoch: 23 [17600/50000] Loss: 0.056949 Acc: 1.0000\n",
      "Train Epoch: 23 [19200/50000] Loss: 0.060310 Acc: 1.0000\n",
      "Train Epoch: 23 [20800/50000] Loss: 0.228458 Acc: 0.9375\n",
      "Train Epoch: 23 [22400/50000] Loss: 0.106898 Acc: 0.9375\n",
      "Train Epoch: 23 [24000/50000] Loss: 0.027893 Acc: 1.0000\n",
      "Train Epoch: 23 [25600/50000] Loss: 0.024877 Acc: 1.0000\n",
      "Train Epoch: 23 [27200/50000] Loss: 0.064083 Acc: 0.9375\n",
      "Train Epoch: 23 [28800/50000] Loss: 0.201805 Acc: 0.8750\n",
      "Train Epoch: 23 [30400/50000] Loss: 0.102275 Acc: 0.9375\n",
      "Train Epoch: 23 [32000/50000] Loss: 0.045813 Acc: 1.0000\n",
      "Train Epoch: 23 [33600/50000] Loss: 0.015314 Acc: 1.0000\n",
      "Train Epoch: 23 [35200/50000] Loss: 0.140261 Acc: 1.0000\n",
      "Train Epoch: 23 [36800/50000] Loss: 0.047964 Acc: 1.0000\n",
      "Train Epoch: 23 [38400/50000] Loss: 0.041429 Acc: 1.0000\n",
      "Train Epoch: 23 [40000/50000] Loss: 0.088111 Acc: 0.9375\n",
      "Train Epoch: 23 [41600/50000] Loss: 0.074894 Acc: 0.9375\n",
      "Train Epoch: 23 [43200/50000] Loss: 0.008496 Acc: 1.0000\n",
      "Train Epoch: 23 [44800/50000] Loss: 0.071010 Acc: 1.0000\n",
      "Train Epoch: 23 [46400/50000] Loss: 0.233992 Acc: 0.8125\n",
      "Train Epoch: 23 [48000/50000] Loss: 0.054991 Acc: 0.9375\n",
      "Train Epoch: 23 [49600/50000] Loss: 0.107385 Acc: 0.9375\n",
      "Elapsed 1006.25s, 41.93 s/epoch, 0.01 s/batch, ets 1090.10s\n",
      "\n",
      "Test set: Average loss: 1.3717, Accuracy: 7328/10000 (73%)\n",
      "\n",
      "Train Epoch: 24 [1600/50000] Loss: 0.007238 Acc: 1.0000\n",
      "Train Epoch: 24 [3200/50000] Loss: 0.011037 Acc: 1.0000\n",
      "Train Epoch: 24 [4800/50000] Loss: 0.052065 Acc: 1.0000\n",
      "Train Epoch: 24 [6400/50000] Loss: 0.053117 Acc: 1.0000\n",
      "Train Epoch: 24 [8000/50000] Loss: 0.009238 Acc: 1.0000\n",
      "Train Epoch: 24 [9600/50000] Loss: 0.135389 Acc: 0.9375\n",
      "Train Epoch: 24 [11200/50000] Loss: 0.108315 Acc: 0.9375\n",
      "Train Epoch: 24 [12800/50000] Loss: 0.010048 Acc: 1.0000\n",
      "Train Epoch: 24 [14400/50000] Loss: 0.050105 Acc: 1.0000\n",
      "Train Epoch: 24 [16000/50000] Loss: 0.004258 Acc: 1.0000\n",
      "Train Epoch: 24 [17600/50000] Loss: 0.080846 Acc: 1.0000\n",
      "Train Epoch: 24 [19200/50000] Loss: 0.174485 Acc: 0.9375\n",
      "Train Epoch: 24 [20800/50000] Loss: 0.074110 Acc: 0.9375\n",
      "Train Epoch: 24 [22400/50000] Loss: 0.032209 Acc: 1.0000\n",
      "Train Epoch: 24 [24000/50000] Loss: 0.003629 Acc: 1.0000\n",
      "Train Epoch: 24 [25600/50000] Loss: 0.002647 Acc: 1.0000\n",
      "Train Epoch: 24 [27200/50000] Loss: 0.241021 Acc: 0.8750\n",
      "Train Epoch: 24 [28800/50000] Loss: 0.130843 Acc: 0.9375\n",
      "Train Epoch: 24 [30400/50000] Loss: 0.055883 Acc: 0.9375\n",
      "Train Epoch: 24 [32000/50000] Loss: 0.224155 Acc: 0.8750\n",
      "Train Epoch: 24 [33600/50000] Loss: 0.017391 Acc: 1.0000\n",
      "Train Epoch: 24 [35200/50000] Loss: 0.245349 Acc: 0.9375\n",
      "Train Epoch: 24 [36800/50000] Loss: 0.107633 Acc: 1.0000\n",
      "Train Epoch: 24 [38400/50000] Loss: 0.196723 Acc: 0.9375\n",
      "Train Epoch: 24 [40000/50000] Loss: 0.037641 Acc: 1.0000\n",
      "Train Epoch: 24 [41600/50000] Loss: 0.207741 Acc: 0.9375\n",
      "Train Epoch: 24 [43200/50000] Loss: 0.181359 Acc: 0.9375\n",
      "Train Epoch: 24 [44800/50000] Loss: 0.005732 Acc: 1.0000\n",
      "Train Epoch: 24 [46400/50000] Loss: 0.021813 Acc: 1.0000\n",
      "Train Epoch: 24 [48000/50000] Loss: 0.238717 Acc: 0.8750\n",
      "Train Epoch: 24 [49600/50000] Loss: 0.052136 Acc: 1.0000\n",
      "Elapsed 1072.07s, 42.88 s/epoch, 0.01 s/batch, ets 1072.07s\n",
      "\n",
      "Test set: Average loss: 1.3648, Accuracy: 7337/10000 (73%)\n",
      "\n",
      "Train Epoch: 25 [1600/50000] Loss: 0.019590 Acc: 1.0000\n",
      "Train Epoch: 25 [3200/50000] Loss: 0.015667 Acc: 1.0000\n",
      "Train Epoch: 25 [4800/50000] Loss: 0.161568 Acc: 0.8750\n",
      "Train Epoch: 25 [6400/50000] Loss: 0.012389 Acc: 1.0000\n",
      "Train Epoch: 25 [8000/50000] Loss: 0.111665 Acc: 1.0000\n",
      "Train Epoch: 25 [9600/50000] Loss: 0.095121 Acc: 0.9375\n",
      "Train Epoch: 25 [11200/50000] Loss: 0.111609 Acc: 0.9375\n",
      "Train Epoch: 25 [12800/50000] Loss: 0.076127 Acc: 1.0000\n",
      "Train Epoch: 25 [14400/50000] Loss: 0.028863 Acc: 1.0000\n",
      "Train Epoch: 25 [16000/50000] Loss: 0.094797 Acc: 1.0000\n",
      "Train Epoch: 25 [17600/50000] Loss: 0.046273 Acc: 1.0000\n",
      "Train Epoch: 25 [19200/50000] Loss: 0.007154 Acc: 1.0000\n",
      "Train Epoch: 25 [20800/50000] Loss: 0.029006 Acc: 1.0000\n",
      "Train Epoch: 25 [22400/50000] Loss: 0.076252 Acc: 0.9375\n",
      "Train Epoch: 25 [24000/50000] Loss: 0.010881 Acc: 1.0000\n",
      "Train Epoch: 25 [25600/50000] Loss: 0.123681 Acc: 0.8750\n",
      "Train Epoch: 25 [27200/50000] Loss: 0.227153 Acc: 0.9375\n",
      "Train Epoch: 25 [28800/50000] Loss: 0.137263 Acc: 0.9375\n",
      "Train Epoch: 25 [30400/50000] Loss: 0.054173 Acc: 1.0000\n",
      "Train Epoch: 25 [32000/50000] Loss: 0.004210 Acc: 1.0000\n",
      "Train Epoch: 25 [33600/50000] Loss: 0.110986 Acc: 0.9375\n",
      "Train Epoch: 25 [35200/50000] Loss: 0.028501 Acc: 1.0000\n",
      "Train Epoch: 25 [36800/50000] Loss: 0.039332 Acc: 1.0000\n",
      "Train Epoch: 25 [38400/50000] Loss: 0.006326 Acc: 1.0000\n",
      "Train Epoch: 25 [40000/50000] Loss: 0.051703 Acc: 1.0000\n",
      "Train Epoch: 25 [41600/50000] Loss: 0.135671 Acc: 0.9375\n",
      "Train Epoch: 25 [43200/50000] Loss: 0.018941 Acc: 1.0000\n",
      "Train Epoch: 25 [44800/50000] Loss: 0.034497 Acc: 1.0000\n",
      "Train Epoch: 25 [46400/50000] Loss: 0.008634 Acc: 1.0000\n",
      "Train Epoch: 25 [48000/50000] Loss: 0.111097 Acc: 0.9375\n",
      "Train Epoch: 25 [49600/50000] Loss: 0.192197 Acc: 0.8125\n",
      "Elapsed 1186.66s, 45.64 s/epoch, 0.01 s/batch, ets 1095.38s\n",
      "\n",
      "Test set: Average loss: 1.3764, Accuracy: 7406/10000 (74%)\n",
      "\n",
      "Train Epoch: 26 [1600/50000] Loss: 0.015755 Acc: 1.0000\n",
      "Train Epoch: 26 [3200/50000] Loss: 0.024607 Acc: 1.0000\n",
      "Train Epoch: 26 [4800/50000] Loss: 0.020111 Acc: 1.0000\n",
      "Train Epoch: 26 [6400/50000] Loss: 0.178054 Acc: 0.9375\n",
      "Train Epoch: 26 [8000/50000] Loss: 0.036990 Acc: 1.0000\n",
      "Train Epoch: 26 [9600/50000] Loss: 0.023217 Acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 26 [11200/50000] Loss: 0.126461 Acc: 0.9375\n",
      "Train Epoch: 26 [12800/50000] Loss: 0.064606 Acc: 1.0000\n",
      "Train Epoch: 26 [14400/50000] Loss: 0.022490 Acc: 1.0000\n",
      "Train Epoch: 26 [16000/50000] Loss: 0.293578 Acc: 0.8750\n",
      "Train Epoch: 26 [17600/50000] Loss: 0.077092 Acc: 1.0000\n",
      "Train Epoch: 26 [19200/50000] Loss: 0.173927 Acc: 0.9375\n",
      "Train Epoch: 26 [20800/50000] Loss: 0.113752 Acc: 0.9375\n",
      "Train Epoch: 26 [22400/50000] Loss: 0.095587 Acc: 0.9375\n",
      "Train Epoch: 26 [24000/50000] Loss: 0.328714 Acc: 0.8750\n",
      "Train Epoch: 26 [25600/50000] Loss: 0.011783 Acc: 1.0000\n",
      "Train Epoch: 26 [27200/50000] Loss: 0.031114 Acc: 1.0000\n",
      "Train Epoch: 26 [28800/50000] Loss: 0.167121 Acc: 0.9375\n",
      "Train Epoch: 26 [30400/50000] Loss: 0.033571 Acc: 1.0000\n",
      "Train Epoch: 26 [32000/50000] Loss: 0.007189 Acc: 1.0000\n",
      "Train Epoch: 26 [33600/50000] Loss: 0.017341 Acc: 1.0000\n",
      "Train Epoch: 26 [35200/50000] Loss: 0.044866 Acc: 1.0000\n",
      "Train Epoch: 26 [36800/50000] Loss: 0.084433 Acc: 1.0000\n",
      "Train Epoch: 26 [38400/50000] Loss: 0.005929 Acc: 1.0000\n",
      "Train Epoch: 26 [40000/50000] Loss: 0.076254 Acc: 0.9375\n",
      "Train Epoch: 26 [41600/50000] Loss: 0.140458 Acc: 0.8750\n",
      "Train Epoch: 26 [43200/50000] Loss: 0.033955 Acc: 1.0000\n",
      "Train Epoch: 26 [44800/50000] Loss: 0.259490 Acc: 0.9375\n",
      "Train Epoch: 26 [46400/50000] Loss: 0.251176 Acc: 0.8750\n",
      "Train Epoch: 26 [48000/50000] Loss: 0.005912 Acc: 1.0000\n",
      "Train Epoch: 26 [49600/50000] Loss: 0.069933 Acc: 1.0000\n",
      "Elapsed 1303.87s, 48.29 s/epoch, 0.02 s/batch, ets 1110.71s\n",
      "\n",
      "Test set: Average loss: 1.3568, Accuracy: 7456/10000 (75%)\n",
      "\n",
      "Train Epoch: 27 [1600/50000] Loss: 0.026712 Acc: 1.0000\n",
      "Train Epoch: 27 [3200/50000] Loss: 0.008123 Acc: 1.0000\n",
      "Train Epoch: 27 [4800/50000] Loss: 0.106981 Acc: 0.9375\n",
      "Train Epoch: 27 [6400/50000] Loss: 0.035803 Acc: 1.0000\n",
      "Train Epoch: 27 [8000/50000] Loss: 0.099730 Acc: 0.9375\n",
      "Train Epoch: 27 [9600/50000] Loss: 0.012497 Acc: 1.0000\n",
      "Train Epoch: 27 [11200/50000] Loss: 0.069367 Acc: 1.0000\n",
      "Train Epoch: 27 [12800/50000] Loss: 0.014097 Acc: 1.0000\n",
      "Train Epoch: 27 [14400/50000] Loss: 0.048326 Acc: 1.0000\n",
      "Train Epoch: 27 [16000/50000] Loss: 0.120035 Acc: 0.9375\n",
      "Train Epoch: 27 [17600/50000] Loss: 0.041705 Acc: 1.0000\n",
      "Train Epoch: 27 [19200/50000] Loss: 0.014634 Acc: 1.0000\n",
      "Train Epoch: 27 [20800/50000] Loss: 0.017786 Acc: 1.0000\n",
      "Train Epoch: 27 [22400/50000] Loss: 0.010234 Acc: 1.0000\n",
      "Train Epoch: 27 [24000/50000] Loss: 0.041397 Acc: 1.0000\n",
      "Train Epoch: 27 [25600/50000] Loss: 0.007331 Acc: 1.0000\n",
      "Train Epoch: 27 [27200/50000] Loss: 0.023906 Acc: 1.0000\n",
      "Train Epoch: 27 [28800/50000] Loss: 0.002967 Acc: 1.0000\n",
      "Train Epoch: 27 [30400/50000] Loss: 0.027351 Acc: 1.0000\n",
      "Train Epoch: 27 [32000/50000] Loss: 0.014957 Acc: 1.0000\n",
      "Train Epoch: 27 [33600/50000] Loss: 0.010121 Acc: 1.0000\n",
      "Train Epoch: 27 [35200/50000] Loss: 0.179801 Acc: 0.8750\n",
      "Train Epoch: 27 [36800/50000] Loss: 0.042486 Acc: 1.0000\n",
      "Train Epoch: 27 [38400/50000] Loss: 0.043086 Acc: 1.0000\n",
      "Train Epoch: 27 [40000/50000] Loss: 0.007299 Acc: 1.0000\n",
      "Train Epoch: 27 [41600/50000] Loss: 0.003167 Acc: 1.0000\n",
      "Train Epoch: 27 [43200/50000] Loss: 0.193678 Acc: 0.9375\n",
      "Train Epoch: 27 [44800/50000] Loss: 0.008598 Acc: 1.0000\n",
      "Train Epoch: 27 [46400/50000] Loss: 0.094506 Acc: 0.9375\n",
      "Train Epoch: 27 [48000/50000] Loss: 0.087072 Acc: 1.0000\n",
      "Train Epoch: 27 [49600/50000] Loss: 0.041750 Acc: 1.0000\n",
      "Elapsed 1394.82s, 49.82 s/epoch, 0.02 s/batch, ets 1095.93s\n",
      "\n",
      "Test set: Average loss: 1.4476, Accuracy: 7412/10000 (74%)\n",
      "\n",
      "Train Epoch: 28 [1600/50000] Loss: 0.031389 Acc: 1.0000\n",
      "Train Epoch: 28 [3200/50000] Loss: 0.089573 Acc: 0.9375\n",
      "Train Epoch: 28 [4800/50000] Loss: 0.034548 Acc: 1.0000\n",
      "Train Epoch: 28 [6400/50000] Loss: 0.004207 Acc: 1.0000\n",
      "Train Epoch: 28 [8000/50000] Loss: 0.030457 Acc: 1.0000\n",
      "Train Epoch: 28 [9600/50000] Loss: 0.001493 Acc: 1.0000\n",
      "Train Epoch: 28 [11200/50000] Loss: 0.004383 Acc: 1.0000\n",
      "Train Epoch: 28 [12800/50000] Loss: 0.026910 Acc: 1.0000\n",
      "Train Epoch: 28 [14400/50000] Loss: 0.010351 Acc: 1.0000\n",
      "Train Epoch: 28 [16000/50000] Loss: 0.059329 Acc: 0.9375\n",
      "Train Epoch: 28 [17600/50000] Loss: 0.029922 Acc: 1.0000\n",
      "Train Epoch: 28 [19200/50000] Loss: 0.004215 Acc: 1.0000\n",
      "Train Epoch: 28 [20800/50000] Loss: 0.004305 Acc: 1.0000\n",
      "Train Epoch: 28 [22400/50000] Loss: 0.142913 Acc: 0.9375\n",
      "Train Epoch: 28 [24000/50000] Loss: 0.004713 Acc: 1.0000\n",
      "Train Epoch: 28 [25600/50000] Loss: 0.025422 Acc: 1.0000\n",
      "Train Epoch: 28 [27200/50000] Loss: 0.007554 Acc: 1.0000\n",
      "Train Epoch: 28 [28800/50000] Loss: 0.038414 Acc: 1.0000\n",
      "Train Epoch: 28 [30400/50000] Loss: 0.019127 Acc: 1.0000\n",
      "Train Epoch: 28 [32000/50000] Loss: 0.291440 Acc: 0.8750\n",
      "Train Epoch: 28 [33600/50000] Loss: 0.091885 Acc: 0.9375\n",
      "Train Epoch: 28 [35200/50000] Loss: 0.478050 Acc: 0.9375\n",
      "Train Epoch: 28 [36800/50000] Loss: 0.007906 Acc: 1.0000\n",
      "Train Epoch: 28 [38400/50000] Loss: 0.231451 Acc: 0.9375\n",
      "Train Epoch: 28 [40000/50000] Loss: 0.016898 Acc: 1.0000\n",
      "Train Epoch: 28 [41600/50000] Loss: 0.057714 Acc: 1.0000\n",
      "Train Epoch: 28 [43200/50000] Loss: 0.004422 Acc: 1.0000\n",
      "Train Epoch: 28 [44800/50000] Loss: 0.050277 Acc: 1.0000\n",
      "Train Epoch: 28 [46400/50000] Loss: 0.044181 Acc: 1.0000\n",
      "Train Epoch: 28 [48000/50000] Loss: 0.033602 Acc: 1.0000\n",
      "Train Epoch: 28 [49600/50000] Loss: 0.061337 Acc: 0.9375\n",
      "Elapsed 1438.71s, 49.61 s/epoch, 0.02 s/batch, ets 1041.82s\n",
      "\n",
      "Test set: Average loss: 1.4337, Accuracy: 7376/10000 (74%)\n",
      "\n",
      "Train Epoch: 29 [1600/50000] Loss: 0.083054 Acc: 0.9375\n",
      "Train Epoch: 29 [3200/50000] Loss: 0.001878 Acc: 1.0000\n",
      "Train Epoch: 29 [4800/50000] Loss: 0.004854 Acc: 1.0000\n",
      "Train Epoch: 29 [6400/50000] Loss: 0.031317 Acc: 1.0000\n",
      "Train Epoch: 29 [8000/50000] Loss: 0.017678 Acc: 1.0000\n",
      "Train Epoch: 29 [9600/50000] Loss: 0.026998 Acc: 1.0000\n",
      "Train Epoch: 29 [11200/50000] Loss: 0.051039 Acc: 0.9375\n",
      "Train Epoch: 29 [12800/50000] Loss: 0.107712 Acc: 0.9375\n",
      "Train Epoch: 29 [14400/50000] Loss: 0.098329 Acc: 0.9375\n",
      "Train Epoch: 29 [16000/50000] Loss: 0.036031 Acc: 1.0000\n",
      "Train Epoch: 29 [17600/50000] Loss: 0.007439 Acc: 1.0000\n",
      "Train Epoch: 29 [19200/50000] Loss: 0.083908 Acc: 0.9375\n",
      "Train Epoch: 29 [20800/50000] Loss: 0.009592 Acc: 1.0000\n",
      "Train Epoch: 29 [22400/50000] Loss: 0.017827 Acc: 1.0000\n",
      "Train Epoch: 29 [24000/50000] Loss: 0.076447 Acc: 1.0000\n",
      "Train Epoch: 29 [25600/50000] Loss: 0.007705 Acc: 1.0000\n",
      "Train Epoch: 29 [27200/50000] Loss: 0.023231 Acc: 1.0000\n",
      "Train Epoch: 29 [28800/50000] Loss: 0.024518 Acc: 1.0000\n",
      "Train Epoch: 29 [30400/50000] Loss: 0.012940 Acc: 1.0000\n",
      "Train Epoch: 29 [32000/50000] Loss: 0.053653 Acc: 1.0000\n",
      "Train Epoch: 29 [33600/50000] Loss: 0.021360 Acc: 1.0000\n",
      "Train Epoch: 29 [35200/50000] Loss: 0.012385 Acc: 1.0000\n",
      "Train Epoch: 29 [36800/50000] Loss: 0.004461 Acc: 1.0000\n",
      "Train Epoch: 29 [38400/50000] Loss: 0.033221 Acc: 1.0000\n",
      "Train Epoch: 29 [40000/50000] Loss: 0.090126 Acc: 0.9375\n",
      "Train Epoch: 29 [41600/50000] Loss: 0.209731 Acc: 0.9375\n",
      "Train Epoch: 29 [43200/50000] Loss: 0.015642 Acc: 1.0000\n",
      "Train Epoch: 29 [44800/50000] Loss: 0.038538 Acc: 1.0000\n",
      "Train Epoch: 29 [46400/50000] Loss: 0.015400 Acc: 1.0000\n",
      "Train Epoch: 29 [48000/50000] Loss: 0.035951 Acc: 1.0000\n",
      "Train Epoch: 29 [49600/50000] Loss: 0.059625 Acc: 0.9375\n",
      "Elapsed 1481.34s, 49.38 s/epoch, 0.02 s/batch, ets 987.56s\n",
      "\n",
      "Test set: Average loss: 1.6191, Accuracy: 7297/10000 (73%)\n",
      "\n",
      "Train Epoch: 30 [1600/50000] Loss: 0.009577 Acc: 1.0000\n",
      "Train Epoch: 30 [3200/50000] Loss: 0.023077 Acc: 1.0000\n",
      "Train Epoch: 30 [4800/50000] Loss: 0.000643 Acc: 1.0000\n",
      "Train Epoch: 30 [6400/50000] Loss: 0.033469 Acc: 1.0000\n",
      "Train Epoch: 30 [8000/50000] Loss: 0.019228 Acc: 1.0000\n",
      "Train Epoch: 30 [9600/50000] Loss: 0.070267 Acc: 0.9375\n",
      "Train Epoch: 30 [11200/50000] Loss: 0.108953 Acc: 0.9375\n",
      "Train Epoch: 30 [12800/50000] Loss: 0.097907 Acc: 0.9375\n",
      "Train Epoch: 30 [14400/50000] Loss: 0.069255 Acc: 1.0000\n",
      "Train Epoch: 30 [16000/50000] Loss: 0.022208 Acc: 1.0000\n",
      "Train Epoch: 30 [17600/50000] Loss: 0.027554 Acc: 1.0000\n",
      "Train Epoch: 30 [19200/50000] Loss: 0.134809 Acc: 0.9375\n",
      "Train Epoch: 30 [20800/50000] Loss: 0.071616 Acc: 0.9375\n",
      "Train Epoch: 30 [22400/50000] Loss: 0.004509 Acc: 1.0000\n",
      "Train Epoch: 30 [24000/50000] Loss: 0.150359 Acc: 0.9375\n",
      "Train Epoch: 30 [25600/50000] Loss: 0.141615 Acc: 0.9375\n",
      "Train Epoch: 30 [27200/50000] Loss: 0.019615 Acc: 1.0000\n",
      "Train Epoch: 30 [28800/50000] Loss: 0.002821 Acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 30 [30400/50000] Loss: 0.014878 Acc: 1.0000\n",
      "Train Epoch: 30 [32000/50000] Loss: 0.032549 Acc: 1.0000\n",
      "Train Epoch: 30 [33600/50000] Loss: 0.033116 Acc: 1.0000\n",
      "Train Epoch: 30 [35200/50000] Loss: 0.009855 Acc: 1.0000\n",
      "Train Epoch: 30 [36800/50000] Loss: 0.033530 Acc: 1.0000\n",
      "Train Epoch: 30 [38400/50000] Loss: 0.053405 Acc: 1.0000\n",
      "Train Epoch: 30 [40000/50000] Loss: 0.092115 Acc: 0.9375\n",
      "Train Epoch: 30 [41600/50000] Loss: 0.006393 Acc: 1.0000\n",
      "Train Epoch: 30 [43200/50000] Loss: 0.020945 Acc: 1.0000\n",
      "Train Epoch: 30 [44800/50000] Loss: 0.081313 Acc: 0.9375\n",
      "Train Epoch: 30 [46400/50000] Loss: 0.055117 Acc: 1.0000\n",
      "Train Epoch: 30 [48000/50000] Loss: 0.067293 Acc: 1.0000\n",
      "Train Epoch: 30 [49600/50000] Loss: 0.002517 Acc: 1.0000\n",
      "Elapsed 1524.00s, 49.16 s/epoch, 0.02 s/batch, ets 934.06s\n",
      "\n",
      "Test set: Average loss: 1.5529, Accuracy: 7388/10000 (74%)\n",
      "\n",
      "Train Epoch: 31 [1600/50000] Loss: 0.024197 Acc: 1.0000\n",
      "Train Epoch: 31 [3200/50000] Loss: 0.004445 Acc: 1.0000\n",
      "Train Epoch: 31 [4800/50000] Loss: 0.001445 Acc: 1.0000\n",
      "Train Epoch: 31 [6400/50000] Loss: 0.011634 Acc: 1.0000\n",
      "Train Epoch: 31 [8000/50000] Loss: 0.001634 Acc: 1.0000\n",
      "Train Epoch: 31 [9600/50000] Loss: 0.001329 Acc: 1.0000\n",
      "Train Epoch: 31 [11200/50000] Loss: 0.002798 Acc: 1.0000\n",
      "Train Epoch: 31 [12800/50000] Loss: 0.090846 Acc: 1.0000\n",
      "Train Epoch: 31 [14400/50000] Loss: 0.010430 Acc: 1.0000\n",
      "Train Epoch: 31 [16000/50000] Loss: 0.004927 Acc: 1.0000\n",
      "Train Epoch: 31 [17600/50000] Loss: 0.000964 Acc: 1.0000\n",
      "Train Epoch: 31 [19200/50000] Loss: 0.020705 Acc: 1.0000\n",
      "Train Epoch: 31 [20800/50000] Loss: 0.044019 Acc: 1.0000\n",
      "Train Epoch: 31 [22400/50000] Loss: 0.043456 Acc: 1.0000\n",
      "Train Epoch: 31 [24000/50000] Loss: 0.049410 Acc: 1.0000\n",
      "Train Epoch: 31 [25600/50000] Loss: 0.020755 Acc: 1.0000\n",
      "Train Epoch: 31 [27200/50000] Loss: 0.003714 Acc: 1.0000\n",
      "Train Epoch: 31 [28800/50000] Loss: 0.001286 Acc: 1.0000\n",
      "Train Epoch: 31 [30400/50000] Loss: 0.003275 Acc: 1.0000\n",
      "Train Epoch: 31 [32000/50000] Loss: 0.020359 Acc: 1.0000\n",
      "Train Epoch: 31 [33600/50000] Loss: 0.001168 Acc: 1.0000\n",
      "Train Epoch: 31 [35200/50000] Loss: 0.001349 Acc: 1.0000\n",
      "Train Epoch: 31 [36800/50000] Loss: 0.013304 Acc: 1.0000\n",
      "Train Epoch: 31 [38400/50000] Loss: 0.068772 Acc: 0.9375\n",
      "Train Epoch: 31 [40000/50000] Loss: 0.008277 Acc: 1.0000\n",
      "Train Epoch: 31 [41600/50000] Loss: 0.037516 Acc: 1.0000\n",
      "Train Epoch: 31 [43200/50000] Loss: 0.010160 Acc: 1.0000\n",
      "Train Epoch: 31 [44800/50000] Loss: 0.015138 Acc: 1.0000\n",
      "Train Epoch: 31 [46400/50000] Loss: 0.007570 Acc: 1.0000\n",
      "Train Epoch: 31 [48000/50000] Loss: 0.231068 Acc: 0.9375\n",
      "Train Epoch: 31 [49600/50000] Loss: 0.008311 Acc: 1.0000\n",
      "Elapsed 1566.67s, 48.96 s/epoch, 0.02 s/batch, ets 881.25s\n",
      "\n",
      "Test set: Average loss: 1.6241, Accuracy: 7308/10000 (73%)\n",
      "\n",
      "Train Epoch: 32 [1600/50000] Loss: 0.043867 Acc: 1.0000\n",
      "Train Epoch: 32 [3200/50000] Loss: 0.032433 Acc: 1.0000\n",
      "Train Epoch: 32 [4800/50000] Loss: 0.039182 Acc: 1.0000\n",
      "Train Epoch: 32 [6400/50000] Loss: 0.009083 Acc: 1.0000\n",
      "Train Epoch: 32 [8000/50000] Loss: 0.405494 Acc: 0.9375\n",
      "Train Epoch: 32 [9600/50000] Loss: 0.036184 Acc: 1.0000\n",
      "Train Epoch: 32 [11200/50000] Loss: 0.003451 Acc: 1.0000\n",
      "Train Epoch: 32 [12800/50000] Loss: 0.007145 Acc: 1.0000\n",
      "Train Epoch: 32 [14400/50000] Loss: 0.004220 Acc: 1.0000\n",
      "Train Epoch: 32 [16000/50000] Loss: 0.032184 Acc: 1.0000\n",
      "Train Epoch: 32 [17600/50000] Loss: 0.045919 Acc: 1.0000\n",
      "Train Epoch: 32 [19200/50000] Loss: 0.110887 Acc: 0.9375\n",
      "Train Epoch: 32 [20800/50000] Loss: 0.000412 Acc: 1.0000\n",
      "Train Epoch: 32 [22400/50000] Loss: 0.014889 Acc: 1.0000\n",
      "Train Epoch: 32 [24000/50000] Loss: 0.004313 Acc: 1.0000\n",
      "Train Epoch: 32 [25600/50000] Loss: 0.040691 Acc: 1.0000\n",
      "Train Epoch: 32 [27200/50000] Loss: 0.013676 Acc: 1.0000\n",
      "Train Epoch: 32 [28800/50000] Loss: 0.001935 Acc: 1.0000\n",
      "Train Epoch: 32 [30400/50000] Loss: 0.177577 Acc: 0.9375\n",
      "Train Epoch: 32 [32000/50000] Loss: 0.022945 Acc: 1.0000\n",
      "Train Epoch: 32 [33600/50000] Loss: 0.050512 Acc: 1.0000\n",
      "Train Epoch: 32 [35200/50000] Loss: 0.021539 Acc: 1.0000\n",
      "Train Epoch: 32 [36800/50000] Loss: 0.024677 Acc: 1.0000\n",
      "Train Epoch: 32 [38400/50000] Loss: 0.018839 Acc: 1.0000\n",
      "Train Epoch: 32 [40000/50000] Loss: 0.007867 Acc: 1.0000\n",
      "Train Epoch: 32 [41600/50000] Loss: 0.130179 Acc: 0.9375\n",
      "Train Epoch: 32 [43200/50000] Loss: 0.068184 Acc: 1.0000\n",
      "Train Epoch: 32 [44800/50000] Loss: 0.178043 Acc: 0.8750\n",
      "Train Epoch: 32 [46400/50000] Loss: 0.084969 Acc: 0.9375\n",
      "Train Epoch: 32 [48000/50000] Loss: 0.143454 Acc: 0.9375\n",
      "Train Epoch: 32 [49600/50000] Loss: 0.031322 Acc: 1.0000\n",
      "Elapsed 1609.95s, 48.79 s/epoch, 0.02 s/batch, ets 829.37s\n",
      "\n",
      "Test set: Average loss: 1.5635, Accuracy: 7441/10000 (74%)\n",
      "\n",
      "Train Epoch: 33 [1600/50000] Loss: 0.069770 Acc: 0.9375\n",
      "Train Epoch: 33 [3200/50000] Loss: 0.052136 Acc: 1.0000\n",
      "Train Epoch: 33 [4800/50000] Loss: 0.006592 Acc: 1.0000\n",
      "Train Epoch: 33 [6400/50000] Loss: 0.008246 Acc: 1.0000\n",
      "Train Epoch: 33 [8000/50000] Loss: 0.049418 Acc: 0.9375\n",
      "Train Epoch: 33 [9600/50000] Loss: 0.039540 Acc: 1.0000\n",
      "Train Epoch: 33 [11200/50000] Loss: 0.004635 Acc: 1.0000\n",
      "Train Epoch: 33 [12800/50000] Loss: 0.000273 Acc: 1.0000\n",
      "Train Epoch: 33 [14400/50000] Loss: 0.013890 Acc: 1.0000\n",
      "Train Epoch: 33 [16000/50000] Loss: 0.022425 Acc: 1.0000\n",
      "Train Epoch: 33 [17600/50000] Loss: 0.162727 Acc: 0.9375\n",
      "Train Epoch: 33 [19200/50000] Loss: 0.030382 Acc: 1.0000\n",
      "Train Epoch: 33 [20800/50000] Loss: 0.028990 Acc: 1.0000\n",
      "Train Epoch: 33 [22400/50000] Loss: 0.004710 Acc: 1.0000\n",
      "Train Epoch: 33 [24000/50000] Loss: 0.188425 Acc: 0.9375\n",
      "Train Epoch: 33 [25600/50000] Loss: 0.004409 Acc: 1.0000\n",
      "Train Epoch: 33 [27200/50000] Loss: 0.000312 Acc: 1.0000\n",
      "Train Epoch: 33 [28800/50000] Loss: 0.001906 Acc: 1.0000\n",
      "Train Epoch: 33 [30400/50000] Loss: 0.003298 Acc: 1.0000\n",
      "Train Epoch: 33 [32000/50000] Loss: 0.009008 Acc: 1.0000\n",
      "Train Epoch: 33 [33600/50000] Loss: 0.003128 Acc: 1.0000\n",
      "Train Epoch: 33 [35200/50000] Loss: 0.007780 Acc: 1.0000\n",
      "Train Epoch: 33 [36800/50000] Loss: 0.013386 Acc: 1.0000\n",
      "Train Epoch: 33 [38400/50000] Loss: 0.010106 Acc: 1.0000\n",
      "Train Epoch: 33 [40000/50000] Loss: 0.060919 Acc: 0.9375\n",
      "Train Epoch: 33 [41600/50000] Loss: 0.028029 Acc: 1.0000\n",
      "Train Epoch: 33 [43200/50000] Loss: 0.044345 Acc: 1.0000\n",
      "Train Epoch: 33 [44800/50000] Loss: 0.000700 Acc: 1.0000\n",
      "Train Epoch: 33 [46400/50000] Loss: 0.003652 Acc: 1.0000\n",
      "Train Epoch: 33 [48000/50000] Loss: 0.008357 Acc: 1.0000\n",
      "Train Epoch: 33 [49600/50000] Loss: 0.090446 Acc: 1.0000\n",
      "Elapsed 1653.21s, 48.62 s/epoch, 0.02 s/batch, ets 777.98s\n",
      "\n",
      "Test set: Average loss: 1.5932, Accuracy: 7348/10000 (73%)\n",
      "\n",
      "Train Epoch: 34 [1600/50000] Loss: 0.113720 Acc: 0.9375\n",
      "Train Epoch: 34 [3200/50000] Loss: 0.025793 Acc: 1.0000\n",
      "Train Epoch: 34 [4800/50000] Loss: 0.002888 Acc: 1.0000\n",
      "Train Epoch: 34 [6400/50000] Loss: 0.000766 Acc: 1.0000\n",
      "Train Epoch: 34 [8000/50000] Loss: 0.109532 Acc: 0.9375\n",
      "Train Epoch: 34 [9600/50000] Loss: 0.000700 Acc: 1.0000\n",
      "Train Epoch: 34 [11200/50000] Loss: 0.005915 Acc: 1.0000\n",
      "Train Epoch: 34 [12800/50000] Loss: 0.002222 Acc: 1.0000\n",
      "Train Epoch: 34 [14400/50000] Loss: 0.014484 Acc: 1.0000\n",
      "Train Epoch: 34 [16000/50000] Loss: 0.093353 Acc: 0.9375\n",
      "Train Epoch: 34 [17600/50000] Loss: 0.021159 Acc: 1.0000\n",
      "Train Epoch: 34 [19200/50000] Loss: 0.001550 Acc: 1.0000\n",
      "Train Epoch: 34 [20800/50000] Loss: 0.002067 Acc: 1.0000\n",
      "Train Epoch: 34 [22400/50000] Loss: 0.016883 Acc: 1.0000\n",
      "Train Epoch: 34 [24000/50000] Loss: 0.001844 Acc: 1.0000\n",
      "Train Epoch: 34 [25600/50000] Loss: 0.003929 Acc: 1.0000\n",
      "Train Epoch: 34 [27200/50000] Loss: 0.064252 Acc: 1.0000\n",
      "Train Epoch: 34 [28800/50000] Loss: 0.069231 Acc: 1.0000\n",
      "Train Epoch: 34 [30400/50000] Loss: 0.001254 Acc: 1.0000\n",
      "Train Epoch: 34 [32000/50000] Loss: 0.111624 Acc: 0.9375\n",
      "Train Epoch: 34 [33600/50000] Loss: 0.074740 Acc: 1.0000\n",
      "Train Epoch: 34 [35200/50000] Loss: 0.001703 Acc: 1.0000\n",
      "Train Epoch: 34 [36800/50000] Loss: 0.049392 Acc: 1.0000\n",
      "Train Epoch: 34 [38400/50000] Loss: 0.036032 Acc: 1.0000\n",
      "Train Epoch: 34 [40000/50000] Loss: 0.002670 Acc: 1.0000\n",
      "Train Epoch: 34 [41600/50000] Loss: 0.032403 Acc: 1.0000\n",
      "Train Epoch: 34 [43200/50000] Loss: 0.012293 Acc: 1.0000\n",
      "Train Epoch: 34 [44800/50000] Loss: 0.006029 Acc: 1.0000\n",
      "Train Epoch: 34 [46400/50000] Loss: 0.011244 Acc: 1.0000\n",
      "Train Epoch: 34 [48000/50000] Loss: 0.010366 Acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 34 [49600/50000] Loss: 0.000224 Acc: 1.0000\n",
      "Elapsed 1696.91s, 48.48 s/epoch, 0.02 s/batch, ets 727.25s\n",
      "\n",
      "Test set: Average loss: 1.6700, Accuracy: 7322/10000 (73%)\n",
      "\n",
      "Train Epoch: 35 [1600/50000] Loss: 0.000594 Acc: 1.0000\n",
      "Train Epoch: 35 [3200/50000] Loss: 0.000989 Acc: 1.0000\n",
      "Train Epoch: 35 [4800/50000] Loss: 0.001827 Acc: 1.0000\n",
      "Train Epoch: 35 [6400/50000] Loss: 0.001351 Acc: 1.0000\n",
      "Train Epoch: 35 [8000/50000] Loss: 0.034106 Acc: 1.0000\n",
      "Train Epoch: 35 [9600/50000] Loss: 0.005836 Acc: 1.0000\n",
      "Train Epoch: 35 [11200/50000] Loss: 0.002189 Acc: 1.0000\n",
      "Train Epoch: 35 [12800/50000] Loss: 0.002063 Acc: 1.0000\n",
      "Train Epoch: 35 [14400/50000] Loss: 0.010649 Acc: 1.0000\n",
      "Train Epoch: 35 [16000/50000] Loss: 0.009492 Acc: 1.0000\n",
      "Train Epoch: 35 [17600/50000] Loss: 0.000788 Acc: 1.0000\n",
      "Train Epoch: 35 [19200/50000] Loss: 0.001499 Acc: 1.0000\n",
      "Train Epoch: 35 [20800/50000] Loss: 0.003740 Acc: 1.0000\n",
      "Train Epoch: 35 [22400/50000] Loss: 0.023279 Acc: 1.0000\n",
      "Train Epoch: 35 [24000/50000] Loss: 0.109061 Acc: 0.9375\n",
      "Train Epoch: 35 [25600/50000] Loss: 0.035229 Acc: 1.0000\n",
      "Train Epoch: 35 [27200/50000] Loss: 0.022817 Acc: 1.0000\n",
      "Train Epoch: 35 [28800/50000] Loss: 0.008833 Acc: 1.0000\n",
      "Train Epoch: 35 [30400/50000] Loss: 0.005036 Acc: 1.0000\n",
      "Train Epoch: 35 [32000/50000] Loss: 0.001864 Acc: 1.0000\n",
      "Train Epoch: 35 [33600/50000] Loss: 0.067782 Acc: 0.9375\n",
      "Train Epoch: 35 [35200/50000] Loss: 0.001214 Acc: 1.0000\n",
      "Train Epoch: 35 [36800/50000] Loss: 0.015147 Acc: 1.0000\n",
      "Train Epoch: 35 [38400/50000] Loss: 0.004907 Acc: 1.0000\n",
      "Train Epoch: 35 [40000/50000] Loss: 0.013805 Acc: 1.0000\n",
      "Train Epoch: 35 [41600/50000] Loss: 0.095556 Acc: 0.9375\n",
      "Train Epoch: 35 [43200/50000] Loss: 0.025315 Acc: 1.0000\n",
      "Train Epoch: 35 [44800/50000] Loss: 0.049469 Acc: 1.0000\n",
      "Train Epoch: 35 [46400/50000] Loss: 0.022631 Acc: 1.0000\n",
      "Train Epoch: 35 [48000/50000] Loss: 0.106995 Acc: 0.9375\n",
      "Train Epoch: 35 [49600/50000] Loss: 0.028817 Acc: 1.0000\n",
      "Elapsed 1739.61s, 48.32 s/epoch, 0.02 s/batch, ets 676.52s\n",
      "\n",
      "Test set: Average loss: 1.6796, Accuracy: 7369/10000 (74%)\n",
      "\n",
      "Train Epoch: 36 [1600/50000] Loss: 0.014212 Acc: 1.0000\n",
      "Train Epoch: 36 [3200/50000] Loss: 0.004051 Acc: 1.0000\n",
      "Train Epoch: 36 [4800/50000] Loss: 0.189534 Acc: 0.9375\n",
      "Train Epoch: 36 [6400/50000] Loss: 0.074884 Acc: 0.9375\n",
      "Train Epoch: 36 [8000/50000] Loss: 0.000686 Acc: 1.0000\n",
      "Train Epoch: 36 [9600/50000] Loss: 0.117886 Acc: 0.9375\n",
      "Train Epoch: 36 [11200/50000] Loss: 0.000561 Acc: 1.0000\n",
      "Train Epoch: 36 [12800/50000] Loss: 0.018063 Acc: 1.0000\n",
      "Train Epoch: 36 [14400/50000] Loss: 0.002627 Acc: 1.0000\n",
      "Train Epoch: 36 [16000/50000] Loss: 0.036328 Acc: 1.0000\n",
      "Train Epoch: 36 [17600/50000] Loss: 0.000525 Acc: 1.0000\n",
      "Train Epoch: 36 [19200/50000] Loss: 0.001606 Acc: 1.0000\n",
      "Train Epoch: 36 [20800/50000] Loss: 0.011542 Acc: 1.0000\n",
      "Train Epoch: 36 [22400/50000] Loss: 0.004995 Acc: 1.0000\n",
      "Train Epoch: 36 [24000/50000] Loss: 0.001200 Acc: 1.0000\n",
      "Train Epoch: 36 [25600/50000] Loss: 0.007193 Acc: 1.0000\n",
      "Train Epoch: 36 [27200/50000] Loss: 0.000726 Acc: 1.0000\n",
      "Train Epoch: 36 [28800/50000] Loss: 0.011784 Acc: 1.0000\n",
      "Train Epoch: 36 [30400/50000] Loss: 0.084515 Acc: 0.9375\n",
      "Train Epoch: 36 [32000/50000] Loss: 0.029589 Acc: 1.0000\n",
      "Train Epoch: 36 [33600/50000] Loss: 0.010019 Acc: 1.0000\n",
      "Train Epoch: 36 [35200/50000] Loss: 0.000223 Acc: 1.0000\n",
      "Train Epoch: 36 [36800/50000] Loss: 0.027287 Acc: 1.0000\n",
      "Train Epoch: 36 [38400/50000] Loss: 0.000839 Acc: 1.0000\n",
      "Train Epoch: 36 [40000/50000] Loss: 0.012139 Acc: 1.0000\n",
      "Train Epoch: 36 [41600/50000] Loss: 0.007366 Acc: 1.0000\n",
      "Train Epoch: 36 [43200/50000] Loss: 0.260854 Acc: 0.9375\n",
      "Train Epoch: 36 [44800/50000] Loss: 0.003684 Acc: 1.0000\n",
      "Train Epoch: 36 [46400/50000] Loss: 0.007159 Acc: 1.0000\n",
      "Train Epoch: 36 [48000/50000] Loss: 0.024948 Acc: 1.0000\n",
      "Train Epoch: 36 [49600/50000] Loss: 0.000837 Acc: 1.0000\n",
      "Elapsed 1782.88s, 48.19 s/epoch, 0.02 s/batch, ets 626.42s\n",
      "\n",
      "Test set: Average loss: 1.6279, Accuracy: 7433/10000 (74%)\n",
      "\n",
      "Train Epoch: 37 [1600/50000] Loss: 0.004599 Acc: 1.0000\n",
      "Train Epoch: 37 [3200/50000] Loss: 0.005990 Acc: 1.0000\n",
      "Train Epoch: 37 [4800/50000] Loss: 0.002272 Acc: 1.0000\n",
      "Train Epoch: 37 [6400/50000] Loss: 0.083252 Acc: 0.9375\n",
      "Train Epoch: 37 [8000/50000] Loss: 0.002864 Acc: 1.0000\n",
      "Train Epoch: 37 [9600/50000] Loss: 0.001734 Acc: 1.0000\n",
      "Train Epoch: 37 [11200/50000] Loss: 0.050941 Acc: 0.9375\n",
      "Train Epoch: 37 [12800/50000] Loss: 0.000126 Acc: 1.0000\n",
      "Train Epoch: 37 [14400/50000] Loss: 0.309736 Acc: 0.9375\n",
      "Train Epoch: 37 [16000/50000] Loss: 0.002024 Acc: 1.0000\n",
      "Train Epoch: 37 [17600/50000] Loss: 0.011379 Acc: 1.0000\n",
      "Train Epoch: 37 [19200/50000] Loss: 0.141306 Acc: 0.9375\n",
      "Train Epoch: 37 [20800/50000] Loss: 0.008804 Acc: 1.0000\n",
      "Train Epoch: 37 [22400/50000] Loss: 0.022343 Acc: 1.0000\n",
      "Train Epoch: 37 [24000/50000] Loss: 0.002934 Acc: 1.0000\n",
      "Train Epoch: 37 [25600/50000] Loss: 0.029406 Acc: 1.0000\n",
      "Train Epoch: 37 [27200/50000] Loss: 0.004602 Acc: 1.0000\n",
      "Train Epoch: 37 [28800/50000] Loss: 0.005655 Acc: 1.0000\n",
      "Train Epoch: 37 [30400/50000] Loss: 0.002587 Acc: 1.0000\n",
      "Train Epoch: 37 [32000/50000] Loss: 0.005037 Acc: 1.0000\n",
      "Train Epoch: 37 [33600/50000] Loss: 0.033490 Acc: 1.0000\n",
      "Train Epoch: 37 [35200/50000] Loss: 0.073699 Acc: 0.9375\n",
      "Train Epoch: 37 [36800/50000] Loss: 0.039626 Acc: 1.0000\n",
      "Train Epoch: 37 [38400/50000] Loss: 0.004701 Acc: 1.0000\n",
      "Train Epoch: 37 [40000/50000] Loss: 0.000511 Acc: 1.0000\n",
      "Train Epoch: 37 [41600/50000] Loss: 0.037461 Acc: 1.0000\n",
      "Train Epoch: 37 [43200/50000] Loss: 0.001364 Acc: 1.0000\n",
      "Train Epoch: 37 [44800/50000] Loss: 0.009038 Acc: 1.0000\n",
      "Train Epoch: 37 [46400/50000] Loss: 0.004566 Acc: 1.0000\n",
      "Train Epoch: 37 [48000/50000] Loss: 0.010825 Acc: 1.0000\n",
      "Train Epoch: 37 [49600/50000] Loss: 0.019624 Acc: 1.0000\n",
      "Elapsed 1826.97s, 48.08 s/epoch, 0.02 s/batch, ets 576.94s\n",
      "\n",
      "Test set: Average loss: 1.6885, Accuracy: 7433/10000 (74%)\n",
      "\n",
      "Train Epoch: 38 [1600/50000] Loss: 0.003882 Acc: 1.0000\n",
      "Train Epoch: 38 [3200/50000] Loss: 0.005789 Acc: 1.0000\n",
      "Train Epoch: 38 [4800/50000] Loss: 0.031399 Acc: 1.0000\n",
      "Train Epoch: 38 [6400/50000] Loss: 0.002670 Acc: 1.0000\n",
      "Train Epoch: 38 [8000/50000] Loss: 0.002033 Acc: 1.0000\n",
      "Train Epoch: 38 [9600/50000] Loss: 0.372776 Acc: 0.9375\n",
      "Train Epoch: 38 [11200/50000] Loss: 0.005436 Acc: 1.0000\n",
      "Train Epoch: 38 [12800/50000] Loss: 0.001482 Acc: 1.0000\n",
      "Train Epoch: 38 [14400/50000] Loss: 0.015197 Acc: 1.0000\n",
      "Train Epoch: 38 [16000/50000] Loss: 0.003412 Acc: 1.0000\n",
      "Train Epoch: 38 [17600/50000] Loss: 0.000801 Acc: 1.0000\n",
      "Train Epoch: 38 [19200/50000] Loss: 0.008973 Acc: 1.0000\n",
      "Train Epoch: 38 [20800/50000] Loss: 0.039610 Acc: 1.0000\n",
      "Train Epoch: 38 [22400/50000] Loss: 0.014115 Acc: 1.0000\n",
      "Train Epoch: 38 [24000/50000] Loss: 0.001924 Acc: 1.0000\n",
      "Train Epoch: 38 [25600/50000] Loss: 0.007777 Acc: 1.0000\n",
      "Train Epoch: 38 [27200/50000] Loss: 0.083944 Acc: 0.9375\n",
      "Train Epoch: 38 [28800/50000] Loss: 0.002333 Acc: 1.0000\n",
      "Train Epoch: 38 [30400/50000] Loss: 0.030377 Acc: 1.0000\n",
      "Train Epoch: 38 [32000/50000] Loss: 0.000531 Acc: 1.0000\n",
      "Train Epoch: 38 [33600/50000] Loss: 0.002050 Acc: 1.0000\n",
      "Train Epoch: 38 [35200/50000] Loss: 0.057644 Acc: 0.9375\n",
      "Train Epoch: 38 [36800/50000] Loss: 0.004433 Acc: 1.0000\n",
      "Train Epoch: 38 [38400/50000] Loss: 0.011383 Acc: 1.0000\n",
      "Train Epoch: 38 [40000/50000] Loss: 0.030427 Acc: 1.0000\n",
      "Train Epoch: 38 [41600/50000] Loss: 0.033690 Acc: 1.0000\n",
      "Train Epoch: 38 [43200/50000] Loss: 0.000216 Acc: 1.0000\n",
      "Train Epoch: 38 [44800/50000] Loss: 0.067199 Acc: 1.0000\n",
      "Train Epoch: 38 [46400/50000] Loss: 0.001965 Acc: 1.0000\n",
      "Train Epoch: 38 [48000/50000] Loss: 0.047013 Acc: 1.0000\n",
      "Train Epoch: 38 [49600/50000] Loss: 0.004460 Acc: 1.0000\n",
      "Elapsed 1869.85s, 47.94 s/epoch, 0.02 s/batch, ets 527.39s\n",
      "\n",
      "Test set: Average loss: 1.5882, Accuracy: 7349/10000 (73%)\n",
      "\n",
      "Train Epoch: 39 [1600/50000] Loss: 0.002336 Acc: 1.0000\n",
      "Train Epoch: 39 [3200/50000] Loss: 0.018822 Acc: 1.0000\n",
      "Train Epoch: 39 [4800/50000] Loss: 0.002582 Acc: 1.0000\n",
      "Train Epoch: 39 [6400/50000] Loss: 0.021603 Acc: 1.0000\n",
      "Train Epoch: 39 [8000/50000] Loss: 0.051870 Acc: 1.0000\n",
      "Train Epoch: 39 [9600/50000] Loss: 0.000908 Acc: 1.0000\n",
      "Train Epoch: 39 [11200/50000] Loss: 0.036121 Acc: 1.0000\n",
      "Train Epoch: 39 [12800/50000] Loss: 0.000450 Acc: 1.0000\n",
      "Train Epoch: 39 [14400/50000] Loss: 0.001383 Acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 39 [16000/50000] Loss: 0.013379 Acc: 1.0000\n",
      "Train Epoch: 39 [17600/50000] Loss: 0.026185 Acc: 1.0000\n",
      "Train Epoch: 39 [19200/50000] Loss: 0.010659 Acc: 1.0000\n",
      "Train Epoch: 39 [20800/50000] Loss: 0.003977 Acc: 1.0000\n",
      "Train Epoch: 39 [22400/50000] Loss: 0.001953 Acc: 1.0000\n",
      "Train Epoch: 39 [24000/50000] Loss: 0.008362 Acc: 1.0000\n",
      "Train Epoch: 39 [25600/50000] Loss: 0.008513 Acc: 1.0000\n",
      "Train Epoch: 39 [27200/50000] Loss: 0.002718 Acc: 1.0000\n",
      "Train Epoch: 39 [28800/50000] Loss: 0.002846 Acc: 1.0000\n",
      "Train Epoch: 39 [30400/50000] Loss: 0.269081 Acc: 0.9375\n",
      "Train Epoch: 39 [32000/50000] Loss: 0.000949 Acc: 1.0000\n",
      "Train Epoch: 39 [33600/50000] Loss: 0.007078 Acc: 1.0000\n",
      "Train Epoch: 39 [35200/50000] Loss: 0.008010 Acc: 1.0000\n",
      "Train Epoch: 39 [36800/50000] Loss: 0.005533 Acc: 1.0000\n",
      "Train Epoch: 39 [38400/50000] Loss: 0.002580 Acc: 1.0000\n",
      "Train Epoch: 39 [40000/50000] Loss: 0.003655 Acc: 1.0000\n",
      "Train Epoch: 39 [41600/50000] Loss: 0.001290 Acc: 1.0000\n",
      "Train Epoch: 39 [43200/50000] Loss: 0.054702 Acc: 0.9375\n",
      "Train Epoch: 39 [44800/50000] Loss: 0.036946 Acc: 1.0000\n",
      "Train Epoch: 39 [46400/50000] Loss: 0.004814 Acc: 1.0000\n",
      "Train Epoch: 39 [48000/50000] Loss: 0.005781 Acc: 1.0000\n",
      "Train Epoch: 39 [49600/50000] Loss: 0.000650 Acc: 1.0000\n",
      "Elapsed 1913.38s, 47.83 s/epoch, 0.02 s/batch, ets 478.34s\n",
      "\n",
      "Test set: Average loss: 1.7056, Accuracy: 7381/10000 (74%)\n",
      "\n",
      "Train Epoch: 40 [1600/50000] Loss: 0.072586 Acc: 1.0000\n",
      "Train Epoch: 40 [3200/50000] Loss: 0.010777 Acc: 1.0000\n",
      "Train Epoch: 40 [4800/50000] Loss: 0.014096 Acc: 1.0000\n",
      "Train Epoch: 40 [6400/50000] Loss: 0.000405 Acc: 1.0000\n",
      "Train Epoch: 40 [8000/50000] Loss: 0.003145 Acc: 1.0000\n",
      "Train Epoch: 40 [9600/50000] Loss: 0.008013 Acc: 1.0000\n",
      "Train Epoch: 40 [11200/50000] Loss: 0.008219 Acc: 1.0000\n",
      "Train Epoch: 40 [12800/50000] Loss: 0.011600 Acc: 1.0000\n",
      "Train Epoch: 40 [14400/50000] Loss: 0.143832 Acc: 0.9375\n",
      "Train Epoch: 40 [16000/50000] Loss: 0.022565 Acc: 1.0000\n",
      "Train Epoch: 40 [17600/50000] Loss: 0.003007 Acc: 1.0000\n",
      "Train Epoch: 40 [19200/50000] Loss: 0.048473 Acc: 1.0000\n",
      "Train Epoch: 40 [20800/50000] Loss: 0.010806 Acc: 1.0000\n",
      "Train Epoch: 40 [22400/50000] Loss: 0.015096 Acc: 1.0000\n",
      "Train Epoch: 40 [24000/50000] Loss: 0.000173 Acc: 1.0000\n",
      "Train Epoch: 40 [25600/50000] Loss: 0.004311 Acc: 1.0000\n",
      "Train Epoch: 40 [27200/50000] Loss: 0.001718 Acc: 1.0000\n",
      "Train Epoch: 40 [28800/50000] Loss: 0.079562 Acc: 1.0000\n",
      "Train Epoch: 40 [30400/50000] Loss: 0.012984 Acc: 1.0000\n",
      "Train Epoch: 40 [32000/50000] Loss: 0.007492 Acc: 1.0000\n",
      "Train Epoch: 40 [33600/50000] Loss: 0.000515 Acc: 1.0000\n",
      "Train Epoch: 40 [35200/50000] Loss: 0.001052 Acc: 1.0000\n",
      "Train Epoch: 40 [36800/50000] Loss: 0.001707 Acc: 1.0000\n",
      "Train Epoch: 40 [38400/50000] Loss: 0.001829 Acc: 1.0000\n",
      "Train Epoch: 40 [40000/50000] Loss: 0.012166 Acc: 1.0000\n",
      "Train Epoch: 40 [41600/50000] Loss: 0.000202 Acc: 1.0000\n",
      "Train Epoch: 40 [43200/50000] Loss: 0.000576 Acc: 1.0000\n",
      "Train Epoch: 40 [44800/50000] Loss: 0.016666 Acc: 1.0000\n",
      "Train Epoch: 40 [46400/50000] Loss: 0.189670 Acc: 0.9375\n",
      "Train Epoch: 40 [48000/50000] Loss: 0.002572 Acc: 1.0000\n",
      "Train Epoch: 40 [49600/50000] Loss: 0.010950 Acc: 1.0000\n",
      "Elapsed 1955.80s, 47.70 s/epoch, 0.02 s/batch, ets 429.32s\n",
      "\n",
      "Test set: Average loss: 1.7509, Accuracy: 7334/10000 (73%)\n",
      "\n",
      "Train Epoch: 41 [1600/50000] Loss: 0.006731 Acc: 1.0000\n",
      "Train Epoch: 41 [3200/50000] Loss: 0.007046 Acc: 1.0000\n",
      "Train Epoch: 41 [4800/50000] Loss: 0.001393 Acc: 1.0000\n",
      "Train Epoch: 41 [6400/50000] Loss: 0.000478 Acc: 1.0000\n",
      "Train Epoch: 41 [8000/50000] Loss: 0.029670 Acc: 1.0000\n",
      "Train Epoch: 41 [9600/50000] Loss: 0.047214 Acc: 1.0000\n",
      "Train Epoch: 41 [11200/50000] Loss: 0.000110 Acc: 1.0000\n",
      "Train Epoch: 41 [12800/50000] Loss: 0.014372 Acc: 1.0000\n",
      "Train Epoch: 41 [14400/50000] Loss: 0.004979 Acc: 1.0000\n",
      "Train Epoch: 41 [16000/50000] Loss: 0.003024 Acc: 1.0000\n",
      "Train Epoch: 41 [17600/50000] Loss: 0.007853 Acc: 1.0000\n",
      "Train Epoch: 41 [19200/50000] Loss: 0.027557 Acc: 1.0000\n",
      "Train Epoch: 41 [20800/50000] Loss: 0.020692 Acc: 1.0000\n",
      "Train Epoch: 41 [22400/50000] Loss: 0.002128 Acc: 1.0000\n",
      "Train Epoch: 41 [24000/50000] Loss: 0.002621 Acc: 1.0000\n",
      "Train Epoch: 41 [25600/50000] Loss: 0.001420 Acc: 1.0000\n",
      "Train Epoch: 41 [27200/50000] Loss: 0.000600 Acc: 1.0000\n",
      "Train Epoch: 41 [28800/50000] Loss: 0.000656 Acc: 1.0000\n",
      "Train Epoch: 41 [30400/50000] Loss: 0.035756 Acc: 1.0000\n",
      "Train Epoch: 41 [32000/50000] Loss: 0.027477 Acc: 1.0000\n",
      "Train Epoch: 41 [33600/50000] Loss: 0.014381 Acc: 1.0000\n",
      "Train Epoch: 41 [35200/50000] Loss: 0.005943 Acc: 1.0000\n",
      "Train Epoch: 41 [36800/50000] Loss: 0.012770 Acc: 1.0000\n",
      "Train Epoch: 41 [38400/50000] Loss: 0.000719 Acc: 1.0000\n",
      "Train Epoch: 41 [40000/50000] Loss: 0.023049 Acc: 1.0000\n",
      "Train Epoch: 41 [41600/50000] Loss: 0.015914 Acc: 1.0000\n",
      "Train Epoch: 41 [43200/50000] Loss: 0.004908 Acc: 1.0000\n",
      "Train Epoch: 41 [44800/50000] Loss: 0.022133 Acc: 1.0000\n",
      "Train Epoch: 41 [46400/50000] Loss: 0.029734 Acc: 1.0000\n",
      "Train Epoch: 41 [48000/50000] Loss: 0.081636 Acc: 0.9375\n",
      "Train Epoch: 41 [49600/50000] Loss: 0.178305 Acc: 0.9375\n",
      "Elapsed 1998.57s, 47.58 s/epoch, 0.02 s/batch, ets 380.68s\n",
      "\n",
      "Test set: Average loss: 1.7120, Accuracy: 7406/10000 (74%)\n",
      "\n",
      "Train Epoch: 42 [1600/50000] Loss: 0.002844 Acc: 1.0000\n",
      "Train Epoch: 42 [3200/50000] Loss: 0.000239 Acc: 1.0000\n",
      "Train Epoch: 42 [4800/50000] Loss: 0.001605 Acc: 1.0000\n",
      "Train Epoch: 42 [6400/50000] Loss: 0.002129 Acc: 1.0000\n",
      "Train Epoch: 42 [8000/50000] Loss: 0.002137 Acc: 1.0000\n",
      "Train Epoch: 42 [9600/50000] Loss: 0.002909 Acc: 1.0000\n",
      "Train Epoch: 42 [11200/50000] Loss: 0.117660 Acc: 0.9375\n",
      "Train Epoch: 42 [12800/50000] Loss: 0.006109 Acc: 1.0000\n",
      "Train Epoch: 42 [14400/50000] Loss: 0.005654 Acc: 1.0000\n",
      "Train Epoch: 42 [16000/50000] Loss: 0.002404 Acc: 1.0000\n",
      "Train Epoch: 42 [17600/50000] Loss: 0.005283 Acc: 1.0000\n",
      "Train Epoch: 42 [19200/50000] Loss: 0.006525 Acc: 1.0000\n",
      "Train Epoch: 42 [20800/50000] Loss: 0.024213 Acc: 1.0000\n",
      "Train Epoch: 42 [22400/50000] Loss: 0.093134 Acc: 0.9375\n",
      "Train Epoch: 42 [24000/50000] Loss: 0.002902 Acc: 1.0000\n",
      "Train Epoch: 42 [25600/50000] Loss: 0.018094 Acc: 1.0000\n",
      "Train Epoch: 42 [27200/50000] Loss: 0.002197 Acc: 1.0000\n",
      "Train Epoch: 42 [28800/50000] Loss: 0.001122 Acc: 1.0000\n",
      "Train Epoch: 42 [30400/50000] Loss: 0.042147 Acc: 1.0000\n",
      "Train Epoch: 42 [32000/50000] Loss: 0.005136 Acc: 1.0000\n",
      "Train Epoch: 42 [33600/50000] Loss: 0.005766 Acc: 1.0000\n",
      "Train Epoch: 42 [35200/50000] Loss: 0.007707 Acc: 1.0000\n",
      "Train Epoch: 42 [36800/50000] Loss: 0.005520 Acc: 1.0000\n",
      "Train Epoch: 42 [38400/50000] Loss: 0.002667 Acc: 1.0000\n",
      "Train Epoch: 42 [40000/50000] Loss: 0.000326 Acc: 1.0000\n",
      "Train Epoch: 42 [41600/50000] Loss: 0.000227 Acc: 1.0000\n",
      "Train Epoch: 42 [43200/50000] Loss: 0.007753 Acc: 1.0000\n",
      "Train Epoch: 42 [44800/50000] Loss: 0.004458 Acc: 1.0000\n",
      "Train Epoch: 42 [46400/50000] Loss: 0.013612 Acc: 1.0000\n",
      "Train Epoch: 42 [48000/50000] Loss: 0.060100 Acc: 0.9375\n",
      "Train Epoch: 42 [49600/50000] Loss: 0.172807 Acc: 0.9375\n",
      "Elapsed 2040.88s, 47.46 s/epoch, 0.02 s/batch, ets 332.24s\n",
      "\n",
      "Test set: Average loss: 1.7936, Accuracy: 7397/10000 (74%)\n",
      "\n",
      "Train Epoch: 43 [1600/50000] Loss: 0.003891 Acc: 1.0000\n",
      "Train Epoch: 43 [3200/50000] Loss: 0.000911 Acc: 1.0000\n",
      "Train Epoch: 43 [4800/50000] Loss: 0.002500 Acc: 1.0000\n",
      "Train Epoch: 43 [6400/50000] Loss: 0.000543 Acc: 1.0000\n",
      "Train Epoch: 43 [8000/50000] Loss: 0.001218 Acc: 1.0000\n",
      "Train Epoch: 43 [9600/50000] Loss: 0.011364 Acc: 1.0000\n",
      "Train Epoch: 43 [11200/50000] Loss: 0.007127 Acc: 1.0000\n",
      "Train Epoch: 43 [12800/50000] Loss: 0.000791 Acc: 1.0000\n",
      "Train Epoch: 43 [14400/50000] Loss: 0.027099 Acc: 1.0000\n",
      "Train Epoch: 43 [16000/50000] Loss: 0.002028 Acc: 1.0000\n",
      "Train Epoch: 43 [17600/50000] Loss: 0.000307 Acc: 1.0000\n",
      "Train Epoch: 43 [19200/50000] Loss: 0.000491 Acc: 1.0000\n",
      "Train Epoch: 43 [20800/50000] Loss: 0.067302 Acc: 0.9375\n",
      "Train Epoch: 43 [22400/50000] Loss: 0.013894 Acc: 1.0000\n",
      "Train Epoch: 43 [24000/50000] Loss: 0.000809 Acc: 1.0000\n",
      "Train Epoch: 43 [25600/50000] Loss: 0.000203 Acc: 1.0000\n",
      "Train Epoch: 43 [27200/50000] Loss: 0.008854 Acc: 1.0000\n",
      "Train Epoch: 43 [28800/50000] Loss: 0.000167 Acc: 1.0000\n",
      "Train Epoch: 43 [30400/50000] Loss: 0.000092 Acc: 1.0000\n",
      "Train Epoch: 43 [32000/50000] Loss: 0.002000 Acc: 1.0000\n",
      "Train Epoch: 43 [33600/50000] Loss: 0.001483 Acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 43 [35200/50000] Loss: 0.000165 Acc: 1.0000\n",
      "Train Epoch: 43 [36800/50000] Loss: 0.000765 Acc: 1.0000\n",
      "Train Epoch: 43 [38400/50000] Loss: 0.055526 Acc: 0.9375\n",
      "Train Epoch: 43 [40000/50000] Loss: 0.030696 Acc: 1.0000\n",
      "Train Epoch: 43 [41600/50000] Loss: 0.000312 Acc: 1.0000\n",
      "Train Epoch: 43 [43200/50000] Loss: 0.025749 Acc: 1.0000\n",
      "Train Epoch: 43 [44800/50000] Loss: 0.000257 Acc: 1.0000\n",
      "Train Epoch: 43 [46400/50000] Loss: 0.281767 Acc: 0.8750\n",
      "Train Epoch: 43 [48000/50000] Loss: 0.151038 Acc: 0.9375\n",
      "Train Epoch: 43 [49600/50000] Loss: 0.002658 Acc: 1.0000\n",
      "Elapsed 2084.03s, 47.36 s/epoch, 0.02 s/batch, ets 284.19s\n",
      "\n",
      "Test set: Average loss: 1.7610, Accuracy: 7388/10000 (74%)\n",
      "\n",
      "Train Epoch: 44 [1600/50000] Loss: 0.177527 Acc: 0.9375\n",
      "Train Epoch: 44 [3200/50000] Loss: 0.025384 Acc: 1.0000\n",
      "Train Epoch: 44 [4800/50000] Loss: 0.003236 Acc: 1.0000\n",
      "Train Epoch: 44 [6400/50000] Loss: 0.000098 Acc: 1.0000\n",
      "Train Epoch: 44 [8000/50000] Loss: 0.000046 Acc: 1.0000\n",
      "Train Epoch: 44 [9600/50000] Loss: 0.002664 Acc: 1.0000\n",
      "Train Epoch: 44 [11200/50000] Loss: 0.031971 Acc: 1.0000\n",
      "Train Epoch: 44 [12800/50000] Loss: 0.007483 Acc: 1.0000\n",
      "Train Epoch: 44 [14400/50000] Loss: 0.000189 Acc: 1.0000\n",
      "Train Epoch: 44 [16000/50000] Loss: 0.003789 Acc: 1.0000\n",
      "Train Epoch: 44 [17600/50000] Loss: 0.050675 Acc: 1.0000\n",
      "Train Epoch: 44 [19200/50000] Loss: 0.006547 Acc: 1.0000\n",
      "Train Epoch: 44 [20800/50000] Loss: 0.030871 Acc: 1.0000\n",
      "Train Epoch: 44 [22400/50000] Loss: 0.123374 Acc: 0.9375\n",
      "Train Epoch: 44 [24000/50000] Loss: 0.002754 Acc: 1.0000\n",
      "Train Epoch: 44 [25600/50000] Loss: 0.006802 Acc: 1.0000\n",
      "Train Epoch: 44 [27200/50000] Loss: 0.002130 Acc: 1.0000\n",
      "Train Epoch: 44 [28800/50000] Loss: 0.008482 Acc: 1.0000\n",
      "Train Epoch: 44 [30400/50000] Loss: 0.000753 Acc: 1.0000\n",
      "Train Epoch: 44 [32000/50000] Loss: 0.001125 Acc: 1.0000\n",
      "Train Epoch: 44 [33600/50000] Loss: 0.001077 Acc: 1.0000\n",
      "Train Epoch: 44 [35200/50000] Loss: 0.014954 Acc: 1.0000\n",
      "Train Epoch: 44 [36800/50000] Loss: 0.014529 Acc: 1.0000\n",
      "Train Epoch: 44 [38400/50000] Loss: 0.001448 Acc: 1.0000\n",
      "Train Epoch: 44 [40000/50000] Loss: 0.002329 Acc: 1.0000\n",
      "Train Epoch: 44 [41600/50000] Loss: 0.000185 Acc: 1.0000\n",
      "Train Epoch: 44 [43200/50000] Loss: 0.067648 Acc: 0.9375\n",
      "Train Epoch: 44 [44800/50000] Loss: 0.003562 Acc: 1.0000\n",
      "Train Epoch: 44 [46400/50000] Loss: 0.007290 Acc: 1.0000\n",
      "Train Epoch: 44 [48000/50000] Loss: 0.120424 Acc: 0.9375\n",
      "Train Epoch: 44 [49600/50000] Loss: 0.003265 Acc: 1.0000\n",
      "Elapsed 2126.77s, 47.26 s/epoch, 0.02 s/batch, ets 236.31s\n",
      "\n",
      "Test set: Average loss: 1.8369, Accuracy: 7448/10000 (74%)\n",
      "\n",
      "Train Epoch: 45 [1600/50000] Loss: 0.000876 Acc: 1.0000\n",
      "Train Epoch: 45 [3200/50000] Loss: 0.006291 Acc: 1.0000\n",
      "Train Epoch: 45 [4800/50000] Loss: 0.001353 Acc: 1.0000\n",
      "Train Epoch: 45 [6400/50000] Loss: 0.040139 Acc: 1.0000\n",
      "Train Epoch: 45 [8000/50000] Loss: 0.001927 Acc: 1.0000\n",
      "Train Epoch: 45 [9600/50000] Loss: 0.042948 Acc: 1.0000\n",
      "Train Epoch: 45 [11200/50000] Loss: 0.001309 Acc: 1.0000\n",
      "Train Epoch: 45 [12800/50000] Loss: 0.001108 Acc: 1.0000\n",
      "Train Epoch: 45 [14400/50000] Loss: 0.000022 Acc: 1.0000\n",
      "Train Epoch: 45 [16000/50000] Loss: 0.002652 Acc: 1.0000\n",
      "Train Epoch: 45 [17600/50000] Loss: 0.000071 Acc: 1.0000\n",
      "Train Epoch: 45 [19200/50000] Loss: 0.000411 Acc: 1.0000\n",
      "Train Epoch: 45 [20800/50000] Loss: 0.002508 Acc: 1.0000\n",
      "Train Epoch: 45 [22400/50000] Loss: 0.003592 Acc: 1.0000\n",
      "Train Epoch: 45 [24000/50000] Loss: 0.005836 Acc: 1.0000\n",
      "Train Epoch: 45 [25600/50000] Loss: 0.001497 Acc: 1.0000\n",
      "Train Epoch: 45 [27200/50000] Loss: 0.000557 Acc: 1.0000\n",
      "Train Epoch: 45 [28800/50000] Loss: 0.002094 Acc: 1.0000\n",
      "Train Epoch: 45 [30400/50000] Loss: 0.003337 Acc: 1.0000\n",
      "Train Epoch: 45 [32000/50000] Loss: 0.004134 Acc: 1.0000\n",
      "Train Epoch: 45 [33600/50000] Loss: 0.002897 Acc: 1.0000\n",
      "Train Epoch: 45 [35200/50000] Loss: 0.000937 Acc: 1.0000\n",
      "Train Epoch: 45 [36800/50000] Loss: 0.002003 Acc: 1.0000\n",
      "Train Epoch: 45 [38400/50000] Loss: 0.018970 Acc: 1.0000\n",
      "Train Epoch: 45 [40000/50000] Loss: 0.015657 Acc: 1.0000\n",
      "Train Epoch: 45 [41600/50000] Loss: 0.006083 Acc: 1.0000\n",
      "Train Epoch: 45 [43200/50000] Loss: 0.007838 Acc: 1.0000\n",
      "Train Epoch: 45 [44800/50000] Loss: 0.003355 Acc: 1.0000\n",
      "Train Epoch: 45 [46400/50000] Loss: 0.002864 Acc: 1.0000\n",
      "Train Epoch: 45 [48000/50000] Loss: 0.005133 Acc: 1.0000\n",
      "Train Epoch: 45 [49600/50000] Loss: 0.001986 Acc: 1.0000\n",
      "Elapsed 2169.23s, 47.16 s/epoch, 0.02 s/batch, ets 188.63s\n",
      "\n",
      "Test set: Average loss: 1.8044, Accuracy: 7414/10000 (74%)\n",
      "\n",
      "Train Epoch: 46 [1600/50000] Loss: 0.006484 Acc: 1.0000\n",
      "Train Epoch: 46 [3200/50000] Loss: 0.005401 Acc: 1.0000\n",
      "Train Epoch: 46 [4800/50000] Loss: 0.042977 Acc: 1.0000\n",
      "Train Epoch: 46 [6400/50000] Loss: 0.000683 Acc: 1.0000\n",
      "Train Epoch: 46 [8000/50000] Loss: 0.007570 Acc: 1.0000\n",
      "Train Epoch: 46 [9600/50000] Loss: 0.016388 Acc: 1.0000\n",
      "Train Epoch: 46 [11200/50000] Loss: 0.007450 Acc: 1.0000\n",
      "Train Epoch: 46 [12800/50000] Loss: 0.000204 Acc: 1.0000\n",
      "Train Epoch: 46 [14400/50000] Loss: 0.002611 Acc: 1.0000\n",
      "Train Epoch: 46 [16000/50000] Loss: 0.005405 Acc: 1.0000\n",
      "Train Epoch: 46 [17600/50000] Loss: 0.002183 Acc: 1.0000\n",
      "Train Epoch: 46 [19200/50000] Loss: 0.002035 Acc: 1.0000\n",
      "Train Epoch: 46 [20800/50000] Loss: 0.000988 Acc: 1.0000\n",
      "Train Epoch: 46 [22400/50000] Loss: 0.000834 Acc: 1.0000\n",
      "Train Epoch: 46 [24000/50000] Loss: 0.003041 Acc: 1.0000\n",
      "Train Epoch: 46 [25600/50000] Loss: 0.000493 Acc: 1.0000\n",
      "Train Epoch: 46 [27200/50000] Loss: 0.013877 Acc: 1.0000\n",
      "Train Epoch: 46 [28800/50000] Loss: 0.019618 Acc: 1.0000\n",
      "Train Epoch: 46 [30400/50000] Loss: 0.000068 Acc: 1.0000\n",
      "Train Epoch: 46 [32000/50000] Loss: 0.025483 Acc: 1.0000\n",
      "Train Epoch: 46 [33600/50000] Loss: 0.305181 Acc: 0.8750\n",
      "Train Epoch: 46 [35200/50000] Loss: 0.003291 Acc: 1.0000\n",
      "Train Epoch: 46 [36800/50000] Loss: 0.006889 Acc: 1.0000\n",
      "Train Epoch: 46 [38400/50000] Loss: 0.005192 Acc: 1.0000\n",
      "Train Epoch: 46 [40000/50000] Loss: 0.009729 Acc: 1.0000\n",
      "Train Epoch: 46 [41600/50000] Loss: 0.002163 Acc: 1.0000\n",
      "Train Epoch: 46 [43200/50000] Loss: 0.006916 Acc: 1.0000\n",
      "Train Epoch: 46 [44800/50000] Loss: 0.000278 Acc: 1.0000\n",
      "Train Epoch: 46 [46400/50000] Loss: 0.414614 Acc: 0.8750\n",
      "Train Epoch: 46 [48000/50000] Loss: 0.046132 Acc: 1.0000\n",
      "Train Epoch: 46 [49600/50000] Loss: 0.002291 Acc: 1.0000\n",
      "Elapsed 2212.05s, 47.06 s/epoch, 0.02 s/batch, ets 141.19s\n",
      "\n",
      "Test set: Average loss: 1.7655, Accuracy: 7452/10000 (75%)\n",
      "\n",
      "Train Epoch: 47 [1600/50000] Loss: 0.000030 Acc: 1.0000\n",
      "Train Epoch: 47 [3200/50000] Loss: 0.000495 Acc: 1.0000\n",
      "Train Epoch: 47 [4800/50000] Loss: 0.016064 Acc: 1.0000\n",
      "Train Epoch: 47 [6400/50000] Loss: 0.139696 Acc: 0.9375\n",
      "Train Epoch: 47 [8000/50000] Loss: 0.039734 Acc: 1.0000\n",
      "Train Epoch: 47 [9600/50000] Loss: 0.027688 Acc: 1.0000\n",
      "Train Epoch: 47 [11200/50000] Loss: 0.001450 Acc: 1.0000\n",
      "Train Epoch: 47 [12800/50000] Loss: 0.004360 Acc: 1.0000\n",
      "Train Epoch: 47 [14400/50000] Loss: 0.000296 Acc: 1.0000\n",
      "Train Epoch: 47 [16000/50000] Loss: 0.000406 Acc: 1.0000\n",
      "Train Epoch: 47 [17600/50000] Loss: 0.001139 Acc: 1.0000\n",
      "Train Epoch: 47 [19200/50000] Loss: 0.002501 Acc: 1.0000\n",
      "Train Epoch: 47 [20800/50000] Loss: 0.019167 Acc: 1.0000\n",
      "Train Epoch: 47 [22400/50000] Loss: 0.028726 Acc: 1.0000\n",
      "Train Epoch: 47 [24000/50000] Loss: 0.049547 Acc: 1.0000\n",
      "Train Epoch: 47 [25600/50000] Loss: 0.001506 Acc: 1.0000\n",
      "Train Epoch: 47 [27200/50000] Loss: 0.026796 Acc: 1.0000\n",
      "Train Epoch: 47 [28800/50000] Loss: 0.000561 Acc: 1.0000\n",
      "Train Epoch: 47 [30400/50000] Loss: 0.322500 Acc: 0.9375\n",
      "Train Epoch: 47 [32000/50000] Loss: 0.000155 Acc: 1.0000\n",
      "Train Epoch: 47 [33600/50000] Loss: 0.016276 Acc: 1.0000\n",
      "Train Epoch: 47 [35200/50000] Loss: 0.000536 Acc: 1.0000\n",
      "Train Epoch: 47 [36800/50000] Loss: 0.000567 Acc: 1.0000\n",
      "Train Epoch: 47 [38400/50000] Loss: 0.000324 Acc: 1.0000\n",
      "Train Epoch: 47 [40000/50000] Loss: 0.000224 Acc: 1.0000\n",
      "Train Epoch: 47 [41600/50000] Loss: 0.000335 Acc: 1.0000\n",
      "Train Epoch: 47 [43200/50000] Loss: 0.001315 Acc: 1.0000\n",
      "Train Epoch: 47 [44800/50000] Loss: 0.145091 Acc: 0.9375\n",
      "Train Epoch: 47 [46400/50000] Loss: 0.003174 Acc: 1.0000\n",
      "Train Epoch: 47 [48000/50000] Loss: 0.000871 Acc: 1.0000\n",
      "Train Epoch: 47 [49600/50000] Loss: 0.006189 Acc: 1.0000\n",
      "Elapsed 2255.12s, 46.98 s/epoch, 0.02 s/batch, ets 93.96s\n",
      "\n",
      "Test set: Average loss: 1.8310, Accuracy: 7379/10000 (74%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 48 [1600/50000] Loss: 0.006228 Acc: 1.0000\n",
      "Train Epoch: 48 [3200/50000] Loss: 0.000233 Acc: 1.0000\n",
      "Train Epoch: 48 [4800/50000] Loss: 0.003804 Acc: 1.0000\n",
      "Train Epoch: 48 [6400/50000] Loss: 0.000073 Acc: 1.0000\n",
      "Train Epoch: 48 [8000/50000] Loss: 0.002108 Acc: 1.0000\n",
      "Train Epoch: 48 [9600/50000] Loss: 0.004032 Acc: 1.0000\n",
      "Train Epoch: 48 [11200/50000] Loss: 0.003632 Acc: 1.0000\n",
      "Train Epoch: 48 [12800/50000] Loss: 0.002120 Acc: 1.0000\n",
      "Train Epoch: 48 [14400/50000] Loss: 0.000524 Acc: 1.0000\n",
      "Train Epoch: 48 [16000/50000] Loss: 0.002773 Acc: 1.0000\n",
      "Train Epoch: 48 [17600/50000] Loss: 0.000923 Acc: 1.0000\n",
      "Train Epoch: 48 [19200/50000] Loss: 0.000585 Acc: 1.0000\n",
      "Train Epoch: 48 [20800/50000] Loss: 0.000243 Acc: 1.0000\n",
      "Train Epoch: 48 [22400/50000] Loss: 0.004657 Acc: 1.0000\n",
      "Train Epoch: 48 [24000/50000] Loss: 0.001050 Acc: 1.0000\n",
      "Train Epoch: 48 [25600/50000] Loss: 0.003753 Acc: 1.0000\n",
      "Train Epoch: 48 [27200/50000] Loss: 0.012207 Acc: 1.0000\n",
      "Train Epoch: 48 [28800/50000] Loss: 0.000247 Acc: 1.0000\n",
      "Train Epoch: 48 [30400/50000] Loss: 0.084050 Acc: 0.9375\n",
      "Train Epoch: 48 [32000/50000] Loss: 0.007164 Acc: 1.0000\n",
      "Train Epoch: 48 [33600/50000] Loss: 0.007475 Acc: 1.0000\n",
      "Train Epoch: 48 [35200/50000] Loss: 0.014543 Acc: 1.0000\n",
      "Train Epoch: 48 [36800/50000] Loss: 0.004051 Acc: 1.0000\n",
      "Train Epoch: 48 [38400/50000] Loss: 0.006031 Acc: 1.0000\n",
      "Train Epoch: 48 [40000/50000] Loss: 0.002020 Acc: 1.0000\n",
      "Train Epoch: 48 [41600/50000] Loss: 0.002344 Acc: 1.0000\n",
      "Train Epoch: 48 [43200/50000] Loss: 0.003244 Acc: 1.0000\n",
      "Train Epoch: 48 [44800/50000] Loss: 0.049746 Acc: 1.0000\n",
      "Train Epoch: 48 [46400/50000] Loss: 0.000035 Acc: 1.0000\n",
      "Train Epoch: 48 [48000/50000] Loss: 0.275897 Acc: 0.9375\n",
      "Train Epoch: 48 [49600/50000] Loss: 0.036859 Acc: 1.0000\n",
      "Elapsed 2363.00s, 48.22 s/epoch, 0.02 s/batch, ets 48.22s\n",
      "\n",
      "Test set: Average loss: 1.9130, Accuracy: 7304/10000 (73%)\n",
      "\n",
      "Train Epoch: 49 [1600/50000] Loss: 0.022173 Acc: 1.0000\n",
      "Train Epoch: 49 [3200/50000] Loss: 0.001567 Acc: 1.0000\n",
      "Train Epoch: 49 [4800/50000] Loss: 0.010098 Acc: 1.0000\n",
      "Train Epoch: 49 [6400/50000] Loss: 0.000699 Acc: 1.0000\n",
      "Train Epoch: 49 [8000/50000] Loss: 0.005343 Acc: 1.0000\n",
      "Train Epoch: 49 [9600/50000] Loss: 0.000517 Acc: 1.0000\n",
      "Train Epoch: 49 [11200/50000] Loss: 0.000354 Acc: 1.0000\n",
      "Train Epoch: 49 [12800/50000] Loss: 0.001170 Acc: 1.0000\n",
      "Train Epoch: 49 [14400/50000] Loss: 0.000465 Acc: 1.0000\n",
      "Train Epoch: 49 [16000/50000] Loss: 0.326168 Acc: 0.9375\n",
      "Train Epoch: 49 [17600/50000] Loss: 0.017441 Acc: 1.0000\n",
      "Train Epoch: 49 [19200/50000] Loss: 0.578035 Acc: 0.9375\n",
      "Train Epoch: 49 [20800/50000] Loss: 0.010066 Acc: 1.0000\n",
      "Train Epoch: 49 [22400/50000] Loss: 0.028326 Acc: 1.0000\n",
      "Train Epoch: 49 [24000/50000] Loss: 0.017785 Acc: 1.0000\n",
      "Train Epoch: 49 [25600/50000] Loss: 0.011699 Acc: 1.0000\n",
      "Train Epoch: 49 [27200/50000] Loss: 0.003589 Acc: 1.0000\n",
      "Train Epoch: 49 [28800/50000] Loss: 0.002924 Acc: 1.0000\n",
      "Train Epoch: 49 [30400/50000] Loss: 0.000100 Acc: 1.0000\n",
      "Train Epoch: 49 [32000/50000] Loss: 0.000311 Acc: 1.0000\n",
      "Train Epoch: 49 [33600/50000] Loss: 0.003843 Acc: 1.0000\n",
      "Train Epoch: 49 [35200/50000] Loss: 0.000453 Acc: 1.0000\n",
      "Train Epoch: 49 [36800/50000] Loss: 0.000555 Acc: 1.0000\n",
      "Train Epoch: 49 [38400/50000] Loss: 0.000390 Acc: 1.0000\n",
      "Train Epoch: 49 [40000/50000] Loss: 0.028776 Acc: 1.0000\n",
      "Train Epoch: 49 [41600/50000] Loss: 0.000871 Acc: 1.0000\n",
      "Train Epoch: 49 [43200/50000] Loss: 0.004720 Acc: 1.0000\n",
      "Train Epoch: 49 [44800/50000] Loss: 0.001034 Acc: 1.0000\n",
      "Train Epoch: 49 [46400/50000] Loss: 0.028365 Acc: 1.0000\n",
      "Train Epoch: 49 [48000/50000] Loss: 0.004974 Acc: 1.0000\n",
      "Train Epoch: 49 [49600/50000] Loss: 0.001046 Acc: 1.0000\n",
      "Elapsed 2484.02s, 49.68 s/epoch, 0.02 s/batch, ets 0.00s\n",
      "\n",
      "Test set: Average loss: 1.8268, Accuracy: 7365/10000 (74%)\n",
      "\n",
      "Total time: 2489.73, Best Loss: 0.782, Best Accuracy: 0.748\n"
     ]
    }
   ],
   "source": [
    "if required_training:\n",
    "    model, epoch_train_loss, epoch_train_acc, epoch_test_loss, epoch_test_acc = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# <font style=\"color:blue\">12. Plot Loss</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false,
    "lines_to_next_cell": 2,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot loss\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "x = range(len(epoch_train_loss))\n",
    "\n",
    "\n",
    "plt.figure\n",
    "plt.plot(x, epoch_train_loss, color='r', label=\"train loss\")\n",
    "plt.plot(x, epoch_test_loss, color='b', label=\"validation loss\")\n",
    "plt.xlabel('epoch no.')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# <font style=\"color:blue\">13. Plot Accuracy</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot loss\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "x = range(len(epoch_train_loss))\n",
    "\n",
    "\n",
    "plt.figure\n",
    "plt.plot(x, epoch_train_acc, color='r', label=\"train accuracy\")\n",
    "plt.plot(x, epoch_test_acc, color='b', label=\"validation accuracy\")\n",
    "plt.xlabel('epoch no.')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(loc='center right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# <font style=\"color:blue\">14. Loading the Model </font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize the model\n",
    "cnn_model = MyModel()\n",
    "\n",
    "models = 'models'\n",
    "\n",
    "model_file_name = 'cifar10_cnn_model.pt'\n",
    "\n",
    "model_path = os.path.join(models, model_file_name)\n",
    "\n",
    "# loading the model and getting model parameters by using load_state_dict\n",
    "cnn_model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# <font style=\"color:blue\">15. Model Prediction</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def prediction(model, train_config, batch_input):\n",
    "    \n",
    "    # send model to cpu/cuda according to your system configuration\n",
    "    model.to(train_config.device)\n",
    "    \n",
    "    # it is important to do model.eval() before prediction\n",
    "    model.eval()\n",
    "\n",
    "    data = batch_input.to(train_config.device)\n",
    "\n",
    "    output = model(data)\n",
    "\n",
    "    # Score to probability using softmax\n",
    "    prob = F.softmax(output, dim=1)\n",
    "\n",
    "    # get the max probability\n",
    "    pred_prob = prob.data.max(dim=1)[0]\n",
    "    \n",
    "    # get the index of the max probability\n",
    "    pred_index = prob.data.max(dim=1)[1]\n",
    "    \n",
    "    return pred_index.cpu().numpy(), pred_prob.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# <font style=\"color:blue\">16. Perform Inference on sample images </font>\n",
    "\n",
    "For prediction, we need to transform the data in the same way as we have done during training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false,
    "lines_to_next_cell": 2,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADSCAYAAAAPFY9jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO2deZRkd3Xfv7f2pbun92Wme6Zn1WhDI1kLIEDslgUcCeIQgw+RExzANgEcEoIxdmSQT/AxS5wDwUZGkRIcSQRQwA4KkmWBEAKBNAgtM9Jolp6Znt6m973WX/54r0VVfW+9qZmeKXUP93NOn666b/u95db73fu79/7EOQfDMHRCL3UDDGMtYwpiGAGYghhGAKYghhGAKYhhBGAKYhgBrGsFEZF+EXEiEjnD7e8QkVvPdrtK9n+RiDwuInKujlHluG8TkXvqdCwnIjvO9bYi0iUiD4vInIh87kyOdyaccwURkQERWRKReREZ9R/KhnN93DXCpwF81vmDTSLSKiL3isiCiBwVkXdX21BE/lBEDovIrIgMicgXSn8IROTTIvK0iORF5JbSbZ1zfw/gYhF5WS2NXO0PTZ14H4BxAE3OuY/W66D1eoO8zTnXAOAKAFcC+GTlCuKxrt9oK4hIRER6ALwOwP8pWfQlAFkAXQB+G8CXReTiKrv5DoArnHNNAC4BcBmAD5UsPwjgYwD+b5Xt74L3UJ0vbAGwz1UZ2T5Xyl3XB9I5dwLAffBuOETk+yLy5yLyIwCLALaJyAYR+aqIDIvICRG5VUTC/vphEfmsiIyLyGEAbzmd44vI5SKy139N3wMgUbH8rSLypIhMi8ijpb/AIrJRRL4pIidF5IiIfKhk2S0i8g0R+ZqIzAL4HQBvArDXObfsr5MG8M8A/Ilzbt459wg8JXhPlWt1yDk3vXIIAEUAO0qW3+mcuw/AXJXT/T5O8/poiMjVIvJj/5oMi8gXRSRWsdoN/ttuXET+svSHTkT+tYjsF5EpEfmeiGw5gzbcAeBmAB/zeyJv1K65iMRF5L/4b9wh/3O8ZD8f889hSER+t6YunnPunP4BGADwRv9zH4BnAXza//59AMcAXAwgAiAK4F4AfwMgDaATwE8BvN9f/wMAnvP30wrgIQAOQMRf/nEA/1ClHTEARwH8oX+c3wSQA3Crv/xyAGMArgEQ9m/IAIA4vB+SJwD8qb+fbQAOA/h1f9tb/H3d5K+bBPCXAL5UcvzLASxWtOnfA/j7gGv3bgCz/jmeBHCZss7XANyiyFv97ZpquEf9pdexYtmvAXi5f3/6AewH8JGS5c6/D60ANgM4AOB3/WU3wnvTXehv/0kAj1Zsu6PkXJ8KaOMdK/cq4Jp/CsBP/OemA8CjJc/a9QBG/Gct5V+3F49f9bh1UpB5ANP+A/rfACRLFORTJet2AcisLPdl7wLwkP/5nwB8oGTZm6vdWKUdrwEwBEBKZI/ilwry5ZWLWbL8eQDXwVOaYxXL/gjAfy+5WQ9XLL8NwGdKvr8awEjFOv8GwPdraPtOePZM92koSNS/NptXoyDKuh8BcG/FQ359yfffB/Cg//k+AO8tWRaC11PYUqkgNRxXU5DKa34IwA0l338dwID/+XYA/7lk2Y5ajl8vo+wm59w/Vll2vOTzFng3drjE8RMqWWdjxfpHT6MNGwGccP7VUbbfAuBmEfm3JbKYv10BwEYRmS5ZFgbwwyrnAQBTABpLvs8DaKpYpwnVu0gv4px7QUSehffj8o5Tre+zcuzpwLVOgYjsAvB5eLZjCt6b4ImK1SrvyUb/8xYAf1XhdRIAm3B6964aldd8Y8V+S9uyEcDjAduqrAWjuPSBPQ7vDdLunGv2/5qccyuG7DC87tUKm0/jOMMANlW4XEu3Pw7gz0uO2+ycSznn7vKXHalY1uicu6HKeQDAUwB2lXw/ACAiIjtLZJfB63LWQgTA9hrXBbxuzYBzbvY0ttH4Mrxu7U7nOQw+Ae8hL6Xyngz5n4/D6x6XXrekc+7RVbZphcprPgRPKbW2DAPordLmqqwFBXkR59wwgPsBfE5EmkQkJCLbReQ6f5WvA/iQiPSKSAs8m6NWfgwg728fFZF3ALi6ZPltAD4gItf4HrW0iLxFRBrh2UFzIvIfRSTpOwsuEZGrAo73AIArRCThn9sCgG8B+JS/72vh9dH/p7axb0R2+p8vgtele7BkedTfdwie4iVWnBk+18Hr4qysf4uIfP8U1yju72flLwTvTTQLYF5EdgP4PWW7/yAiLSLSB+DDAFbGYP4awB+teOp8B8w/P0UbVsNdAD4pIh0i0g7PZvyav+zrAP6ViFwoIikAf1LLDteUgvj8S3hdm33wuinfANDjL7sNwPcA/ALAXngP3IuIyCdE5D4oOOey8LonvwNgEsC/KN3eOfc4PJvgi/5xD/rrwjlXAPBWAHsAHIHnj/9bABuqnYRzbhSezXRjifj34RmTY/Bu5u8555712/5qEZkvWfdaAE+LyAKA7/p/nyhZfhuAJXg22h/7n0s9Yu+C5+xYoQ/Aj6q112fe38/K3+vhORLeDa8reBt++fCX8m143a4n4bmdv+pfg3sB/AWAu31P0zMAfkM7sIj8tt+NXA23wutGPQXgaXjPyK1+W+4D8F/hORQOwjPmAa/HUhUp75IbZxP/l/9OAFe7Ol5oEXkbgPc4595ZInsSwBuccxP1asdaRkQuhKewcedcvup6piDGrwoi8nZ4b+IUvB+uonPupqBt1mIXyzDOFe+H1709BM8zqdlTZdgbxDACsDeIYQSwKgURketF5HkROSgip+NyNYx1wRl3sXyf+wF4QXmDAH4G4F3OuX3VtonFIi6RiJfJJMw6mssXSFYosKxYKKrHiUTDipCDBmrN0nBFvkbZxWXeX4h3GE1E1X0qqwKOhU6RRSLKceJKUIR2gsr9lioXopDndfN5dvhoj1A6nWChsuLszDzJonG+ZqEqgd65bI6FIV43HCp/JpYXlpHNZE/5BKwm1ORqAAedc4cBQETuhufzr6ogiUQcV16zu0wWbayMvgDGpiZJNjnJEROZOX5IAaClm/cZaW0jmUSVi64p7BzfhGN7+TSjTZVBrkDfzh6SAUBSeciLOX4wCnler6WDH76erXx+YeVHoVjgBzwS5XYDwOwkn/fJkTGS5YrcxldcvZtkLsPHvv/+h0m2qX8TyZLROMkAYOj4CMnCSU43akw3ln3/6f0/U/dXyWq6WJtQHs8y6MvKEJH3iZdV93g2V9XdbBhrknNupDvnvuKcu9I5d2UsupYT1gyDWc0TewLlAV+9vqw6YUGkobx7kOxoodUaMjz6Pzk1RbLWrkaSAUD3du7WTC9r9orSBVW6JYvL3E8uFLn7saGJI086OvU2Rhx3a2ZnFDsrzMduaE+RLKfYaJklxZbLZUkWT1frirMtl8vweUdiSZK1beBu7uL8DMtmF0l2cogH+5MxvRsYdtzGdFMzybIV16JW03s1b5CfAdgpIlv9DLPfgpchZxjnDWf8BnHO5UXkg/CCB8MAbl8JvDOM84VVGQXOuZUoU8M4L7GRdMMIoK5uJQmHEakw3qJxNr4amtiwTU/yel29repxko1pks1k2diNRJRBvBBfksLSEm+r/LSkG3h8IqcMrAFAyLFhu7zAyX/LWZYV8+283gyPCU2O8NhROMbn3LGZ2wIAkRgb75kFNvITSb7eCWWwr7DMBvXyIhv92UW2oLva9HudaOIxj5zyuz98dKjseyHHDgwNe4MYRgCmIIYRgCmIYQRgCmIYAdTVSA9HotjQ0Vkmm5vmwMREA48UN7awMdbcoxtu80oafjTERmNCGQHOFXnEPb/MBnBMMXZFiX6dGmHnAAAklJ+mzLxSIkvYmEyF2RnQmObrU8wpgZdK5K4W1AgAxTwb0KGwEkkc5WtRGT0LAMk4t7u7byPJevu4OmnPpk6SAUBGcSQMDgySbHGpPBKjWD0NvQx7gxhGAKYghhGAKYhhBGAKYhgB1NVIDwkQj5QbbxJhY66zmw232cw4yaRKfklmhq30WIgz0qJF/n3QUpCzWR491oLnZ8Y5JD+Z5lFmAFhOsPHd3MZh2g2NbNjOOd52Mc+OhEKKz1mybJwuzXDIOQDEYnx9JMrXJ6U4VeIhdoA0dfJ6u/dw5iGUZ8Il9fj0kJIBmkqy0+CKV5ZPtnXyODuH1P3XtJZh/IpiCmIYAZiCGEYApiCGEcCqjHQRGYBXFr8AIO+cu/JsNMow1gpnw4v1Ouccu5gUCoUC5mbKE/dFCe04foxn50ordZEWJ/TJkwo59vzElFCThWnOlwilOO9EDblQQjZiSg5E22b2TAFAupkLPKQalenjlSJohRx7dHJKfI0oRefmx9h7M3NSnxHhoqsuIFlbNxfZoHmeAMSjfA+am9ijl27l4g5LBb7eOdVvCLQ08PVt6eNnZW6+POQnrHi/NKyLZRgBrFZBHID7ReQJETmfJq03DACr72K9yjl3wp9L7wERec45V1ZL0lec9wFAskFP7TSMtcqq3iDOuRP+/zEA96J8UsyVdV6srBhP6vVVDWOtcsZvEBFJAwg55+b8z28G8KmgbQrFIuYWysMaciE2vgaefJpkm7Zw+EljlTCO5jSHNDglR2RmZoGFikFeVMIzGpRjb72MZ6Vu38FFpQHdSBSlgvnoUa5GeHw/5zu0NrLxfPEll5Ls8WfZATI9ruespBvZkRAKs0WeySg5K81ceCMRZyeEVgU+6Xg9KeihJu3NHSR7+tm9JHt+34Gy7wtzenhNJavpYnUBuNcvnR8B8L+cc/9vFfszjDXHaiorHgZw2Vlsi2GsOczNaxgBmIIYRgB1zQcpFotYXC6vUpgtsgGcURLq0xvZ2E0Wda9YIcsWeUg4x6AhwQbiyUnO6Vhe4v1tv6SfZP2X88xIGce5JACgzSg2N8QG+YFHnyHZvDJtWfoCpZIhuN1NnVz8IF7lZzIe4qiCnHLJGzex+34swyP2jQ1KxcwkO1QiRWWqg7w+kl5QClMcPnCcZKOHymfGyimzXWnYG8QwAjAFMYwATEEMIwBTEMMIoL5FG0IhJCsS/OfHOVK+e1Mvyfq3byNZS1IJvQZw7NARkg0d5hHk1g42GqOKYZvt5hHl3t3dJAsp00qHlJL/ACDK9M6Hn+AR8oVJHu2/4GV8LXZfcyHJho+xsdqkWOS7r9qltjHUxIZ/spmdJdEU73M5y6kEo5NskAvYIA8rk8gXlEqNADA3x1NTnBzj8P2iMtd9LdgbxDACMAUxjABMQQwjAFMQwwigvkZ6JIxka7lhHJvi0eOQMoF9Q4Jzl5NNbPQBwLYLOZd65NgIy0bZmOtW5hnc8zI2gPuU6o9OqdSYD3H4PAC88OxBkp08dpJkXVs5nHv3NReTrLGNr8XSEldbbGrkofB4lz6NRCiqjKSDR6BHD3K7+3Z1cXvy2lyPivGsjeAX2XAHgPGTQySbmmDHTzKkPyunwt4ghhGAKYhhBGAKYhgBmIIYRgCnNNJF5HYAbwUw5py7xJe1ArgHQD+AAQDvdM5xnHgFIREkIuWjs1HF+Mork7wXCxzuLMqIKwAklTzn7Rez4f7Ew4+R7LkTJ0h26avYKM4o0wBEZ7iNbY7bAgBz4IJnF+/aSbL2nWzsRtNsaC8s8oh7xxY+RmwDt2dJ9yOgNcnOkkNPsrNj8NgYyV61m/PhiyF2GmgD3C7EOem5AjtzAKCY49zyYkF5fpS5HmuhljfIHQCur5B9HMCDzrmdAB70vxvGeccpFcSvc1WZ/XIjgDv9z3cCuOkst8sw1gRnaoN0OeeG/c8j8CqcqIjI+0TkcRF5PLPIr1jDWMus2kh33pxlVUMlywrHpfT+uGGsVc50JH1URHqcc8Mi0gOArTT1YCF0hctHNAeUt0qhwKO1uQzndhfyuuEVirNx2burn2TDAxwCPzLOhnZ8I+dcT+S5snznDLenscCh8gDQkmRDdMfr3kCy1o08yj2zxAbrvHAOeKbAI9exIcWAXdDzveeTbABHldz+HZezAyTRzqkEExPsx1nMKVETMZbFw3oOeUKJgtcq78/Pz5V9LxRrM9rP9A3yHQA3+59vBvDtM9yPYaxpTqkgInIXgB8DuEBEBkXkvQA+A+BNIvICgDf63w3jvOOUXSzn3LuqLOL+gGGcZ9hIumEEUN/CcYUC5qfKjaWFeR4BVuxAzEyxUeyUEVMA6OxT8sWT7EG75BVcWvjS5e0kC4d5qHlpnA3lrhiPcKcK+mg/prj428hhDoEPh7kYXZMSuh0u8Pllcmx8x6Y45z4W0UPBx4fYqN6hFH/LgM97eY6dL5EI57jPLnDKQcbx9e5u1ttYVM4xEuPHemNXedrAwCEOk9ewN4hhBGAKYhgBmIIYRgCmIIYRgCmIYQRQVy8WQiFIqtzj0d3LcY6ZjBJ+kuNQg+yyMvEggKkRLiLQ2d9HspY2DuNIT/IlyRxnj8emGBeRyIU4tCMrerLFxo3K9opHJneco3hO5jj0rRhm119jWpkTMMmhL5GYMt0AgJBSPEGrzDg+wR697ADLXCt72lLKscNJ5Xc7yh4wAMgoCSX9F3Dlya2by72BIyOnTF8CYG8QwwjEFMQwAjAFMYwATEEMI4D6VlYMh5BoTpfJYuNspCWb2JiLRbipkbDe/KkhLizQ2cPhJ4WwUjBilg3/3BTnRYwVOD8lmuCQiyalUiMAJBSbM9XIhvvyojKHo5JDo4XdVOZAAMB8hLcNKyEg3gIO74i18ZQTfRvY2VEs8vU5+DxP79DSxXMmZqLscJhf0ud6DCuPcDLOsmzFXJGueo5fGfYGMYwATEEMIwBTEMMIoJaMwttFZExEnimR3SIiJ0TkSf/vhnPbTMN4aajFSL8DwBcB/I8K+Recc589nYMVi0UsLJQbvPksjzTnlXyQfJGN1UJBN7QiKS6ysDjLBmtiA480R5o43+GVr72OZI/t3UuyHz3+c5JdqlRLBICuFj7O3ATniGxoVuZH7Ooh2dICbzsxzYUcljVjN6xfx9EJdnakGtmpsmUHF22QZb5fW4scKTAwyZECkSaeWmJhWTfSB144RLIjB54jWU//tWXfQzX2nc60cJxh/EqwGhvkgyLylN8F06ebNYx1zpkqyJcBbAewB8AwgM9VW7G0suKyVVY01hlnpCDOuVHnXME5VwRwG4CrA9Z9sbJiwiorGuuMMxpJX6mq6H99O4BngtZfoVgsIrtUHhKeTiml7sGGezHBBl6yibcFgFSa5/XTqjVqZfJPzHARgZ0pNqivvvQKkj2xdx/JFjN6RcCkEnaeUCoKhpQpHoaGRkkWj/No+Jb+fpI5ZbqJqDJyDQB9SkGNYeXYB/fzee+6+HKSbW/laSQmH+PUhEklciGnzFsJABOzHFa/oaWdZNu2lxfj+GH8CXV/ldQyP8hdAF4LoF1EBgH8JwCvFZE98GryDgB4f01HM4x1xpkWjvvqOWiLYaw5bCTdMAIwBTGMAOoa7i4AwhVhxqkGNrSb2liWKSoVAWO6fo8PDpMs3c4h2bNDvF4ixsbuT/bxyOy1l11Fsre/4+0kGzw6oLaxoEQQJBrZGQClMGNjA9+2QpH3NzTII+GxGEcZFPN63nwkydeiq5cdIDMTbMyPj3Bo+8EZro7Z091PssGRAZK5Bj1vfvMFm0k2sO8IyUYGx8u+57O686QSe4MYRgCmIIYRgCmIYQRgCmIYAdQ3Jz0UQipZbiTmlekBWlp5JDSUYUNyOavHdo2dUHKflYjufI5D4JM9nCM9GeUR90d/waHtb3n9m0nmlrmYHAAcO8RTHcSVeQszWQ7z3tjN1yeu5GFPz3EIfEKZokEKupE+OjVOsoJSOC6Z5hCipQU2yHMZHiH/wc9fINnAIt+XhmY9b35DGzsdei/oJVl7V3mBwkiVQnSV2BvEMAIwBTGMAExBDCMAUxDDCKDOhePCSG4oL45WcFqINxtQQ0d5dDSb1uf/K0ZYPnqMDffefq4sn11iw791Exvu+378JMnSD/+QZJdfouekLy+xAR1TQv/bu3l0PbuoVFPPcqRBe2sbyYqihc/ziDsAFLLK72dWKban7LNQZMdGMs6j4cfHOCc91MZOiMlxvRp7fnqaZFe85lqSdbdXGOlKeoCGvUEMIwBTEMMIwBTEMAIwBTGMAGpJue2DVzSuC16K7Vecc38lIq0A7gHQDy/t9p3OucB5rUKhEJIN5RXD55bZmDvyPI8yLyijuukUh14DQE5JX15Y4pDscJRHgA8PHCPZ7CSP7G66dAfJvvvgIySby/CIMgBcfemlJMss84h2Sil0EYvybZtRjFXN4ZBUHAGhKI9GA0A8qdQBUCrqZxWDPJPjc8kodQH6tm0n2bxSbX4mpBe3a+lSnoE4RwuMLpfXGsgrbdao5Q2SB/BR59xFAF4O4A9E5CIAHwfwoHNuJ4AH/e+GcV5RS2XFYefcXv/zHID9ADYBuBHAnf5qdwK46Vw10jBeKk7LBhGRfgCXA3gMQFdJ6Z8ReF0wbZsXC8ctznOwmmGsZWpWEBFpAPBNAB9xzpV1rJ1zDtCn7CktHJdq4BmLDGMtU5OCiEgUnnL8nXPuW754VER6/OU9AHhI1DDWObV4sQReHaz9zrnPlyz6DoCbAXzG///tGvaFeKTcwzB88jitd/S550l26VVclS8c0avtzRXY+9KwgSsZalMBtLVycYdjx4+SrGfXFpJt/bWLSHZwgENcAGBbPxcb2L6F97msVDfMK9M+dHZvItnQILd7SpkGIga+XgCQVwpBTCkevXiKvUZOma7C5dlzFEtwmMqCUt2ydytfLwDYchF7wU5MsSdyvmL6BC0URqOWWKxrAbwHwNMishKA9Al4ivF1EXkvgKMA3lnTEQ1jHVFLZcVHoBafAQC84ew2xzDWFjaSbhgBmIIYRgB1zQcpFAqYmS4PvZif4RCJhhSHGohi9MXjevhBawuHZwyPc/GEBSWHon87G4MbOngCrUPK3Hi7t7DBGIroru3Kie0BYHGZDfIm5VrM5TmEJJtjWaqpmWTj0+xsXJrSI4SaGtmxkYryb2pI2OBtSXP4ylyBc2DSCzw21qyEimzo4pwcADiZ4ekT5vPsSIArz0XRnxzG3iCGEYApiGEEYApiGAGYghhGAHU10ovFAhYrKu6llOT5V77xdSTbfeE2kh2fYEMZAAZneYR96QU20pcW2Siey7EzoKOBix9MFDk/Zf+zPE3Cay6+TG1je0MTyeYmeAS5SRnZlzw7F2YW2eiH8O0NKYPm6bQy7QKAVIINba1iYlwpxlAUdhosxnnb1CI3aFsPRwVMRPQqmlMzfB+iSTby80uVjoTazHR7gxhGAKYghhGAKYhhBGAKYhgB1NVIj0QjaO0uNzp7du6i9fYooeQt7Tyq29SqV8eLsd2GSAPHW06MskFeLPIo7LGjPJdhc4rbE+3oJtnYkjKqC6AvnSZZOM+GY2GZDfK8EgFQgFLcQSmwEBP+TVzK6/P19XQq56Nk/cwv8DlOK+e97PgeLE3zsU8ucYqAa1cTViHKXI/xtFKYIl6+nijVIDXsDWIYAZiCGEYApiCGEcApFURE+kTkIRHZJyLPisiHffktInJCRJ70/2449801jPpSi5G+Ujhur4g0AnhCRB7wl33BOffZWg9WLBaxtFg+Ijo4f4LWy+ZGSbZl61aS9XZxmXwAuGDjBSQLh/hUk7FJkmUySpXAOR7FnZ1h4/Blu9jhkFDC1QFgeoxHzTsibGgPnmSPwwllxN1F2ejf1s2GbWOKR8clrOf2LynzI0ZCPGo+P88GeV6prNjVoEwjscBzFD57hKe62Lqlymh/jK9vTqkoefxoeZ56NqNEHijUknI7DGDY/zwnIiuF4wzjvGc1heMA4IMi8pSI3C4inFVkGOuc1RSO+zKA7QD2wHvDfK7Kdi9WVlya16dENoy1yhkXjnPOjTrnCs65IoDbAFytbVtaWTHZoFcRN4y1yhkXjhORnpLavG8H8Myp9pXP5TExUm505pViYvue48JfW0fZmH/lK65Sj9PezCOpW9p5cvlwiI3T40rOdt+FbFyODXIe98GDPyNZcwuPRgNAk+NR8znlBXtMmVvx+aNcbK+zjdvYnmKDuqOZQ/dbmjn0HgCOD/N9aFKM/OZWzn1fWOBc/JOz7BSZXOA89RmluB2qjHwvKc/PyGGePiNZLL/eUofCce8SkT3wAusHALy/piMaxjpiNYXjvnv2m2MYawsbSTeMAExBDCOAOuekOyxWVFRvSrAx98IAFwM7doRH1+dnOaccAK56JVdZb23hYZrudi4Sl05yGPuxqQGSFXt55Ho+we2ZXWCDGgDyCR41nysq4eAdPIIcifSRbGqejd28NkCuOAdmp7h4HwC0dfFI/NL8DB97hmWhCDsITkxwVMDegzxq3r6H6w9oYfoAMHiAnRgNinMi5spH9kMW7m4Yq8cUxDACMAUxjABMQQwjgLoa6aFQCMlUhXGa57DjUIENqNERDvF+8NuPqMdp2sDW6c5Ld5AsFeER5N5Gnpg+rlRbe77IxqE3Y2M5sYxeoMwp4da5hBIi3s4j5J15PtDCJBdlm1OO0eB4lHoxqxdliyTZ2E0rldenFMP/yOBhkj03wCPcUEbmOzdx1MNTP3iMZABw3ZVXkuyqV7+CZD/8p/vLvkeqhPhXYm8QwwjAFMQwAjAFMYwATEEMIwBTEMMIoK5eLAkB0XS5TmpF/aItHH6ypZnzKgb3j6jHeeSBX5As1cTeklSawz3SSf7N6NzAoQ/RFOdVHB1nL83sInumAGA5yfkIUzMcYjOXZdnyGId2pBb5XHJFnjphOsEeuVhcL4iQzfK6U/Oc03FCCT+ZjCpVIhu5jd1tfF9OHjlKsojSFgDYvINzf8IR9ng2N5SHEGm5QBr2BjGMAExBDCMAUxDDCKCWyooJEfmpiPzCr6z4Z758q4g8JiIHReQeEeFhV8NY59RipGcAvN45N+9XN3lERO4D8O/gVVa8W0T+GsB74ZUCCqAIVyyfOH56gnMohk+wYXrhNf0kyy7oYRzTExxO8dD3HidZPsSGcnYXew02KvMWtjWxkX5B98Ukm5pjAxYAxhY5NyIMbk8qxA6LTOh5RqcAAAQLSURBVIyLJBz4+T6SDStzFfT0bifZ5GF9rsfsMleRECX7OtnJ7dl8EVe3bNnM+TcLy5zHEorw73ZbD4fcAIBL8r2ZnuNnanq2/FwKxbM0R6HzWDmLqP/nALwewDd8+Z0AbqrpiIaxjqi1LlbYr2gyBuABAIcATDvnVtR3EFXKkZYWjlte5IlfDGMtU5OC+AXi9gDohVcgbnetBygtHJdIcSSoYaxlTsuL5ZybBvAQgFcAaBZ5cSLuXgBc2c0w1jm1VFbsAJBzzk2LSBLAmwD8BTxF+U0AdwO4GcC3T7WvfK6A6dHyioTPPXGA1lte4K5YWCly0NbHxiEAZJd4+xMvsFH8E/CIezTJ5fRnO3j0uGmSj72xk0fcmxv1KRpiUf5tSimOwI4Ub9/Rr0QabODR8B/8hB0TRxY4+mB8Qf9ta1OiFzZt5vkje3s5P6VvIxeWGJ/gapTz0HJR2IBubNRro2eKSuGOAl+fzk3luTGRqD4tRSW1eLF6ANwpImF4b5yvO+f+QUT2AbhbRG4F8HN45UkN47yilsqKT8Gb8qBSfhhVClYbxvmCjaQbRgCmIIYRgDgl4f6cHUzkJICjANoBsNW8PrFzWZuc6ly2OOe4QkcFdVWQFw8q8rhzjstRrEPsXNYmZ+tcrItlGAGYghhGAC+VgnzlJTruucDOZW1yVs7lJbFBDGO9YF0swwig7goiIteLyPN+JuLH63381SAit4vImIg8UyJrFZEHROQF/78eNLTGEJE+EXlIRPb5maIf9uXr7nzOZdZrXRXEj+f6EoDfAHARvJlyeTqotcsdAK6vkH0cwIPOuZ0AHvS/rwfyAD7qnLsIwMsB/IF/L9bj+axkvV4GYA+A60Xk5fCCar/gnNsBYApe1utpUe83yNUADjrnDjvnsvAigW+scxvOGOfcwwAqQ3tvhJdRCayjzErn3LBzbq//eQ7AfnhJb+vufM5l1mu9FWQTgNJJ+6pmIq4jupxzw/7nEQA8sd8aR0T64QWkPoZ1ej6ryXoNwoz0s4jzXILryi0oIg0AvgngI865sklG1tP5rCbrNYh6K8gJAKWZNOdDJuKoiDd1jv+fS4msUfwqNd8E8HfOuW/54nV7PsDZz3qtt4L8DMBO37sQA/BbAL5T5zacbb4DL6MSqDGzci0gIgIvyW2/c+7zJYvW3fmISIeINPufV7Je9+OXWa/AmZ6Lc66ufwBuAHAAXh/xj+t9/FW2/S4AwwBy8Pq07wXQBs/b8wKAfwTQ+lK3s8ZzeRW87tNTAJ70/25Yj+cD4GXwslqfAvAMgD/15dsA/BTAQQD/G0D8dPdtI+mGEYAZ6YYRgCmIYQRgCmIYAZiCGEYApiCGEYApiGEEYApiGAGYghhGAP8fBgqIBOkK45UAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "batch_size = 5\n",
    "train_config = TrainingConfiguration()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    train_config.device = \"cuda\"\n",
    "else:\n",
    "    train_config.device = \"cpu\"\n",
    "    \n",
    "    \n",
    "\n",
    "# load test data without image transformation\n",
    "test = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10(root=train_config.data_root, train=False, download=False, \n",
    "                   transform=transforms.functional.to_tensor),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=1\n",
    "    )\n",
    "\n",
    "try:\n",
    "    mean, std = get_mean_std_train_data(data_root)\n",
    "    assert len(mean) == len(std) == 3\n",
    "except:\n",
    "    mean = (0.5, 0.5, 0.5)\n",
    "    std = (0.5, 0.5, 0.5)\n",
    "\n",
    "# load testdata with image transformation\n",
    "image_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "    ])\n",
    "\n",
    "test_trans = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10(root=train_config.data_root, train=False, download=False, transform=image_transforms),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=1\n",
    "    )\n",
    "\n",
    "for data, _ in test_trans:\n",
    "    # pass the loaded model\n",
    "    pred, prob = prediction(cnn_model, train_config, data)\n",
    "    break\n",
    "    \n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (3, 3)\n",
    "for images, label in test:\n",
    "    for i, img in enumerate(images):\n",
    "        img = transforms.functional.to_pil_image(img)\n",
    "        plt.imshow(img)\n",
    "        plt.gca().set_title('Pred: {0}({1:0.2}), Label: {2}'.format(classes[pred[i]], prob[i], classes[label[i]]))\n",
    "        plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:blue\">17. Report your findings</font>\n",
    "- \n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# <font style=\"color:blue\">References</font>\n",
    "\n",
    "1. https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
    "1. https://pytorch.org/tutorials/beginner/saving_loading_models.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
